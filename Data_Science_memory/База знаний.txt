from concurrent.futures.process import _ExecutorManagerThread
from pickletools import read_unicodestring4
from tarfile import ExtractError


//////////////////
///ТИПЫ ДАННЫХ///
////////////////
a = 5 		#int
a = 5.0 	#float
a = "5"		#string
a = True 	#bool print(True+False+False+True) = 2  print(True+False+False+True) = 0 print(True+True+True+True) = 1
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////








//////////////////////////////
///МАТЕМАТИЧЕСКИЕ ОПЕРАЦИИ///
////////////////////////////
abs() - взятие по модую
round((a-b), 2) - округление до 2х знаков после запятой







/////////////////////////////////////////////////////////////////////////////////////////////////////////////////








/////////////
///СТРОКИ///
///////////
#Задание строк. Нумерация начинается с 0!!! "01234..."
str1 = 'Hello!'
str2 = "Hello!"
str3 = '''Hello,
				world'''

/Метод .len()
#Длина строки
str1 = "Hello!"
str1.len() 
# 6

/Метод .upper()
#Все буквы большие
str1 = "Hello!"
str1.upper() 
# "HELLO!"

/Метод .lower()
#Все буквы маленькие
str1 = "Hello!"
str1.lower() 
# "hello!"

/Метод .title() #.capitalize() - первая большая, а все остальные маленькие
#Первая буква большая, остальные маленькие
str1 = "Hello!"
str1.title() 
# "Hello!"

/Метод .swapcase()
#Меняет регистр символов
str1 = "Hello!"
str1.swapcase() 
# "hELLO!"

/Метод .find()
#Возвращает индекс первого встреченного заданного символа
str1 = "Hello!"
str1.find() 
# 2

/Метод .rfind()
#Возвращает индекс последнего встреченного заданного символа
str1 = "Hello!"
str1.rfind() 
# 3

/Метод .isdigit()
#Возвращает True, если строка только из цифр

/Метод .isalpha()
#Возвращает True, если строка только из букв

/Метод .isalnum()
#Возвращает True, если строка только из цифр и букв, но не содержит символы

/Метод .replace("что меняем","на что меняем")
#Заменяет символы или удаляет, если заменить на ''
s = "Hello$ Python3$" 
s1 = s.replace("$", "") 
print (s1) 
# Результат: Hello Python3

/Метод .split() #Здесь разделение идет по пробелу, но можно и по другим символам .split("символ")
#Разделяет текст по словам, от пробела до пробела
colors = 'red blue green'
print(colors.split())
# ['red', 'blue', 'green']
#Результат работы этого метода — список строк.
# Если нужно разделить по нескольким символам, то 
str.split(',| |;')

/Метод 'чем склеить'.join(список)
#Соединяет элементы списка нужным символом
colors = 'red green blue'
colors_split = colors.split() # список цветов по отдельности
colors_joined = ' and '.join(colors_split) # объединение строк
print(colors_joined)
# red and green and blue

/Условия на наличие в тексте
if 'abc' in 'aaa asc abc':
    print('есть')
else: 
    print('нету')
#есть
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////








///////////////
///f-СТРОКИ///
/////////////
#Возможно создание форматированных строк

/Метод .format()
print("The {} currancy rate on the date {} is {}".format(currancy, cur_date, rate))

/f-строки
print(f"The {currancy} currancy rate on the date {cur_date} is {rate*1.2:.3f}") #Также можно производить операции с переменными

#Внимание!!! "двойные ковычки обязательно", 'с одинарными f строки не работают'!!!

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////








///////////
///ВВОД///
/////////
a = input()    
#или 
a = input("Здесь можно писать о том, что нужно ввести: ")
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////







	
////////////
///ВЫВОД///
//////////
print("Здесь можно писать о том, что нужно вывести:", a, sep='',end='\n')

sep='' #аргумент, отвечающий за то, как будут разделяться выводимые данные
print('a','b',sep='')
print('a','b',sep=' ')
print('a','b',sep=',')
print('a','b',sep='123')
#ab
#a b
#a,b
#a123b

end='' #аргумент задаёт символ, которым заканчивается печатаемая строка (по умолчанию это перенос на новую строку — символ \n).
print('a','b',end='\n')
print('a','b',end=', ')
print('a','b',end='\n\n')
print('a','b',end='!!!')
#a b
#a b, a b
#
#a b!!!
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////








/////////////
///СПИСКИ///
///////////
#Список в Python — это упорядоченная ИЗМЕНЯЕМАЯ коллекция объектов произвольных типов
#Важно: в списке можно хранить не только простые типы (числа, строки), но также кортежи, 
#словари, списки, списки внутри списков и даже функции.

#2 варианта создания списков:
my_list = list()
my_list = [ ]
			
a = 3
spisok = [1,2,a,'a',"Text luboy",[1,'abc',3],(5,8,9)]
#[1, 2, 3, 'a', "Text luboy",[1,'abc',3],(5,8,9)]

/Индексация
#spisok[0] = [1]
#spisok[1] = [2]
#spisok[-1] = ["Text luboy"]

/Срезы
#spisok[1:3] = [2, 3, 'a'] 
#spisok[0:4:2] = [1, 3, "Text luboy"] - взятие только четных индексов

//Генератор целочисленных списков определённой длины
a = range(начало, конец, шаг) - конец не входит в список
a = range(0, 10, 2)
[0, 2, 4, 6, 8]

шаг может быть отрицательным
a = range(10, 3, -1)
[10, 9, 8, 7, 6, 5, 4]

/Метод .append()
#Добавляем элемент в конец списка
orders_daily = [] 
# изначально список с чеками пустой
orders_daily.append("order1")
orders_daily 
# [“order1”] — в списке появился первый чек.

list.remove(element)

/Метод .clear()
#Очистка списка
a = ["order1", "order2", "order3", "order4"]
a.clear()
a 
# []

#синтаксический сахар
a = []
a 
# []

/Метод .count()
#Число элементов в списке
a = ["a", "b", "c", "d", "b", "b", "g", "b", "r"]
a.count("b") 
# 4

/Метод .copy()
#Копирование списка
a = [1,2,3]
b = a.copy()
b 
# [1,2,3]

#В Python есть синтаксический сахар для данного метода — две квадратные скобки с двоеточием внутри [:]. 
#Мы как бы говорим: «Сделай мне полный срез исходного списка в другую переменную»:
a = [1,2,3]
b = a[:]
b 
# [1,2,3]

/Метод .extend()
#Приклеивание списка
a = ["a", "b", "c"]
b = ["d", "e"]
a.extend(b)
a 
# ["a", "b", "c", "d", "e"]

/Метод .reverse()
#Переворот списка начало-конец
a = [1,2,3,4,5]
a.reverse()
a 
# [5,4,3,2,1]

#синтаксический сахар
a = [1,2,3,4,5]
b = a[::-1]
b 
# [5,4,3,2,1]

/Метод .sort()
#Сортировка от 0 до бесконечности, от a до z (от 1 буквы (сначала поставит cab, а потом cav)), сначала заглавные, потом прописные
a = [3,4,1,5,10,0, 2]
a.sort()
a 
# [0, 1, 2, 3, 4, 5, 10]

/Сгладить список списков с помощью sum
#Суммирование по внутренним спискам-это еще одно решение. Функция имеет два параметра: iterable , 
#который является списком списков, и start , который является пустым списком в нашем случае, 
#который служит исходным плоским списком, к которому добавляются элементы внутренних подсписков.

#Этот подход удобен тем, что вам не нужно ничего импортировать, но он медленнее, чем функции 
#itertools() и chain() при большом количестве подсписков:

regular_list = [[1, 2, 3, 4], [5, 6, 7], [8, 9]]

flat_list = sum(regular_list, [])

print('Original list', regular_list)
print('Transformed list', flat_list)

regular_list = [[1, 2, 3, 4], [5, 6, 7], [8, 9]]
​
flat_list = sum(regular_list, [])
​
print('Original list', regular_list)
print('Transformed list', flat_list)
​


/Метод 'чем склеить'.join(список)
#Соединяет элементы списка нужным символом
colors = 'red green blue'
colors_split = colors.split() # список цветов по отдельности
colors_joined = ' and '.join(colors_split) # объединение строк
print(colors_joined)
# red and green and blue

/Перебор уникальных значений
for recipe in recipes: # начинаем перебор всех рецептов
    if not(recipe['cuisine'] in cuisines): # если тип кухни текущего блюда ещё не встречался
        cuisines.append(recipe['cuisine']) # добавляем его к списку cuisines

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////








/////////////
///КОРТЕЖ///
///////////
#Кортежи в Python — это упорядоченная НЕИЗМЕНЯЕМАЯ коллекция объектов произвольных типов
#Важно: в кортеже можно хранить не только простые типы (числа, строки), но также кортежи, 
#словари, списки, списки внутри списков и даже функции.
#Кортежи занимают меньше места, чем списки

#2 варианта создания кортежей:
tpl1 = tuple()
tpl1 = ()

tpl3 = ("s") - переменная типа string
# "s"
tpl4 = ("s", ) - кортеж
# ("s", )
			
a = 3
kortez = (1,2,a,'a',"Text luboy",[1,'abc',3],(5,8,9))
#(1, 2, 3, 'a', 'Text luboy',[1,'abc',3],(5,8,9))
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////








//////////////
///СЛОВАРЬ///
////////////
#Хранит в себе ключи и значения

#2 варианта создания словарей:
my_dict = dict() 
my_dict = {} 

//Образец словаря
phones = {'+79033923029': 'Ivan Ivanov', '+78125849204': 'Kirill Smirnov', '+79053049385': 'Mark Parkhomenko', '+79265748370': 'Ekaterina Dmitrieva', '+79030598495': 'Ruslan Belyi'}

/Обращение по ключу
phones["+79265748370"] 
# Ekaterina Dmitrieva

/Обновление элементов
phones["+79265748370"]  = 'Ekaterina Ershova'
phones["+79265748370"] 
#  Ekaterina Ershova

/Добавление элементов
phones["+79686581788"]  = 'Artem Pliev'

/Метод .clear()
#Очистка словаря
phones.clear()
phones 
# {}

#синтаксический сахар
phones = {}
# {}

/Метод .keys()
#Возвращает ключи словаря
phones.keys() 
# dict_keys(['+79033923029', '+78125849204', '+79053049385', '+79265748370', '+79030598495', '+79686581788'}

/Метод .values()
#Возвращает значения словаря без привязки к ключам
phones.values()
# dict_values(['Ivan Ivanov', 'Kirill Smirnov', 'Mark Parkhomenko', 'Ekaterina Dmitrieva', 'Ruslan Belyi', 'Artem Pliev'}

/Метод .get()
#Выводит значени по ключу, но если не найдет, то не выдает ошибку, как при обычном обращении
phones.get("+79265748370", "I don't have it!") 
# Ekaterina Dmitrieva
#А если не найдет, то выведет все, что в аргументе, хоть число! (Здесь "I don't have it!")

/Метод .update()
#Добавляет или обновляет элементы не по одному, как через {}, а можно сразу несколько
phones.update({"+79686581788":'Artem Pliev'})

/Метод .pop()
#Удаляет элмент, но с присвоением удаленного элемента преременной, используя ключ
phones2 = phones.pop("+79686581788")
#'Artem Pliev'

/Метод .setdefault()
#Если не было элемента, то создаст, если был, то оставит не изменным
phones.setdefault('+79033923029', 'Ivan Petrov')
phones = {'+79033923029': 'Ivan Ivanov', '+78125849204': 'Kirill Smirnov', '+79053049385': 'Mark Parkhomenko', '+79265748370': 'Ekaterina Dmitrieva', '+79030598495': 'Ruslan Belyi'}
phones['+79033923029']
#'Ivan Ivanov'

/Метод .items()
#


/////////////////////////////////////////////////////////////////////////////////////////////////////////////////








///////////////
///МНОЖЕСТВА///
///////////////
#Множество — это структура данных. Типы элементов внутри множества могут быть различными. Порядок элементов не фиксирован.

#С множествами можно делать многие операции из теории множеств: объединение, пересечение, вычитание и т. д. 
#Можно проверять принадлежность элемента к множеству.

#Любые неизменяемые типы данных могут быть элементами множества: числа, строки, кортежи.

#→ В отличие от списков, где элементы хранятся в виде последовательностей, в множествах порядок хранения элементов не определён. 
#Внутри множества представлены с помощью «хитрых» алгоритмов, которые позволяют выполнять операции типа 
#«проверить принадлежность элемента множеству» быстрее, чем просто перебором всех элементов множества.

#2 варианта создания множеств:
set1 = set()
set1 = {'chto-nubed'} - множество. Нужно указать хотя бы один элемент
!!!
set1 = {} - словарь

//Образец множества
s1 = set("hello")
#  {‘h’, ‘l’, ‘e’, ‘o’} - мы имеем одну l, так как в множествах нет повторений. Не важно число раз,
#встреч компонентов, варно просто наличие.

/Метод .add()
#быстро и безболезненно добавляет 1 элемент в множество 
s = {1, 2, 3, 4}
s.add(5)
# {1, 2, 3, 4, 5}

/Метод .update()
#Добавляет во множество сразу несколько элементов. Ему можно передать один или сразу несколько итерируемых 
#объектов (строк, списков, кортежей, множеств), если, их там ещё нет.
#Если нужно добавить числа, то нужно оформлять их как текст
s = {1, 2, 3, 4}
s.update('578')
# {1, 2, 3, 4, 5, 7, 8}

/Методы .remove() и .discard()
#Удаляют указанные объекты
#Если элемента нет, то первый выдаст ошибку, а второй проигнорирует.
#Применение зависит от логики работы программы
s1 = {1,2,3,4,5}
s1.remove(10)
# Ошибка KeyError: 10
s1.discard(10)
# Ничего не произошло

/Опрерация над множествами .union()
#Объединение множеств
cluster1 = {"item1", "item2", "item3", "item4"}
cluster2 = {"item2", "item3", "item5", "item7"}
cluster1.union(cluster2) 
# {"item1", "item2", "item3", "item4", "item5", "item7"}

/Опрерация над множествами .intersection()
#Пересечение множеств
cluster1 = {"item1", "item2", "item3", "item4"}
cluster2 = {"item2", "item3", "item5", "item7"}
cluster1.intersection(cluster2) 
# {"item2", "item3"}

/Опрерация над множествами .difference()
#Вычитание множеств
cluster1 = {"item1", "item2", "item3", "item4"}
cluster2 = {"item2", "item3", "item5", "item7"}
cluster1.intersection(cluster2) 
# {"item1", "item4"}

/Опрерация над множествами .issubset()
#Сравнение множеств
cluster1 = {"item1", "item2", "item3", "item4"}
cluster2 = {"item2", "item3", "item5", "item7"}
cluster1.intersection(cluster2) 
# False


///ИЗМЕНЕНИЕ(ПРИВЕДЕНИЕ) ТИПОВ ДАННЫХ///
#to float - происходит автоматически. Писать не обязательно, но нужно знать.
var_float = float(var)

#to int - обрубает дробную часть, а не округляет!!! int(7.8) = 7!!!
var_int = int(var)

#str
var_str = str(var)

#to кортеж
vat_tuple = tuple()

#to список
var_list = list()
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////








//////////////////////////
///ОПЕРАТОРЫ СРАВНЕНИЯ///
////////////////////////
a == b
a != b
a > b
a < b
a <= b
a >= b
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////







///////////////////////////
///ЛОГИЧЕСКИЕ ОПЕРАТОРЫ///
/////////////////////////
#Логическое «НЕ»				Возвращает противоположное значение
not	

#Логическое «ИЛИ»				Возвращает True, если хотя бы одна из переменных True
or

#Логическое «И»					Возвращает True, если обе переменные True
and	

#Проверка принадлежности		Возвращает True, если проверяемая переменная содержится/не содержится в 
#								последовательности (списке, кортеже, строке...)
in 
not in	
print('5' in str(123456789))
#	True

#Проверка тождественности		Возвращает True, если проверяемые объекты эквивалентны/не эквиваленты. 
#								То есть переменные ссылаются на один и тот же адрес в памяти компьютера
is 
is not	
a = [1, 2, 3]
print(id(a))  # id возвращает идентификатор объекта
# 140039772293512

b = a
print(id(b))
# 140039772293512

print(a is b)  # а и b являются одним и тем же объектом
# True
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////







////////////////////////
///УСЛОВНЫЙ ОПЕРАТОР///
//////////////////////
if Условие:
    Блок инструкций 1
elif Условие N:
	Блок инструкций N
else:
    Блок инструкций 2

//Пример
if a == 10:
    print('a equals 10') # a равно 10
elif a < 10:
    print('a is less than 10') # a меньше 10
else:
    print('a is more than 10') # a больше 10

//Инлайновый - if
a = 42
b = 41
if a > b:
    result = a
else:
    result = b
#Данный код, в зависимости от значения переменных а и b, присваивает переменной result значение большей из них.

#Код сравнения занимает аж четыре строки, а выполняет элементарное действие. 
#Это не в стиле Python — нужно исправлять данную ситуацию.
#Для таких случаев существует так называемый тернарный условный оператор — оператор, который записывается в одну строку.

#В Python вы можете встретить «инлайновый if». С его помощью можно переписать код следующим образом:
/Тернарный оператор
result = a if a > b else b
#ИЛИ
result = (b, a)[a > b] - результат равен a, если условие верно. ТОЧНО a, ПРОВЕРИЛ. ХОТЬ И СТОИТ НА 2 МЕСТЕ В СКОБКАХ
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////








/////////////////
///ИСКЛЮЧЕНИЯ///
////////////////
//Конструкция
try:
    *код, который может вызвать ту или иную ошибку*
except *ошибка*:
    *код, который выполнится в случае возникновения ошибки*
else:
    *код, который выполнится только в случае, если в try ничего не сломалось*
finally:
    *код, который выполнится в любом случае*

//Вызов ошибки*
raise ValueError("Invalid Date!")

//Пример
try:
    print("Before exception") # перед исключением
    a = int(input("a: "))
    b = int(input("b: "))
    c = a / b
    print(c) # печатаем c = a / b, если всё хорошо
except ZeroDivisionError as e:
    print("After exception") # после исключения
else: # код в блоке else выполняется только в том случае, если код в блоке try выполнился успешно (т. е. не произошло никакого исключения)
    print("Everything's fine!") # всё отлично!
finally: # код в блоке finally выполнится в любом случае при выходе из try-except
    print("Finally finished!") # наконец-то завершено!
 
print("After After exception") # после после исключения

//Ошибки
#Исключение, возникающее при делении на 0	
ZeroDivisionError

#Ошибка значения	
#При невозможности привести один тип к другому	
ValueError

#Файл не найден	
#Если попытаться открыть файл для чтения, который не был создан	
FileNotFoundError

#Недостаточно прав	
#Если попытаться открыть файл из корневых каталогов при запуске программы не от имени администратора	
PermissionError
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////








///////////////
///ЦИКЛ for///
/////////////
//Конструкция
for value in iterator:
    # Начало блока кода с телом цикла
    ...
    ...
    ...
    # Конец блока кода с телом цикла
# Код, который будет выполняться после цикла

//Пример
S = 0  # создаём переменную-счётчик, в которой будем считать сумму
N = 5

# создаём цикл for, которым мы будем проходить по всем числам от одного до N
for i in range(1, N + 1):  # равносильно выражению for i in [1, 2, 3, ... , N -1, N]:
    print("Sum on the previous step: ", S) # значение суммы на предыдущем шаге
    print("Current number: ", i) # текущее число
    S = S + i  # cуммируем текущее число i и перезаписываем значение суммы
    print("Sum after addition: ", S) # значение суммы после сложения
    print("---")
print("End of the cycle") # конец цикла
print()
print("Answer: sum = ", S) # ответ: сумма равна =
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////







/////////////////
///ЦИКЛ while///
///////////////
//Конструкция
while условие:
    # Начало блока кода с телом цикла
    # пока условие истинно, цикл выполняется
    ...
    ...
    ...
    # Конец блока кода с телом цикла
# Код, который будет выполняться после цикла

//Пример
S = 0  # создаём переменную-счётчик, в которой будем считать сумму
n = 1  # текущее натуральное число

# создаём цикл while, который будет работать, пока сумма не превысит 500
while S < 500:  # делай, пока ...
    S += n  # увеличиваем сумму, равносильно S = S + n
    n += 1  # так как сумма ещё не достигла нужного значения, увеличиваем переменную-счётчик
    print("Still counting ...") # идёт подсчёт

print("Sum is: ", S) # сумма равна
print("Numbers total: ", n-1) # количество чисел
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////








//////////////
///МАТРИЦЫ///
////////////
//Конструкция
for i in range(N): 
    for j in range(M): 
        print(matrix[i][j], end=" ")
    print()  # перенос на новую строку

# 0 1 2
# 3 4 5

#min and max

//Пример
random_matrix = [
   [9, 2, 1],
   [2, 5, 3],
   [4, 8, 5]
]
min_value_rows = []
min_index_rows = []
max_value_rows = []
max_index_rows = []
for row in random_matrix:
    min_index = 0
    min_value = row[min_index]
    max_index = 0
    max_value = row[max_index]
    for index_col in range(len(row)):
        if row[index_col] < min_value: 
            min_value = row[index_col]
            min_index = index_col
        if row[index_col] > max_value: 
            max_value = row[index_col]
            max_index = index_col
    min_value_rows.append(min_value)
    min_index_rows.append(min_index)
    max_value_rows.append(max_value)
    max_index_rows.append(max_index)
print("Minimal elements:", min_value_rows) # минимальные элементы
print("Their indices:", min_index_rows) # их индексы
print("Maximal elements:", max_value_rows) # максимальные элементы
print("Their indices:", max_index_rows) # их индексы
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////







////////////////
///ENUMERATE///
//////////////
#За один проход по циклу for мы можем либо получить само значение из списка, либо индекс, по 
#которому дальше обратимся и получим элемент, как, например, здесь:

list_ = [-5, 2, 4, 8, 12, -7, 5]

for i in range(len(list_)):  # равносильно выражению for i in [0, 1, 2, 3, 4, 5, 6]:
    print("Element index: ", i) # индекс элемента
    print("Element value: ", list_[i])  # с помощью индекса получаем значение элемента
    print("---")
print("End of the cycle") # конец цикла

#Но чтобы убить двух зайцев сразу, есть функция enumerate. 
#Она возвращает кортежи, где на первом месте стоит индекс элемента, а на втором — его значение.

list1 = [-5, 2, 4, 8, 12, -7, 5]
# Функция enumerate возвращает данные в виде кортежей, 
# где на первом месте стоит индекс, а затем значение 

for i, value in enumerate(list1):  
    print("Element index: ", i) # индекс элемента
    print("Element value: ", value)  # с помощью индекса получаем значение элемента
    print("---")
print("End of the cycle") # конец цикла
# [(0, -5), (1, 2), (2, 4), ...] что значит [(i0,value0),(i1,value1),...,(iN,valueN)]
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////







////////////////////
///АНАЛИЗ ТЕКСТА///
//////////////////
#Символы в верхнем и нижнем регистре будем считать одинаковыми, поэтому приведём текст в 
#нижний регистр и удалим все пробелы и символы переноса строки.

count = {}  # для подсчёта символов и их количества
for char in text:
   if char in count:  # если символ уже встречался, увеличиваем его количество на 1
       count[char] += 1
   else:
       count[char] = 1
	   
#Создаём переменную-счётчик в виде словаря, где по ключу будет храниться символ, 
#по значению — его количество. Далее с помощью цикла for посимвольно будем проходиться по обработанному тексту и считать символы:

for char, cnt in count.items():
   print(f"Symbol {char} can be found {cnt} times in the text") #символ {char} встречается в тексте {cnt} раз
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////







/////////////////////
///BREAK/CONTINUE///
///////////////////
#При встрече слова 
break
#цикл прекращается полностью

#При встрече слова 
continue
#цикл прекращает данный круг и переходит к следующему
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////







//////////////
///ФУНКЦИИ///
////////////

//Конструкция
def название функции(аргумент1, ..., аргументN, аргументПоУмолчанию1 = None, ..., *arg, **kwargs) #аргПоУмолч это int, floar, str, bool, None
    # Начало блока кода с телом функции
    pass 	#Дает понять итератору, что функция пока не написана, но объявлена
    ...		#Тут могут находиться переменные, условия, циклы, другие функции и т.д.
    ...
    # Конец блока кода с телом функции
	raise Ошибка("Сообщение об ошибке!") #Вызываем ошибку и прекращаем выполнение функции
	return аргумент1, ..., аргументN #возвращает аргумент(ты) после выполнения функции.

# Код, который будет выполняться после функции

//Учёт типов данных для ускоренного написания документации по функции
def random_predict(number:int=1) -> int:
'''
Обратите внимание, что в аргументах функции мы через двоеточие указываем тип данных для ввода (int), 
через равно — стандартное значение этого типа данных. Стрелка (->) указывает, какой тип данных мы должны 
получить на выходе. Это упростит заполнение документации, а также позволит в дальнейшем эффективнее работать с ошибками.
'''
//Пример
#Извлечение корня
def root(value, n=2):
   result = value ** (1/n)
   return result


/Порядковые аргументы *arg - кортеж. Неизвестное число агрументов
def mean(*numbers):
   result = sum(numbers) / len(numbers)
   return result
 
print(mean(5,4,4,3))
# Будет напечатано
# 4.0

/Именованные аргументы **kwargs - словарь
# В переменную kwargs будут записаны все
# именованные аргументы
def schedule(**kwargs):
   # kwargs — это словарь, проверим это с помощью isinstance:
   print(isinstance(kwargs, dict))
   # Напечатаем объект kwargs
   print(kwargs)
 
schedule(monday='Python', tuesday='SQL', friday='ML')
# Будет напечатано:
# True
# {'monday': 'Python', 'tuesday': 'SQL', 'friday': 'ML'}

//lambda-функции 
/Обычная функция
def root(num):
    # Напоминание: в Python используется оператор **
    # для возведения числа в степень.
    # В математике возведение в степень ½ соответствует
    # вычислению квадратного корня.
    return num ** (1/2)
	
/lambda
# Напоминание: оператор % используется для получения остатка
# от деления. Если остаток от деления на 2 равен 0, то
# число является чётным.
# Обратный слэш (\) используется в Python для того,
# чтобы перенести одну строку кода на следующую строку.
# Получается, что компьютер интерпретирует записанное ниже
# как одну строку.
is_even = lambda num: "even" if num % 2 == 0 \
    else "odd"

/Сортировка через lambda-функции
def sort_registry(registry):
    # Вместо pass напишите тело функции
    registry.sort(key=lambda x:
        (x[-1], x[-2], x[-3], x[0], x[1], x[2]))
    return registry

reg = [('Petrova', 'Maria', 'Ivanovna', 13, 3, 2003),
      ('Ivanov', 'Sergej', None, 24, 9, 1995),
      ('Smith', 'John', None, 13, 2, 2003)]
 
reg = sort_registry(reg)
print(reg)	
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////








////////////////////////////
///РАЗРЕШЕНИЕ ПЕРЕМЕННЫХ///
//////////////////////////
#Приоритет переменных
1
Локальные переменные (local) — это переменные, которые были объявлены в функции и используются непосредственно в ней.
local perermennaya = 5

2
Нелокальные переменные (nonlocal) — это переменные, которые были объявлены во внешней функции относительно 
рассматриваемой.
nonlocal perermennaya = 5

3
Глобальные переменные (global) — это переменные, которые были объявлены непосредственно в исходном коде основного скрипта.
global perermennaya = 5

4
Встроенные переменные (built-in) — это переменные и объекты, которые встроены в функционал Python изначально. 
Например, к ним относятся функции print, len, структуры данных list, dict, tuple и другие.
built-in perermennaya = 5

Таким образом, когда интерпретатор встречает в коде функции ссылку на какой-то объект, он начинает 
искать его среди локальных переменных, затем переключается на нелокальные, потом на глобальные и, 
наконец, ищет переменную среди встроенных объектов. Если поиск оказался безрезультатным, возникает ошибка.

→ Однако интерпретатор не всегда проходит весь этот путь самостоятельно. Ему необходимо показать, 
что та или иная переменная является глобальной или нелокальной, если в коде функции происходит 
изменение этой переменной.
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////







///////////////
///РЕКУРСИЯ///
/////////////
#Функция может вызывать саму себя. Это часто бывает удобно, но жертвуем быстродействием.

//Конструкция
def название функции(аргумент1, ..., аргументN, аргументПоУмолчанию1 = None, ..., *arg, **kwargs) #аргПоУмолч это int, floar, str, bool, None
    # Задаём условия выхода из рекурсии:
	if первое условие: return 1
    if n-е условие: return 1
	# Когда достигнуто конечное значение, функция начинает "схлапываться"
    pass 	#Дает понять итератору, что функция пока не написана, но объявлена
    ...		#Тут могут находиться переменные, условия, циклы, другие функции и т.д.
    ...
    # Конец блока кода с телом функции
	raise Ошибка("Сообщение об ошибке!") #Вызываем ошибку и прекращаем выполнение функции
	return название #функции Функция вызывает саму себя

# Код, который будет выполняться после функции

//Пример
#Факториал
def factorial(n):
   # Задаём условия выхода из рекурсии:
   if n==0: return 1
   if n==1: return 1
   # Во всех других случаях возвращаем
   # произведение текущего числа n и функции от n-1
   return factorial(n-1)*n
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////







////////////////
///ИТЕРАТОРЫ///
//////////////
#В Python из многих встроенных структур данных (списков, словарей, множеств) можно получать итераторы. 
#Происходит это с помощью функции 
iter().

//Пример
users = ['admin', 'guest', 'root', 'anonymous']
iter_users = iter(users)
 
for user in iter_users:
   print(user)
 
# Будет напечатано:
# admin
# guest
# root
# anonymous
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////







/////////////////
///ГЕНЕРАТОРЫ///
///////////////
#Похож на функцию, но вместо return в генераторе
#используется yield, который также возвращает значение, но также
#запоминает его, и в следующий раз с ним работает 

//Пример
def deposit(money, interest):
   # Процент по вкладу преобразуем во множитель:
   # делим процент на 100 и прибавляем 1
   interest = interest/100 + 1
   while True:
       # Сумма на вкладе через год — это
       # текущая сумма, домноженная на множитель и
       # округлённая до 2 знаков после запятой
       money = round(interest * money, 2)
       yield money
#Как видите, генератор использует ту же сигнатуру, что и функция.

#Будет объект функцией или генератором, определяется наличием оператора yield в коде. 
#Этот оператор также возвращает следующее за ним значение в исходный код основного скрипта, 
#однако интерпретатор запоминает место, на котором он завершил работу с генератором и возвращается 
#на то же место при повторном обращении к генератору. В случае с return повторное выполнение функции 
#произошло бы с самого начала. 

/Списочные сокрощения генераторов
#Создание генератора не как функции, а в одну строку

squares_generator = (x**2 for x in range(1, 11))
 
squares_list = list(squares_generator)
print(squares_list)
# Будет напечатано:
# [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






5.2
//////////////////////////
///ИТЕРАТОРЫ И ФУНКЦИИ///
////////////////////////
///ФУНКЦИЯ map()

//Конструкция
итератор = map(функция, указатель на итерируемый объект)

//Пример
#Вариант выполнения 1
names = ['Ivan', 'Nikita', 'Simon', 'Margarita', 'Vasilisa', 'Kim']
 
lens = []
 
for name in names:
   length = len(name)
   lens.append(length)
 
print(lens)
# [4, 6, 5, 9, 8, 3]

#Вариант выполнения 2
def get_length(word):
   return len(word)
lens = map(get_length, names)
# Проверим, что переменная lens — это объект типа map:
print(isinstance(lens, map))
# Будет напечатано:
# True
#Объект типа map можно использовать как обычный итератор, то есть применять к нему функцию next():

print(next(lens))
print(next(lens))
print(next(lens))
# Будет напечатано:
# 4
# 6
# 5

#Вариант выполнения 3
lens = list(map(lambda x: len(x), names))
print(lens)
# Будет напечатано:
# [4, 6, 5, 9, 8, 3]


///ФУНКЦИЯ filter()

//Конструкция
итератор = filter(функция(должна возвращать True, указатель на итерируемый объект)

//Пример
#Вариант выполнения 1
def is_even(num):
   if num % 2 == 0:
       return True
   return False
 
even = filter(is_even, [4, 6, 5, 9, 8, 3])
# Убедимся, что even — объект типа filter
print(isinstance(even, filter))
# Будет напечатано:
# True
Объект filter также является итератором. Сохраним все элементы из него в список и напечатаем этот список:

print(list(even))
# Будет напечатано:
# [4, 6, 8]

#Вариант выполнения 2
even = filter(lambda x: x % 2 == 0, [4, 6, 5, 9, 8, 3])
print(list(even))
# Будет напечатано:
# [4, 6, 8]


///Конвейер из map() и filter()

//Пример
#Вариант выполнения 1
names = ['Ivan', 'Nikita', 'Simon', 'Margarita', 'Vasilisa', 'Kim']
count_a = list()
for name in names:
   if len(name) >= 5:
       count_a.append((name, name.upper().count('А')))
print(count_a)
 
# Будет напечатано:
# [('Nikita', 1), ('Simon', 0), ('Margarita', 3), ('Vasilisa', 2)]

#Вариант выполнения 2
names = ['Ivan', 'Nikita', 'Simon', 'Margarita', 'Vasilisa', 'Kim']
# Отбираем имена из 5 и более букв
long_names = filter(lambda x: len(x) >= 5, names)
# Все отобранные имена переводим в верхний регистр и считаем число букв А в них
# Результат сохраняем в виде кортежа (имя, число букв "A")
count_a = map(lambda x: (x, x.upper().count('A')), long_names)
# Переводим объект map в list и печатаем его
print(list(count_a))
 
# Будет напечатано:
# [('Nikita', 1), ('Simon', 0), ('Margarita', 3), ('Vasilisa', 2)]


///ФУНКЦИЯ zip()

//Пример
surnames = ['Ivanov', 'Smirnov', 'Kuznetsova', 'Nikitina']
names = ['Sergej', 'Ivan', 'Maria', 'Elena']
for surname, name in zip(surnames, names):
  print(surname, name)
 
# Будет напечатано:
# Ivanov Sergej
# Smirnov Ivan
# Kuznetsova Maria
# Nikitina Elena
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






5.2
/////////////////
///ДЕКОРАТОРЫ///
///////////////
#Декораторы — это функции, которые изменяют поведение основной функции таким образом, 
#что она продолжает принимать и возвращать те же значения, однако её функционал расширяется.

//Пример
# Декорирующая функция принимает в качестве
# аргумента название функции
def simple_decorator(func):
 
   # Функция, в которой происходит модификация поведения
   # функции func. Она будет принимать те же аргументы,
   # что и функция func, которую декорирует decorated_function.
   # Чтобы принять все возможные аргументы, используем сочетание
   # *args и *kwargs.
   def decorated_function(*args, **kwargs):
       # Печатаем принятые аргументы
       print("Input:")
       print("Positional:", args)
       print("Named:", kwargs)
       # С помощью конструкции *args/**kwargs
       # считаем результат выполнения функции func
       result = func(*args, **kwargs)
       # Печатаем результат выполнения функции
       print("Result:", result)
       # Не забываем вернуть результат, чтобы
       # не повлиять на поведение декорируемой функции!
       return result
   # Внешняя функция возвращает функцию
   # decorated_function
   return decorated_function

//Сокращение
#В Python декораторы используются довольно часто. Они позволяют значительно упростить жизнь разработчику. 
#Чтобы применять декораторы было удобнее, используется запись названия декоратора через символ @ прямо над сигнатурой основной функции:

@simple_decorator
def root(value, n=2):
   result = value ** (1/n)
   return result

#Такая запись говорит интерпретатору о том, что необходимо применить функцию simple_decorator  к функции root. 
#При этом удобным оказывается то, что название самой декорированной функции от применения декоратора не меняется.

//time()
#Напишем более практичный декоратор. Он будет печатать время работы функции в секундах с помощью функции time() из модуля time:

# Из модуля time импортируем функцию time
from time import time
 
def time_decorator(func):
   def decorated_func(*args, **kwargs):
       # Получаем время на момент начала вычисления
       start = time()
       result = func(*args, **kwargs)
       # Получаем время на момент окончания вычисления
       end = time()
       # Считаем длительность вычисления
       delta = end - start
       # Печатаем время работы функции
       print("Runtime:", delta)
       return result
   return decorated_func
#Применим новый декоратор time_decorator к функции root и несколько раз посчитаем время вычислений:

@time_decorator
def root(value, n=2):
   result = value ** (1/n)
   return result
 
print(root(81))
print(root(81))
print(root(81))
print(root(81))
# Будет напечатано:
# Runtime: 1.9073486328125e-05
# 9.0
# Runtime: 5.245208740234375e-06
# 9.0
# Runtime: 3.814697265625e-06
# 9.0
# Runtime: 2.1457672119140625e-06
# 9.0
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






9.1
/////////////////////////
///Модуль Collections///
///////////////////////
Collections позволяет упростить написание кода при решении некоторых типовых задач, 
таких как подсчёт числа различных элементов или создание словаря для хранения в нём списков.

//Counter
#Счетчик числа различных данных
Давайте посмотрим, как используется счётчик. Вначале необходимо импортировать Counter из модуля collections, 
а затем создать пустой экземпляр этого объекта:
/
# Импортируем объект Counter из модуля collections
from collections import Counter
# Создаём пустой объект Counter
c = Counter()
#Теперь в переменной c хранится объект с возможностями Counter.

#Однако гораздо проще при создании Counter сразу передать в круглых скобках итерируемый объект, в котором необходимо посчитать значения:
c = Counter(cars)
print(c)
# Counter({'red': 3, 'black': 3, 'blue': 2, 'white': 1})

'''
Рассмотрим базовый синтаксис этого инструмента. Например, будем считать 
#цвета проезжающих машин: если встретили красную машину, посчитаем её. 
#Для этого прибавим к ключу 'red' единицу. Синтаксис очень похож на работу со словарём:
'''
c['red'] += 1
print(c)
# Будет напечатано:
# Counter({'red': 1})

'''
Узнать сумму всех значений в объекте Counter можно, воспользовавшись следующей конструкцией:
'''
print(sum(c.values()))
# 9

/Обработка списков
cars = ['red', 'blue', 'black', 'black', 'black', 'red', 'blue', 'red', 'white']

#Посчитать значения, конечно, можно и в цикле, используя синтаксис из предыдущего примера:
c = Counter()
for car in cars:
   c[car] += 1
 
print(c)
# Counter({'red': 3, 'black': 3, 'blue': 2, 'white': 1})




/Вычитание counter
print(counter_moscow)
print(counter_spb)
# Counter({'black': 4, 'yellow': 3, 'white': 2})
# Counter({'white': 3, 'red': 2, 'black': 2, 'yellow': 2})
 
counter_moscow.subtract(counter_spb)
print(counter_moscow)
# Counter({'black': 2, 'yellow': 1, 'white': -1, 'red': -2})

#Обычное вычитание приводит к другому результату
print(counter_moscow - counter_spb)
# Counter({'black': 2, 'yellow': 1})

/Получение всего списка ключей (элементы возвращаются в алфавитном порядке, а не в хронологии)
print(*counter_moscow.elements())
# black black black black white white yellow yellow yellow

/Чтобы получить список уникальных элементов, достаточно воспользоваться функцией list():
print(list(counter_moscow))
# ['black', 'white', 'yellow']

/С помощью метода dict() можно превратить Counter в обычный словарь:
print(dict(counter_moscow))
# {'black': 4, 'white': 2, 'yellow': 3}

/Метод most_common() позволяет получить список из кортежей элементов в порядке убывания их встречаемости:
print(counter_moscow.most_common())
# [('black', 4), ('yellow', 3), ('white', 2)]

#В неё также можно передать значение, которое задаёт желаемое число первых наиболее частых элементов, например, 2:
print(counter_moscow.most_common(2))
# [('black', 4), ('yellow', 3)]

/Метод clear() позволяет полностью обнулить счётчик:
counter_moscow.clear()
print(counter_moscow)
# Counter()


//defaultdict
#Словарь с заданным типом данных по умолчанию
from collections import defaultdict
groups = defaultdict(list)
#Обратите внимание, что в скобках мы передаём именно указатель на класс объекта (например list; также можно 
#было бы применить set, dict) без круглых скобок, которые используются для создания нового экземпляра объекта.

#Теперь тот же код, который вызывал ошибку при работе с обычным словарём, сработает так, как ожидается:

for student, group in students:
   groups[group].append(student)
 
print(groups)
# defaultdict(<class 'list'>, {1: ['Ivanov', 'Kuznetsova'], 4: ['Smirnov'], 3: ['Petrov', 'Markov'], 2: ['Nikitina', 'Pavlov']})
#В выводе есть небольшое отличие от обычного словаря: печатаются не только элементы словаря, 
#но и само название объекта defaultdict, а также класс объекта, который задан по умолчанию. 
#В данном случае это <class 'list'>. 

#Получить элемент из defaultdict по ключу можно так же, как и из обычного словаря:
print(groups[3])
# ['Petrov', 'Markov']

#Если запрашиваемого ключа нет в словаре, KeyError не возникнет. 
#Вместо этого будет напечатан пустой элемент, который создаётся в словаре по умолчанию:
print(groups[2021])
# []

#Теперь в словаре groups автоматически появился элемент 2021 с пустым списком внутри, 
#несмотря на то что мы его не создавали:
print(groups)
# defaultdict(<class 'list'>, {1: ['Ivanov', 'Kuznetsova'], 4: ['Smirnov'], 3: ['Petrov', 'Markov'], 2: ['Nikitina', 'Pavlov'], 2021: []})

#Итак, вы обратили внимание, что поведение defaultdict в коде отличается от обычного словаря dict. 
#Узнать, с каким именно словарём мы имеем дело в коде, можно с помощью встроенной функции type:

dict_object = dict()
defaultdict_object = defaultdict()
 
print(type(dict_object))
# <class 'dict'>
print(type(defaultdict_object))
# <class 'collections.defaultdict'>

/Примерэ
students = [('Ivanov',1),('Smirnov',4),('Petrov',3),('Kuznetsova',1),
            ('Nikitina',2),('Markov',3),('Pavlov',2)]

from collections import defaultdict
groups = defaultdict(list)

for student, group in students:
   groups[group].append(student)
 
print(groups)
# defaultdict(<class 'list'>, {1: ['Ivanov', 'Kuznetsova'], 4: ['Smirnov'], 3: ['Petrov', 'Markov'], 2: ['Nikitina', 'Pavlov']})

//deque ("дэк") Очереди и стеки
#Очередь - первым пришёл, первым ушёл
#Стек(рюкзак) - последним пришёл, первым ушёл
#Инструмент для работы с очередями элементов
'''
Можно сказать, что стек и очередь — это принципы обработки данных. deque позволяет 
обрабатывать данные обоими способами в зависимости от того, что требуется от разработчика. 
В каком порядке обрабатывать данные (FIFO или LIFO) вам подскажет собственная логика или более 
продвинутая теория алгоритмов, которая в данном модуле не изучается.
'''
from collections import deque
dq = deque()
print(dq)
# deque([])
/У deque есть четыре ключевые метода:
- append (добавить элемент в конец дека);
- appendleft (добавить элемент в начало дека);
- pop (удалить и вернуть элемент из конца дека);
- popleft (удалить и вернуть элемент из начала дека).

Также в очередь возможно добавить сразу несколько элементов из итерируемого объекта в дек. 
- extend (добавить в конец дека)
- extendleft (добавить в начало дека)

/ОЧЕРЕДЬ С ОГРАНИЧЕННОЙ МАКСИМАЛЬНОЙ ДЛИНОЙ
#При создании очереди можно также указать её максимальную длину с помощью параметра maxlen. Сделать это можно как при создании пустой очереди, так и при создании очереди от заданного итерируемого объекта:
limited = deque(maxlen=3)
print(limited)
# deque([], maxlen=3)
limited_from_list = deque([1,3,4,5,6,7], maxlen=3)
print(limited_from_list)
# deque([5, 6, 7], maxlen=3)

#Обратите внимание, что теперь дополнительно печатается максимальная длина очереди.
#Также заметьте, что в очереди с ограниченной длиной сохраняются только последние элементы, а первые исчезают из памяти:
limited.extend([1,2,3])
print(limited)
# deque([1, 2, 3], maxlen=3)
 print(limited.append(8))
# None
print(limited)
# deque([2, 3, 8], maxlen=3)
#При этом, как видно из результата операции limited.append(8), удаляемый элемент не возвращается, а просто исчезает.

/reverse позволяет поменять порядок элементов в очереди на обратный:
dq = deque([1,2,3,4,5])
print(dq)
# deque([1, 2, 3, 4, 5])
 
dq.reverse()
print(dq)
# deque([5, 4, 3, 2, 1])

/rotate переносит  заданных элементов из конца очереди в начало:
dq = deque([1,2,3,4,5])
print(dq)
# deque([1, 2, 3, 4, 5])
 dq.rotate(2)
print(dq)
# deque([4, 5, 1, 2, 3])

Элементы можно переносить и из начала в конец:
dq = deque([1,2,3,4,5])
print(dq)
# deque([1, 2, 3, 4, 5])
# Отрицательное значение аргумента переносит
# n элементов из начала в конец
dq.rotate(-2)
print(dq)
# deque([3, 4, 5, 1, 2])

/index позволяет найти первый индекс искомого элемента, а count позволяет подсчитать, сколько раз элемент встретился в очереди (функции аналогичны одноимённым функциям для списков):
dq = [1,2,4,2,3,1,5,4,4,4,4,4,3]
print(dq.index(4))
# 2
print(dq.count(4))
# 6

/clear позволяет очистить очередь:
dq = deque([1,2,4,2,3,1,5,4,4,4,4,4,3])
print(dq)
# deque([1, 2, 4, 2, 3, 1, 5, 4, 4, 4, 4, 4, 3])
dq.clear()
print(dq)
# deque([])

//OrderedDict нужен до версии питона 3.7
#Словарь, который гарантирует сохранение порядка добавления ключей в нём
from collections import OrderedDict
data = [('Ivan', 19),('Mark', 25),('Andrey', 23),('Maria', 20)]
ordered_client_ages = OrderedDict(data)
print(ordered_client_ages)
# По результатам 3 повторов получились вот такие результаты:
# OrderedDict([('Ivan', 19), ('Mark', 25), ('Andrey', 23), ('Maria', 20)])
# OrderedDict([('Ivan', 19), ('Mark', 25), ('Andrey', 23), ('Maria', 20)])
# OrderedDict([('Ivan', 19), ('Mark', 25), ('Andrey', 23), ('Maria', 20)])

#Можно, например, отсортировать с помощью функции sorted список кортежей при создании из него OrderedDict, 
#и объекты будут добавлены в порядке сортировки:
#sorted(iterable,key=None,reverse=False)
data = [('Ivan', 19),('Mark', 25),('Andrey', 23),('Maria', 20)]
# Сортируем по второму значению из кортежа, то есть по возрасту
ordered_client_ages = OrderedDict(sorted(data, key=lambda x: x[1]), reverse=False)
print(ordered_client_ages)
# OrderedDict([('Ivan', 19), ('Maria', 20), ('Andrey', 23), ('Mark', 25)])
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






9.5
////////////
///NumPy///
//////////
import numpy as np
Могла возникнуть ошибка:

ModuleNotFoundError: No module named 'numpy'
Это означает, что модуль NumPy пока не установлен. Чтобы его установить, необходимо выполнить следующую команду в командной строке (для установки библиотеки через встроенный в Anaconda менеджер пакетов conda):

conda install numpy
Если вдруг вы окажетесь за компьютером, где есть только Python, но нет Anaconda, библиотеку NumPy можно установить через стандартный для Python менеджер пакетов — pip:

pip install numpy

//ОСОБЕННОСТИ
в NumPy int по умолчанию становится int64, если не указано иное количество выделенной памяти.

print(*sorted(map(str, set(np.sctypeDict.values()))), sep='\n')
Всего в выдаче будет 24 строки. Int, uint и float мы уже изучили. 
Datetime и timedelta используются для хранения времени, complex используется для работы с комплéксными числами.

/Узнать границы
# Можно применить к самому
# названию типа данных
np.iinfo(np.int8)
# iinfo(min=-128, max=127, dtype=int8)

# Можно применить к существующему
# конкретному объекту
np.iinfo(a)
# iinfo(min=-128, max=127, dtype=int8)

/Небольшое замечание про bool: несмотря на то что для хранения значения истина/ложь было бы достаточно только 
одного бита, из-за особенностей работы с памятью компьютера булевая переменная всё равно занимает в памяти целый байт.

//ЦЕЛОЧИСЛЕННЫЕ ТИПЫ ДАННЫХ В NUMPY
Это тип данных с общим корнем int. Int может быть со следующими окончаниями: int8, int16, int32 и int64. Окончание типа данных в NumPy показывает, сколько битов памяти должно быть выделено для хранения переменной.

Преобразуем обычное целое число в NumPy-тип, например в int8. Для этого напишем выражение np.int8 и круглые скобки. В круглых скобках в качестве аргумента передадим тот объект, который должен быть преобразован:

import numpy as np
a = np.int8(25)
print(a)
# 25
print(type(a))
# <class 'numpy.int8'>

/Узнать границы
# Можно применить к самому
# названию типа данных
np.iinfo(np.int8)
# iinfo(min=-128, max=127, dtype=int8)

# Можно применить к существующему
# конкретному объекту
np.iinfo(a)
# iinfo(min=-128, max=127, dtype=int8)

Доступны следующие типы данных int: 
int8, int16, int32, int64 (применяется по умолчанию, если объём памяти не задан дополнительно).
np.iinfo(np.int8)
# min = -128 max = 127
np.iinfo(np.int16)
# min = -32768 max = 32767
np.iinfo(np.int32)
# min = -2147483648 max = 2147483647
np.iinfo(np.int64)
# min = -9223372036854775808 max = 9223372036854775807

//БЕЗЗНАКОВЫЕ ЦЕЛОЧИСЛЕННЫЕ ТИПЫ ДАННЫХ В NUMPY
В NumPy доступны и беззнаковые целочисленные типы данных. Они имеют корень uint (unsigned int — беззнаковое целое). 
uint доступны также с выделением памяти в 8, 16, 32 и 64 бита. При этом максимально возможное число оказывается в 
два раза больше, чем для соответствующего int, поскольку отрицательные числа исключены из типа данных uint.
b = np.uint8(124)
print(b)
# 124
print(type(b))
# <class 'numpy.uint8'>
np.iinfo(b)
# iinfo(min=0, max=255, dtype=uint8)

//ТИПЫ ДАННЫХ С ПЛАВАЮЩЕЙ ТОЧКОЙ В NUMPY
Беззнаковых float нет.
Доступны следующие типы данных float: 
float16, float32, float64 (применяется по умолчанию, если объём памяти не задан дополнительно), float128.
np.finfo(np.float16)
# finfo(resolution=0.001, min=-6.55040e+04, max=6.55040e+04, dtype=float16)
np.finfo(np.float32)
# finfo(resolution=1e-06, min=-3.4028235e+38, max=3.4028235e+38, dtype=float32)
np.finfo(np.float64)
# finfo(resolution=1e-15, min=-1.7976931348623157e+308, max=1.7976931348623157e+308, dtype=float64)
np.finfo(np.float128)
# finfo(resolution=1e-18, min=-1.189731495357231765e+4932, max=1.189731495357231765e+4932, dtype=float128)

//bool_ and str_
Следует обратить внимание на типы данных bool_ и str_. Они аналогичны bool и str из встроенных в Python, 
однако записывать их необходимо именно с нижним подчёркиванием, иначе произойдёт приведение к стандартному 
типу данных, а не типу NumPy. В целом, существенной разницы между этими типами данных нет, однако о такой
 двойственности следует помнить при сравнении типов переменных: тип bool не является эквивалентным numpy.bool_, 
 несмотря на то что оба типа данных хранят значения True или False.

Пример с bool:
a = True
print(type(a))
# <class 'bool'>
a = np.bool(a)
print(type(a))
# <class 'bool'>
a = np.bool_(a)
print(type(a))
# <class 'numpy.bool_'>
 
# Значения равны
print(np.bool(True) == np.bool_(True))
# True
# А типы — нет:
print(type(np.bool(True)) == type(np.bool_(True)))
# False

Пример со str:
a = "Hello world!"
print(type(a))
# <class 'str'>
a = np.str(a)
print(type(a))
# <class 'str'>
a = np.str_(a)
print(type(a))
# <class 'numpy.str_'>

//МАССИВЫ
#Итак, массив — это структура данных, в которой:
1 Элементы хранятся в указанном порядке.
2 Каждый элемент можно получить по индексу за одинаковое время.
3 Все элементы приведены к одному и тому же типу данных.
4 Максимальное число элементов и объём выделенной памяти заданы заранее.
#3x5 — у этой таблицы две размерности: 3 строки и 5 столбцов.

/СОЗДАНИЕ МАССИВА ИЗ СПИСКА
Создать массив из списка можно с помощью функции np.array(<объект>):
import numpy as np
arr = np.array([1,5,2,9,10])
arr
# array([ 1,  5,  2,  9, 10])
Функция np.array возвращает объекты типа numpy.ndarray:
print(type(arr))
# <class 'numpy.ndarray'>

/Давайте теперь создадим двумерный массив из списка списков. 
Его также можно назвать таблицей чисел или матрицей. Сделаем это с помощью той же функции np.array():

# Перечислить список из списков можно
# было и в одну строку, но на нескольких
# строках получается нагляднее
nd_arr = np.array([
               [12, 45, 78],
               [34, 56, 13],
               [12, 98, 76]
               ])
nd_arr
# array([[12, 45, 78],
#        [34, 56, 13],
#        [12, 98, 76]])


/ТИПЫ ДАННЫХ В МАССИВЕ

Мы только что узнали, что массив — это набор однотипных данных, но не указали никакой тип. Какого типа данные хранятся теперь в массиве arr? Узнать это можно, напечатав свойство dtype:

arr = np.array([1,5,2,9,10])
arr.dtype
# dtype('int64')

#Задать тип данных сразу при создании массива можно с помощью параметра dtype:
arr = np.array([1,5,2,9,10], dtype=np.int8)
arr
# array([ 1,  5,  2,  9, 10], dtype=int8)

#Поменять тип данных во всём массиве можно с помощью тех же функций, 
#которыми мы пользовались для преобразования типов отдельных переменных в предыдущем юните (например, np.int32 или np.float128):
arr = np.float128(arr)
arr
# array([ 1.,  5., 12.,  9., 10.], dtype=float128)

//Свойства массивов
print(array.dtype) #Узнать тип данных массива
print(array.ndim) #Узнать размерность массива
print(array.size) #Узнать общее число элементов массива
print(array.shape) #Форма или структура массива (6, 5, 7) - оси массива
print(array.itemsize) #Узнать сколько весит элемент массива
array = np.sort(mystery) #Сортировка массива
/Пустой массиваСоздадим одномерный массив из пяти элементов:
zeros_1d = np.zeros(5)
zeros_1d
# array([0., 0., 0., 0., 0.])

Создадим трёхмерный массив с формой 5x4x3 и типом float32:
zeros_3d = np.zeros((5,4,3), dtype=np.float32)
print(zeros_3d.shape)
# (5, 4, 3)

/задание массивов
#Ещё одной удобной функцией для создания одномерных массивов является arange. 
#Она аналогична встроенной функции range, но обладает рядом особенностей. 
#Вот её сигнатура: 

arange([start,] stop[, step,], dtype=None)

Аргументы start (по умолчанию 0), step (по умолчанию 1) и dtype (определяется автоматически) являются необязательными:
start (входит в диапазон возвращаемых значений) задаёт начальное число;
stop (не входит в диапазон возвращаемых значений, как и при использовании range) задаёт правую границу диапазона;
step задаёт шаг, с которым в массив добавляются новые значения.
В отличие от range, в функции arange все перечисленные параметры могут иметь тип float.
sample = np.arange(1, 101)
#[1,2,3....,99,100]


/На самом деле операции с плавающей точкой не всегда бывают предсказуемыми из-за особенностей хранения таких чисел в памяти компьютера. Поэтому для работы с дробными параметрами start, stop и step лучше использовать функцию linspace (англ. linear space — линейное пространство). Она тоже возвращает одномерный массив из чисел, расположенных на равном удалении друг от друга между началом и концом диапазона, но обладает немного другим поведением и сигнатурой:

np.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)

start и stop являются обязательными параметрами, задающими начало и конец возвращаемого диапазона;
num — параметр, задающий число элементов, которое должно оказаться в массиве (по умолчанию 50);
endpoint — включён или исключён конец диапазона (по умолчанию включён);
dtype — уже хорошо знакомый нам параметр, задающий тип данных (если не задан, определяется автоматически);
retstep (по умолчанию False) позволяет указать, возвращать ли использованный шаг между значениями, помимо самого массива.
Давайте потренируемся. Создадим массив из десяти чисел между 1 и 2:

arr = np.linspace(1, 2, 10)
arr
# array([1.        , 1.11111111, 1.22222222, 1.33333333, 1.44444444,
#        1.55555556, 1.66666667, 1.77777778, 1.88888889, 2.        ])

Узнаем, какой шаг был использован для создания массива из десяти чисел между 1 и 2, где 2 включалось и не включалось:

arr, step = np.linspace(1, 2, 10, endpoint=True, retstep=True)
print(step)
# 0.1111111111111111

arr, step = np.linspace(1, 2, 10, endpoint=False, retstep=True)
print(step)
# 0.1

//ДЕЙСТВИЯ С МАССИВАМИ
/ИЗМЕНЕНИЕ ФОРМЫ МАССИВА
Создадим массив из восьми чисел:
import numpy as np
arr = np.arange(8)
arr
# array([0, 1, 2, 3, 4, 5, 6, 7])

Поменять форму массива arr можно с помощью присвоения атрибуту shape кортежа с желаемой формой:
arr.shape = (2, 4) #.reshape((2, 4)) - не меняет массив, а создает новый
arr
# array([[0, 1, 2, 3],
#        [4, 5, 6, 7]])

'''
У функции reshape есть дополнительный именованный аргумент order. 
Он задаёт принцип, по которому элементы заполняют массив новой формы. 
Если order='C' (по умолчанию), массив заполняется по строкам, как в примере выше. 
Если order='F', массив заполняется числами по столбцам:'''
arr = np.arange(8)
arr_new = arr.reshape((2, 4), order='F')
arr_new
# array([[0, 2, 4, 6],
#       [1, 3, 5, 7]])

#Ещё одной часто используемой операцией с формой массива (особенно двумерного) является транспонирование. 
Эта операция меняет строки и столбцы массива местами. В NumPy эту операцию совершает функция transpose.
Будем работать с двумерным массивом:
arr = np.arange(8)
arr.shape = (2, 4)
arr
# array([[0, 1, 2, 3],
#        [4, 5, 6, 7]])

Транспонируем его:
arr_trans = arr.transpose()
arr_trans
# array([[0, 4],
#        [1, 5],
#        [2, 6],
#        [3, 7]])

/ИНДЕКСЫ И СРЕЗЫ В МАССИВАХ
array[0][1] == array[0, 1] - в массивах удобнее обращаться к элементам
можно и срезами array[2:4, 5]

/СОРТИРОВКА МАССИВОВ
#Способ 1. Функция np.sort(<массив>) возвращает новый отсортированный массив:
arr = np.array([23,12,45,12,23,4,15,3])
arr_new = np.sort(arr)
print(arr)
# [23 12 45 12 23  4 15  3]
print(arr_new)
# [ 3  4 12 12 15 23 23 45]

#Способ 2. Функция <массив>.sort() сортирует исходный массив и возвращает None:
arr = np.array([23,12,45,12,23,4,15,3])
print(arr.sort())
# None
print(arr)
# [ 3  4 12 12 15 23 23 45]

//РАБОТА С ПРОПУЩЕННЫМИ ДАННЫМИ
Отличие 1. None является отдельным объектом типа NoneType. np.nan — это отдельный представитель класса float:
print(type(None))
# <class 'NoneType'>
print(type(np.nan))
# <class 'float'>
type(np.nan)

Отличие 2. None могут быть равны друг другу, а np.nan — нет:
print(None == None)
# True
print(np.nan == np.nan)
# False
Как вы помните, чтобы грамотно сравнить что-либо с None, необходимо использовать оператор is. 
Это ещё более актуально для np.nan. Однако None даже через is не является эквивалентным np.nan:
print(None is None)
# True
print(np.nan is np.nan)
# True
print(np.nan is None)
# False

/ОБХОД ПРОПУЩЕННЫХ ДАННЫХ
np.isnan(roots)
# array([False, False,  True, False])
roots[np.isnan(roots)] = 0
roots
# array([2.        , 3.        , 0.        , 1.73205081])

//ВЕКТОРЫ В NUMPY И АРИФМЕТИКА
#Вектор - одномерный массив
/Арифметика - для векторов одинаковой длины
import numpy as np
vec1 = np.array([2, 4, 7, 2.5])
vec2 = np.array([12, 6, 3.6, 13])
print(vec1 + vec2)          #сложение
#[14. , 10. , 10.6, 15.5]
print(vec1 - vec2)          #вычитание
#[-10.   -2.    3.4 -10.5]
print(vec1 * vec2)          #поэлементное умножение
#[ 24.   24.   25.2  32.5]
print(vec1 * 2)             #умножение на число
#[  4.   8.  14.   5.]
print(vec1 > vec2)          #логические операции
#[False False  True False]
print(vec1 < 4)             #сравнения
[ True False False  True]

#Длина вектора 						\[length = \sqrt{x_{1}^{2} + x_{2}^{2} + ... + x_{n}^{2}}\]
vec = np.array([3, 4])
print(vec)
#[3 4]
length = np.sqrt(np.sum(vec ** 2))  
print(length)
# 5.0

#длина вектора с помощью подмодуля linalg
length = np.linalg.norm(vec)        
print(length)
# 5.0

#Расстояние м/ж векторами 			\[distance = \sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + ... + (x_n - y_n)^2}\]
vec1 = np.array([0, 3, 5])
vec2 = np.array([12, 4, 7])
distance = np.linalg.norm(vec1 - vec2)
distance
# 12.206555615733702

#Скалярное произведение векторов 	\[X * Y = x_1 * y_1 + x_2 * y_2 + ... + x_n * y_n\]
#Равенство скалярного произведения нулю означает перпендикулярность рассматриваемых векторов
scalar_product = np.dot(vec1, vec2)
scalar_product
# 250.0

/БАЗОВЫЕ СТАТИСТИЧЕСКИЕ ФУНКЦИИ ДЛЯ ВЕКТОРОВ
vec = np.array([2,7,18,28,18,1,8,4])
vec.min() или min(vec)			#минимаьное
# 1
vec.max() или max(vec)			#максимальное
# 28
vec.mean()			#среднее значение
# 10.75
np.median(vec)		#Среднее медианное
# 7.5
np.std(vec)
# 8.95474734429		#Стандартное отклонение

//СЛУЧАЙНЫЕ ЧИСЛА
/ПОДМОДУЛЬ random_matri
import numpy as np
np.random.rand()
# 0.06600758835806675
Например, получим массив из пяти случайных чисел:
np.random.rand(5)
# array([0.83745099, 0.58426808, 0.89206204, 0.41149807, 0.42445145])

Массив из двух случайных строк и трёх столбцов:
np.random.rand(2, 3)
# array([[0.94931212, 0.06680018, 0.26707599],
#      [0.67908873, 0.18001743, 0.97732239]])

В NumPy есть и другая функция, генерирующая массивы случайных чисел от 0 до 1, 
которая принимает в качестве аргумента именно кортеж без распаковки. Она называется sample:
shape = (2, 3)
np.random.sample(shape)
# array([[0.39756103, 0.01995168, 0.2768951 ],
#       [0.82195372, 0.26435273, 0.00957881]])
Возможно, именно функция sample покажется вам удобнее, поскольку информацию о форме 
массива обычно удобнее хранить в коде в виде кортежа и не задумываться потом о его распаковке. 
В остальном функция sample не отличается от rand.

/Задание чисел по диапазонам
uniform(low=0.0, high=1.0, size=None)
Первые два аргумента — нижняя и верхняя границы диапазона в формате float, третий опциональный аргумент — форма массива 
(если не задан, возвращается одно число). 
Форма массива задаётся кортежем или одним числом.

Давайте поэкспериментируем ↓
Запуск без аргументов эквивалентен работе функций rand или sample:
np.random.uniform()
# 0.951557685543591

Зададим границы диапазона от -30 до 50:
np.random.uniform(-30, 50)
# 38.47365525953661

Получим пять чисел в интервале от 0.5 до 0.75:
np.random.uniform(0.5, 0.75, size=5)
# array([0.58078945, 0.58860342, 0.73790553, 0.63448265, 0.70920297])

Получим массив из двух строк и трёх столбцов из чисел в интервале от -1000 до 500:
np.random.uniform(-1000, 500, size=(2, 3))
# array([[ 129.22164163,   77.69090611, -132.9656972 ],
#        [  18.65802226, -317.14793906,   85.3613547 ]])

/ГЕНЕРАЦИЯ INT

Не всегда требуется генерировать числа с плавающей точкой. 
Иногда бывает удобно получить целые числа int (например, для поля игры в лото). 
Для генерации целых чисел используется функция random.randint:

randint(low, high=None, size=None, dtype=int)

Функцию randint нельзя запустить совсем без параметров, необходимо указать хотя бы одно число.
#Если указан только аргумент low, числа будут генерироваться от 0 до low-1, то есть верхняя граница не включается.
#Если задать low и high, числа будут генерироваться от low (включительно) до high (не включительно).
#size задаёт форму массива уже привычным для вас образом: одним числом — для одномерного или кортежем — для многомерного.
#dtype позволяет задать конкретный тип данных, который должен быть использован в массиве.

np.random.randint(6, 12, size=(3,3))
# array([[ 9,  6, 10],
#        [10, 11, 10],
#        [ 7, 10, 11]])

/ГЕНЕРАЦИЯ ВЫБОРОК
Просто перемешать все числа в массиве позволяет функция random.shuffle.
arr = np.arange(6)
print(arr)
# [0 1 2 3 4 5]
print(np.random.shuffle(arr))
# None
arr
# array([0, 5, 1, 3, 2, 4])

Функция random.shuffle перемешивает тот массив, к которому применяется, и возвращает None.

→Чтобы получить новый перемешанный массив, а исходный оставить без изменений, можно использовать функцию random.permutation. 
Она принимает на вход один аргумент — или массив целиком, или одно число:
playlist = ["The Beatles", "Pink Floyd", "ACDC", "Deep Purple"]
shuffled = np.random.permutation(playlist)
print(shuffled)
# ['The Beatles' 'Pink Floyd' 'Deep Purple' 'ACDC']
print(playlist)
# ['The Beatles', 'Pink Floyd', 'ACDC', 'Deep Purple']
Обратите внимание, что необязательно передавать в функцию сразу массив: 
в этот раз мы передали в качестве аргумента список и ошибки не возникло. 
При этом на выходе получился уже NumPy-массив (это заметно по отсутствию запятых при печати массива). 
Сам список playlist при этом остался без изменений.
Можно генерить массивы
np.random.permutation(10)
# array([7, 8, 2, 9, 4, 3, 1, 0, 5, 6])

Чтобы получить случайный набор объектов из массива, используется функция random.choice:
np.random.choice(a, size=None, replace=True)
#a — массив или число для генерации arange(a);
#size — желаемая форма массива (число для получения одномерного массива, кортеж — для многомерного; если параметр не задан, возвращается один объект);
#replace — параметр, задающий, могут ли элементы повторяться (по умолчанию могут).

workers = ['Ivan', 'Nikita', 'Maria', 'John', 'Kate']
choice = np.random.choice(workers, size=2, replace=False)
print(choice)

/SEED ГЕНЕРАТОРА ПСЕВДОСЛУЧАЙНЫХ ЧИСЕЛ
seed - зерно. Это то, на основе чего работает генератор случайных чисел
По умолчанию оно берется само компьютером.
Самостоятельно задать seed в NumPy можно с помощью функции np.random.seed(<np.uint32>). 
Число в скобках должно быть в пределах от 0 до 2**32 - 1 (=4294967295).
Зададим seed и посмотрим, что получится:
np.random.seed(23)
np.random.randint(10, size=(3,4))
# array([[3, 6, 8, 9],
#        [6, 8, 7, 9],
#        [3, 6, 1, 2]])









/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






10.1
/////////////
///PANDAS///
///////////
#→ Pandas является наиболее продвинутой и быстроразвивающейся библиотекой для анализа данных и их предобработки.
#«Анализ данных начинается с импорта Pandas»
Установка
pip install pandas

Импорт
import pandas as pd
pd.__version__ 			#Проверка
'1.0.5'

//SERIES
pandas.Series (серия, ряд).
Series — это упорядоченная изменяемая коллекция объектов, имеющая так называемые ассоциативные метки (индексы). 
→ Series в какой-то степени является единицей хранения информации в Pandas. 
Её можно рассматривать как именованный столбец таблицы с индексами строк.

/СОЗДАНИЕ SERIES
Способ 1 — из списка с использованием параметров функции pd.Series():
countries = pd.Series(
    data = ['Англия', 'Канада', 'США', 'Россия', 'Украина', 'Беларусь', 'Казахстан'],
    index = ['UK', 'CA', 'US', 'RU', 'UA', 'BY', 'KZ'],
    name = 'countries'
)
display(countries)
'''
UK       Англия
CA       Канада
US          США
RU       Россия
UA      Украина
BY     Беларусь
KZ    Казахстан
Name: countries, dtype: object
'''

Способ 2 — из словаря, в котором ключами являются будущие метки, а значениями — 
будущие значения Series, при этом использование параметра name также возможно:
countries = pd.Series({
    'UK': 'Англия',
    'CA': 'Канада',
    'US' : 'США',
    'RU': 'Россия',
    'UA': 'Украина',
    'BY': 'Беларусь',
    'KZ': 'Казахстан'},
    name = 'countries'
)
display(countries)
'''
UK       Англия
CA       Канада
US          США
RU       Россия
UA      Украина
BY     Беларусь
KZ    Казахстан
Name: countries, dtype: object
'''

/ДОСТУП К ДАННЫМ В SERIES (.loc[] and .iloc[])
print(countries.loc['US']) #Доступ по индексу
# Можно и через print(countries['US'])
# США
print(countries.iloc[6])	#Доступ по номеру индекса (с 0)
# Можно и через print(countries[6])
# Казахстан
loc[::10, ['Distance', 'Price']]#вывод каждого 10 значения таблицы

Для мультиидексных таблиц
# Создадим таблицы с ежедневными данными для групп A и B, 
# для удобства дальнейшего обращения к ним
days_A = days_A_B.xs('A', level='group')
Здесь мы выбрали все данные, где в индексе 'group' стоит А

//DATAFRAME = ТАБЛИЦА
Примечание. В дальнейшем слова DataFrame и таблица будут употребляться как синонимы. 
Также синонимами в Data Science являются слова ПРИЗНАК и СТОЛБЕЦ таблицы.

/СОЗДАНИЕ DATAFRAME
	A	B
0	0	1
1	1	0


СПОСОБ 1
Самый простой способ создания DataFrame — из словаря, ключами которого являются имена 
столбцов будущей таблицы, а значениями — списки, в которых хранится содержимое этих столбцов:
pd.DataFrame({'А': [0, 1], 'B': [1, 0]})

countries_df = pd.DataFrame({
    'country': ['Англия', 'Канада', 'США', 'Россия', 'Украина', 'Беларусь', 'Казахстан'],
    'population': [56.29, 38.05, 322.28, 146.24, 45.5, 9.5, 17.04],
    'square': [133396, 9984670, 9826630, 17125191, 603628, 207600, 2724902]
},
	index = ['UK', 'CA', 'US', 'RU', 'UA', 'BY', 'KZ']
)
display(countries_df)

СПОСОБ 2
Также DataFrame можно создать из вложенного списка, внутренние списки которого будут являться строками новой таблицы:
pd.DataFrame([[0,1], [1, 0]], columns=['А', 'B'])

countries_df = pd.DataFrame(
    data = [
        ['Англия', 56.29, 133396],
        ['Канада', 38.05, 9984670],
        ['США', 322.28, 9826630],
        ['Россия', 146.24, 17125191],
        ['Украина', 45.5, 603628],
        ['Беларусь', 9.5, 207600],
        ['Казахстан', 17.04, 2724902]
    ],
    columns= ['country', 'population', 'square'],
    index = ['UK', 'CA', 'US', 'RU', 'UA', 'BY', 'KZ']
)
display(countries_df)
#		columns 
#index	data
В данном варианте создания DataFrame мы задаём имена столбцов в списке с помощью параметра columns, 
а также инициализируем параметр index для задания меток стран.

/AXIS В DATAFRAME
Так как можно работать и со строками, и со столбцами
используют оси (asix)
asix = 0 #строки
asix = 1 #столбцы

/ОБРАЩЕНИЕ К ЭЛЕМЕНТАМ DATAFRAME
countries_df.population 	#По имени столбца
countries_df['population']	#По индексу

//ЗАПИСЬ В CSV-ФАЙЛ
countries_df.to_csv('C:\Python\countries.csv', sep=';', decimal='.', index=True, ...)
path_or_buf — путь до файла, в который будет записан DataFrame (например, data/my_data.csv);
sep(seporator) — разделитель данных в выходном файле (по умолчанию ',');
decimal — разделитель чисел на целую и дробную части в выходном файле (по умолчанию '.');
columns — список столбцов, которые нужно записать в файл (по умолчанию записываются все столбцы);
index — параметр, определяющий, требуется ли создавать дополнительный столбец с индексами строк 
в файле (по умолчанию True).

//ЧТЕНИЕ CSV-ФАЙЛА
countries_data = pd.read_csv('C:\Python\countries.csv', sep=';', decimal='.', skiprows = 20)
ufo_data = pd.read_csv('C:\\Python\\ufo.csv', sep=',') #Удвоение обратной черты используется
    #для обхода ошибок связанных с неверным чтением команд \n,\u...
filepath_or_buffer — путь до файла, который мы читаем;
sep(seporator) — разделитель данных (по умолчанию ',');
decimal — разделитель чисел на целую и дробную часть в выходном файле (по умолчанию '.');
names — список с названиями столбцов для чтения;
skiprows — количество строк в файле, которые нужно пропустить (например, файл может содержать 
служебную информацию, которая нам не нужна).

//ЗАПИСЬ И ЧТЕНИЕ В ДРУГИХ ФОРМАТАХ
/Методы для записи таблиц в файлы отличных от csv форматов:
to_excel() — запись DataFrame в формат Excel-таблицы (.xslx);
to_json() — запись DataFrame в формат JSON (.json);
to_xml() — запись DataFrame в формат XML-документа (.xml);
to_sql() — запись DataFrame в базу данных SQL (для реализации этого метода 
необходимо установить соединение с базой данных).
.
/Методы для чтения таблиц из файлов в отличных от csv форматах:
read_excel() — чтение из формата Excel-таблицы(.xslx) в DataFrame;
read_json() — чтение из формата JSON (.json) в DataFrame;
read_xml() — чтение из формата XML-документа (.xml) в DataFrame;
read_sql() — чтение из базы данных SQL в DataFrame (также необходимо установить соединение с базой данных).

//ВЫВОД N-го ЧИСЛА СТРОК (по умолчанию 5)
display(melb_data.head(n))  #Вывод n первых строк
display(melb_data.tail(n))  #Вывод n послежних строк
display(melb_data.shape)    #Вывод размерности

//РАБОТА С ТАБЛИЦЕЙ
/Получение информации о столбцах
display(melb_data.info())

/Получение описательной статистики столбцов
display(melb_data.describe())

/Преобразование типа данных столбца
melb_data['Postcode'] = melb_data['Postcode'].astype('int64') 

//ПОЛУЧЕНИЕ ОПИСАТЕЛЬНОЙ СТАТИСТИКИ
'''По умолчанию метод работает с числовыми (int64 и float64) столбцами и показывает число непустых 
значений (count), среднее (mean), стандартное отклонение (std), минимальное значение (min),  
квартили уровней 0.25, 0.5 (медиана) и 0.75 (25%, 50%, 75%) и максимальное значение (max) для 
каждого столбца исходной таблицы.'''
melb_data.describe().loc[:, ['Distance', 'BuildingArea' , 'Price']] #Для числовых значений
melb_data.describe(include=['object']) #Для других значеий

        Unnamed: 0	    points	        price	        price_round	    
count	129971.000000	129971.000000	129971.000000	129971.000000	
mean	64985.000000	88.447138	    35.363389	    35.338237	    
std	    37519.540256	3.039730	    39.577066	    39.577174	    
min	    0.000000	    80.000000	    4.000000	    4.000000	    
25%	    32492.500000	86.000000	    18.000000	    18.000000	    
50%	    64985.000000	88.000000	    28.000000	    28.000000	    
75%	    97477.500000	91.000000	    40.000000	    40.000000	    
max	    129970.000000	100.000000	    3300.000000	    3300.000000	    

data['priznak'].value_counts() - получение чатсоты встречаемых значений
data['priznak'].value_counts(normalize=True) - получение частоты в относительных значениях (долях)(%)
data['priznak'].nlargest(10) - получение 10 самых популярных значений признака


//АГРЕГИРУЮЩИЕ МЕТОДЫ
Агрегирующим в Pandas называется метод, который для каждого столбца возвращает только одно 
значение — показатель (например, вычисление медианы, максимума, среднего и так далее).
Параметры методов:
axis  — определяет, подсчитывать параметр по строкам или по столбцам;
numeric_only — определяет, вычислять параметры только по числовым столбцам/строкам или нет (True/False).

.count()    	#Количество непустых значений
.mean()	        #Среднее значение
.median()       #Медиана (среднее)
.min()	        #Минимальное значение
.max()	        #Максимальное значение
.deviance()	    #Дисперсия
.std()	        #Стандартное отклонение
.sum()	        #Сумма
.quantile(x)	#Квантиль уровня x
.nunique()	    #Число уникальных значений
.mode()         #Мода - самое распрастраненное значение (может возвращать несколько)
.describe()     #Показывает распределение характерирстик признака (как график box)


//ФИЛЬТРАЦИЯ ДАННЫХ В DATAFRAME
Под фильтрацией в DataFrame подразумевается получение новой таблицы путём вырезания строк, 
не удовлетворяющих поставленному условию. 
Маской называется Series, которая состоит из булевых значений, при этом значения 
True соответствуют тем индексам, для которых заданное условие выполняется, в противном случае ставится значение 
False (например, цена > 2 млн).
mask = melb_data['Price'] > 2000000     #Задание маски
melb_data[mask]                         #Применение маски
или
melb_data[melb_data['Price'] > 2000000] #Можно задать условие сразу
Можно объединять условия, но нельзя использовать 'and' и 'or', а нужно '&' и '|' - поэлементную логику.
melb_data[((melb_data['Rooms'] == 3) | (melb_data['BuildingArea'] > 100)) & (melb_data['Price'] < 300000)].shape[0]
Можно объединять условия и методы
mean_price = melb_data['Price'].mean()
melb_data[melb_data['Price'] > mean_price]['BuildingArea'].median()
Можно улучшать читаемость с помощью переменных
mask1 = (melb_data['Rooms'] == 3)
mask2 = (melb_data['BuildingArea'] > 100)
mask3 = (melb_data['Price'] < 300000)
melb_data[(mask1 | mask2) & mask3].shape[0]

popular_stypes =street_types.value_counts().nlargest(10).index
    #nlargest(n) - возвращяет n самых популярных элементов
print(popular_stypes)
# Index(['St', 'Rd', 'Ct', 'Dr', 'Av', 'Gr', 'Pde', 'Pl', 'Cr', 'Cl'], dtype='object')
melb_df['StreetType'] = street_types.apply(lambda x: x if x in popular_stypes else 'other')
    #Если наш элемент не относится к 10 популярных, то он становиться в категорию "другие" - 'other'
display(melb_df['StreetType'])
.nunique() #Показывает число уникмльных элементов


//РАБОТА С DATAFRAME
/Создание копии DataFrame
melb_df = melb_data.copy()

/Удаление столбцов
melb_df = melb_df.drop(['index', 'Сoordinates'], axis=1) 
    'labels' — порядковые номера или имена столбцов, которые подлежат удалению; 
    если их несколько, то передаётся список;
    'axis' — ось совершения операции, axis=0 — удаляются строки, axis=1 — удаляются столбцы;
    'inplace' — если параметр выставлен на True, происходит замена изначального DataFrame 
    на новый, при этом метод ничего не возвращает; если на False — возвращается копия DataFrame 
    без значений, подлежащих удалению, при этом первоначальный DataFrame не изменяется; по умолчанию 
    параметр равен False.

/Совершение математических операций
total_rooms = melb_df['Rooms'] + melb_df['Bedroom'] + melb_df['Bathroom']
    
    
//ПРЕОБРАЗОВАНИЕ В ТИП DATETIME
    
melb_df['Date'] = pd.to_datetime(melb_df['Date']) #Преодразование 
    #дат в формат YYYY-MM-DD HH: MM: SS
    #что значит год-месяц-день часы:минуты:секунды
years_sold = melb_df['Date'].dt.year
Акцессор df позволяет выделять:
    date — дата;
    year, month, day — год, месяц, день;
    days — период в днях (350 дней, например);
    time — время;
    seconds - время в секундах; #Только для разницы врмени (deltaTime)
    hour, minute, second — час, минута, секунда;
    dayofweek — номер дня недели, от 0 до 6, где 0 — понедельник, 6 — воскресенье;
    weekday_name — название дня недели;
    dayofyear — порядковый день года;
    quarter — квартал (интервал в три месяца);
    x — время года.
delta_days = melb_df['Date'] - pd.to_datetime('2016-01-01')  
    #Разница времени с 1 января 2016 до момента продажи

ab_data['timestamp'] = pd.to_datetime(ab_data['timestamp'], format='%Y-%m-%d')

//ФУНКЦИИ В PANDAS
/Пример
# На вход данной функции поступает строка с адресом.
def get_street_type(address):
# Создаём список географических пометок exclude_list.
    exclude_list = ['N', 'S', 'W', 'E']
# Метод split() разбивает строку на слова по пробелу.
# В результате получаем список слов в строке и заносим его в переменную address_list.
    address_list = address.split(' ')
# Обрезаем список, оставляя в нём только последний элемент,
# потенциальный подтип улицы, и заносим в переменную street_type.
    street_type = address_list[-1]
# Делаем проверку на то, что полученный подтип является географической пометкой.
# Для этого проверяем его на наличие в списке exclude_list.
    if street_type in exclude_list:
# Если переменная street_type является географической пометкой,
# переопределяем её на второй элемент с конца списка address_list.
        street_type = address_list[-2]
# Возвращаем переменную street_type, в которой хранится подтип улицы.
    return street_type

street_types = melb_df['Address'].apply(get_street_type)
display(street_types)

//ОПРЕДЕЛЕНИЕ ЧИСЛА УНИКАЛЬНЫХ КАТЕГОРИЙ
# создаём пустой список
unique_list = []
# пробегаемся по именам столбцов в таблице
for col in melb_df.columns:
    # создаём кортеж (имя столбца, число уникальных значений)
    item = (col, melb_df[col].nunique(),melb_df[col].dtype) 
    # добавляем кортеж в список
    unique_list.append(item) 
# создаём вспомогательную таблицу и сортируем её
unique_counts = pd.DataFrame(
    unique_list,
    columns=['Column_Name', 'Num_Unique', 'Type']
).sort_values(by='Num_Unique',  ignore_index=True)
# выводим её на экран
display(unique_counts)

//ПРЕОБРАЗОВАНИЕ СТОЛБЦОВ К ТИПУ ДАННЫХ category .astype('category')
cols_to_exclude = ['Date', 'Rooms', 'Bedroom', 'Bathroom', 'Car'] # список столбцов, которые мы не берём во внимание
max_unique_count = 150 # задаём максимальное число уникальных категорий
for col in melb_df.columns: # цикл по именам столбцов
    if melb_df[col].nunique() < max_unique_count and col not in cols_to_exclude: # проверяем условие
        melb_df[col] = melb_df[col].astype('category') # преобразуем тип столбца
display(melb_df.info())
Разберём код подробнее:
1 Задаём список столбцов, которые мы не берём в рассмотрение (cols_to_exclude), а также условленный 
нами ранее порог уникальных значений столбца max_unique_count.
2 В цикле перебираем имена столбцов, и, если число уникальных категорий меньше 
заданного порога и имён столбцов нет в списке cols_to_exclude, то с помощью метода astype() 
приводим столбец к типу данных category.
3 Итоговый объём памяти — 1.9 Мб. В результате такого преобразования объём памяти, 
занимаемый таблицей, уменьшился почти в 1.5 раза. Это впечатляет!

/АТРИБУТЫ category .cat.atribyt()
#Получение списка уникальных категорий
print(melb_df['Regionname'].cat.categories)

#Посмотрим, каким образом столбец кодируется в виде чисел в памяти компьютера
print(melb_df['Regionname'].cat.codes)

#Переименование категорий с помощью словаря
melb_df['Type'] = melb_df['Type'].cat.rename_categories({
    'старое название':'новое название',
    'u': 'unit',
    't': 'townhouse',
    'h': 'house'
})

#rename single column 
df.rename(columns={'b': 'k', 'c': 'm'}, inplace=True)

#Добавить категорию
melb_df['Type'] = melb_df['Type'].cat.add_categories('flat')

//СОРТИРОВКА ТАБЛИЦЫ С ПОМОЩЬЮ МЕТОДА sort_values()
melb_df.sort_values(by='Price').head(10) # Сортируем по признаку(столбцу) 'Price'
    by — имя или список имён столбцов, по значениям которых производится сортировка.
    Если сортируем по нескольким признакам, то сначала сортируется по 1 признаку, и 
    если значения одинаковые, то сортируется по 2 признаку, и т.д.
    axis — ось, по которой производится сортировка (0 — строки, 1 — столбцы). 
    По умолчанию сортировка производится по строкам.
    ascending — сортировка по возрастанию (от меньшего к большему). По умолчанию параметр выставлен 
    на True, для сортировки по убыванию (от большего к меньшему) необходимо выставить его на False.
    ignore_index — создаются ли новые индексы в таблице. По умолчанию выставлен на False и 
    сохраняет индексы изначальной таблицы.
    inplace — производится ли замена исходной таблицы на отсортированную. По умолчанию параметр 
    выставлен на False, то есть замены не производится. Чтобы переопределить исходную таблицу на 
    отсортированную, необходимо выставить этот параметр на True.
    kind - алгоритм сортировки. Стондартно стоит quicksort
//Сортировка + фильтрация
mask1 = melb_df['AreaRatio'] < -0.8
mask2 = melb_df['Type'] == 'townhouse'
mask3 = melb_df['SellerG'] == 'McGrath'
melb_df[mask1 & mask2 & mask3].sort_values(
    by=['Date', 'AreaRatio'],
    ascending=[True, False],
    ignore_index=True
).loc[:, ['Date', 'AreaRatio']]

//ГРУППИРОВКА ДАННЫХ В DATAFRAME С ПОМОЩЬЮ МЕТОДА .groupby()
'''Метод groupby() возвращает объект DataFrameGroupBy, который хранит в себе информацию о том, 
какие строки относятся к определённой группе, и сам по себе не представляет для нас интереса. 
Однако к этому объекту можно применять уже знакомые нам агрегирующие методы (mean, median, sum и т. д.), 
чтобы рассчитывать показатели внутри каждой группы.'''
melb_df.groupby(by='Type').mean()
    by — имя или список имён столбцов, по которым производится группировка.
    axis — ось, по которой производится группировка (0 — строки, 1 — столбцы). 
    По умолчанию группировка производится по строкам.
    as_index — использовать ли групперуемый параметр как индекс к таблице. По умолчанию установлен на True.



//ГРУППИРОВКА ДАННЫХ ПО ОДНОМУ КРИТЕРИЮ С НЕСКОЛЬКИМИ АГРЕГАЦИЯМИ
В результате получаем DataFrame
melb_df.groupby('MonthSale')['Price'].agg(
    ['count', 'mean', 'max']
).sort_values(by='count', ascending=False)
метод agg(), принимает список строк с названиями агрегаций и применяет их.

           count          mean        max
MonthSale
8           1850  1.056371e+06  6500000.0
7           1835  9.314698e+05  9000000.0
5           1644  1.097807e+06  8000000.0
6           1469  1.068981e+06  7650000.0
3           1408  1.146762e+06  5600000.0
4           1246  1.050479e+06  5500000.0
9           1188  1.126349e+06  6400000.0
10           854  1.135970e+06  6250000.0
11           750  1.142503e+06  5050000.0
12           725  1.144737e+06  5700000.0
2            333  1.169051e+06  4735000.0
1            278  9.397921e+05  5200000.0

//ПОЛУЧИМ МНОЖЕСТВО ЭЛЕМЕНТОВ СТОЛБЦА
melb_df.groupby('Regionname')['SellerG'].agg(
    		['nunique', set]
)
                            nunique                                                set
Regionname
Eastern Metropolitan             26  {McGrath, Biggin, Jellis, RT, Miles, hockingst...
Eastern Victoria                 11  {McGrath, Eview, hockingstuart, Ray, O'Brien, ...
Northern Metropolitan            40  {McGrath, Collins, Biggin, Cayzer, Rendina, Ra...
Northern Victoria                11  {McGrath, LITTLE, hockingstuart, Ray, Buckingh...
South-Eastern Metropolitan       25  {McGrath, Thomson, Biggin, Jellis, Greg, Eview...
Southern Metropolitan            38  {McGrath, Thomson, Collins, Biggin, Cayzer, Re...
Western Metropolitan             34  {McGrath, Biggin, Bells, Rendina, Raine, Jelli...
Western Victoria                  6       {hockingstuart, Ray, HAR, Raine, YPA, other}

//РАЗБИЕНИЕ СТОЛБЦА НА НЕСКОЛЬКО ДРУГИХ
import pandas as pd        
df = pd.DataFrame({
          'A':['a','b','a'],
          'B':['b','a','c']
        })
df
Out[]: 
   A  B
0  a  b
1  b  a
2  a  c
# Get one hot encoding of columns B
one_hot = pd.get_dummies(df['B'])
# Drop column B as it is now encoded
df = df.drop('B',axis = 1)
# Join the encoded df
df = df.join(one_hot)
df  
Out[]: 
       A  a  b  c
    0  a  0  1  0
    1  b  1  0  0
    2  a  0  0  1


//ПОСТРОЕНИЕ СВОДНЫХ ТАБЛИЦ ЧЕРЕЗ .groupby()
melb_df.groupby(['Rooms', 'Type'])['Price'].mean().unstack()
    #Сортируем так - строки - Type, столбцы - Rooms, Значекния - средняя цена
Type          house     townhouse          unit
Rooms
1      8.668655e+05  5.927045e+05  3.899289e+05
2      1.017238e+06  7.101585e+05  6.104905e+05
3      1.109233e+06  9.847087e+05  8.505963e+05
4      1.462283e+06  1.217092e+06  1.037476e+06
5      1.877327e+06  1.035000e+06           NaN
6      1.869508e+06           NaN  5.200000e+05
7      1.920700e+06           NaN           NaN
8      1.510286e+06           NaN  2.250000e+06
10     9.000000e+05           NaN           NaN

//Построение сводных таблиц через pivot_table()
melb_df.pivot_table(
    values='Landsize',
    index='Regionname',
    columns='Type',
    aggfunc=['median', 'mean'],
    fill_value=0
)
    values — имя столбца, по которому необходимо получить сводные данные, применяя агрегирующую функцию;
    index — имя столбца, значения которого станут строками сводной таблицы;
    columns — имя столбца, значения которого станут столбцами сводной таблицы;
    aggfunc — имя или список имён агрегирующих функций (по умолчанию — подсчёт среднего, 'mean');
    fill_value — значение, которым необходимо заполнить пропуски (по умолчанию пропуски не заполняются).    
    
                           median                        mean
Type                        house townhouse unit        house   townhouse        unit
Regionname
Eastern Metropolitan        674.0     233.5  203   717.422847  269.440678  330.444444
Eastern Victoria            843.0       0.0  230  3108.960000    0.000000  295.333333
Northern Metropolitan       459.5     134.0    0   619.249092  317.325733  495.026538
Northern Victoria           724.0       0.0    0  3355.463415    0.000000    0.000000
South-Eastern Metropolitan  630.5     240.0  199   664.306701  212.160000  357.864865
Southern Metropolitan       586.0     246.0    0   569.643881  278.858824  466.380245
Western Metropolitan        531.0     198.0   62   507.883406  244.560669  557.637232
Western Victoria            599.5       0.0    0   655.500000    0.000000    0.000000

//Многомерные сводные таблицы
pivot = melb_df.pivot_table(
    values='Landsize',
    index='Regionname',
    columns='Type',
    aggfunc=['median', 'mean'],
    fill_value=0
)
#Мы передаем в параметры index или columns
                           median                        mean
Type                        house townhouse unit        house   townhouse        unit
Regionname
Eastern Metropolitan        674.0     233.5  203   717.422847  269.440678  330.444444
Eastern Victoria            843.0       0.0  230  3108.960000    0.000000  295.333333
Northern Metropolitan       459.5     134.0    0   619.249092  317.325733  495.026538
Northern Victoria           724.0       0.0    0  3355.463415    0.000000    0.000000
South-Eastern Metropolitan  630.5     240.0  199   664.306701  212.160000  357.864865
Southern Metropolitan       586.0     246.0    0   569.643881  278.858824  466.380245
Western Metropolitan        531.0     198.0   62   507.883406  244.560669  557.637232
Western Victoria            599.5       0.0    0   655.500000    0.000000    0.000000

#Доп функции
pivot.columns #Выводит названия парамера columns
    MultiIndex([('median',     'house'),
                ('median', 'townhouse'),
                ('median',      'unit'),
                (  'mean',     'house'),
                (  'mean', 'townhouse'),
                (  'mean',      'unit')],
            names=[None, 'Type'])

display(pivot['mean']['unit']) #Обращение к данным
Regionname
Eastern Metropolitan          330.444444
Eastern Victoria              295.333333
Northern Metropolitan         495.026538
Northern Victoria               0.000000
South-Eastern Metropolitan    357.864865
Southern Metropolitan         466.380245
Western Metropolitan          557.637232
Western Victoria                0.000000
Name: unit, dtype: float64

#Фильтрации
mask = pivot['mean']['house'] < pivot['median']['house']
filtered_pivot = pivot[mask]
display(filtered_pivot)

//СКЛЕЙКА = КОНКАТЕНИРОВАНИЕ ТАБЛИЦ
'left'
'right'
'inner'
'full'


ratings = pd.concat(
    [ratings1_df, ratings2_df],
    ignore_index=True
    )
print(ratings)
    objs — список объектов DataFrame ([df1, df2,…]), которые должны быть сконкатенированы;
    axis — ось определяет направление конкатенации: 0 — конкатенация по строкам (по умолчанию), 1 — конкатенация по столбцам;
    join — либо inner (пересечение), либо outer (объединение); рассмотрим этот момент немного позже;
    ignore_index — по умолчанию установлено значение False, которое позволяет значениям индекса оставаться такими, какими они 
    были в исходных данных. Если установлено значение True, параметр будет игнорировать исходные значения и повторно назначать 
    значения индекса в последовательном порядке.

/Удаление дублирующих значений
ratings = ratings.drop_duplicates(ignore_index=True)
print('Число строк в таблице ratings: ', ratings.shape[0])

//МЕТОД ОБЪЕДИНЕНИЯ join()
joined = ratings_dates.join(
    movies.set_index('movieId'),
    on='movieId',
    how='left'
)
    other — таблица, которую мы присоединяем. При объединении она является «правой», а исходная таблица, 
    от имени которой вызывается метод, является «левой».
    how — параметр типа объединения. 
    Он может принимать значения 'inner', 'left' (left outer), 'right' (right outer), и 'outer' (full outer). 
    По умолчанию параметр установлен на 'left'.
    on — параметр, который определяет, по какому столбцу в «левой» таблице происходит объединение по индексам из «правой».
    lsuffix и rsuffix — дополнения (суффиксы) к названиям одноимённых столбцов в «левой» и «правой» таблицах.
    set_index - указываем у одной из таблиц ключевой столбец

//МЕТОД ОБЪЕДИНЕНИЯ merge()
#Метод merge() предлагает более гибкий способ управления объединением, благодаря чему является более популярным.
merged = ratings_dates.merge(
    movies,
    on='movieId',
    how='left'
)
merged2 = orders_df.merge(
    products_df,
    left_on='ID товара',
    right_on='Product_ID',
    how='left'
)

merged = bronze_df.merge(
    silver_df,
    on='Country',
    how='inner',
    suffixes=('_bronze','_silver')
    )

print(merged)

    right — присоединяемая таблица. По умолчанию она является «правой».
    how — параметр типа объединения. По умолчанию принимает значение 'inner'.
    on — параметр, который определяет, по какому столбцу происходит объединение. Определяется автоматически, но рекомендуется указывать вручную.
    left_on — если названия столбцов в «левой» и «правой» таблицах не совпадают, то данный параметр отвечает за наименования ключевого столбца исходной таблицы.
    right_on — аналогично предыдущему, параметр отвечает за наименование ключевого столбца присоединяемой таблицы.
    suffixes=('_left','_right') — дополнения (суффиксы) к названиям одноимённых столбцов в «левой» и «правой» таблицах.
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






13
///////////////////////
///ГРАФИКИ В PANDAS///
/////////////////////
//Построение графиков с plot()
    x — название признака, который будет отложен по оси абсцисс;
    y — название признака, который будет отложен по оси ординат;
    figsize — размер графика (кортеж из ширины и высоты в дюймах);
    kind —тип визуализации. Основные типы:
    'line' — линейный график (по умолчанию);
    'bar' — столбчатая диаграмма;
    'barh' — горизонтальная столбчатая диаграмма;
    'hist' — гистограмма;
    'box' — коробчатая диаграмма (boxplot);
    'pie' — круговая диаграмма;
    'scatter' — диаграмма рассеяния.
    grind — отображение сетки (по умолчанию False);
    legend — отображение легенды (по умолчанию False);
    title — название графика;
    xlabel — название оси x;
    ylabel — название оси y;
    color — цвет.
    
grouped_cases = covid_df.groupby('date')['daily_confirmed'].sum()
grouped_cases.plot(
    kind='line',
    figsize=(12, 4),
    title='Ежедневная заболеваемость по всем странам',
    grid = True,
    lw=3
)
sp_mounth.plot(
    x='mounth',
    y='day_power',
    kind='bar',
    figsize=(18, 6),
    title='Ежемесячная выработка солнечной энергии',
    grid=True,
    legend=False,
    xlabel='Месяц',
    ylabel='Энергия'
);
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






13.5
////////////////////////////
///БИБЛИОТЕКА Matplotlib///
//////////////////////////
pip install matplotlib

#Импорт модуля визуализации графиков pyplot
import matplotlib.pyplot as plt
%matplotlib inline

//У объекта координатной плоскости axes вызовем метод scatter()
    x, y — последовательности, которые будут отложены по осям абсцисс и ординат;
    s — размер маркеров;
    marker — вид маркеров ('o' — точки, '^' — треугольники);
    c — цвет маркеров.

//Для построения круговых диаграмм в Matplotlib используется метод pie()
    x — значения, по которым будет строиться круговая диаграмма;
    labels — метки, соответствующие значениям;
    autopct — формат отображения долей на диаграмме (например, '%.1f%%' означает, что округление будет производиться до первого знака после запятой и при выводе будет указан знак "%"; открывающий и закрывающий проценты означают форматирование, а внутренний — вывод знака "%");
    explode — последовательность, которая определяет долю смещения сектора от центра для каждого значения из x.

//Для этого построим столбчатые диаграммы с помощью метода bar()
    x — названия категорий, которые будут располагаться по оси абсцисс;
    height — высота столбцов диаграммы, массив из показателей для визуализации (например, среднее, максимальное значение и т. д.);
    width — ширина столбцов диаграммы;
    color — цвет.
    
//За построение гистограмм в библиотеке Matplotlib отвечает метод hist()
    x — массив чисел, для которого строится гистограмма;
    bins — число столбцов (корзин);
    orientation — ориентация гистограммы (по умолчанию 'vertical');
    color — цвет.    

//В большинстве случаев для отображения нескольких систем координат используется функция subplots()
    nrows — число строк;
    ncols — число столбцов;
    figsize — общий размер фигуры в дюймах (ширина и высота).
fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(10, 5))

//Оформление графика
    axes.set_title() — заголовок диаграммы, а также его настройки (например, параметр fontsize отвечает за размер шрифта);
    axes.set_xlabel() — название оси абсцисс;
    axes.set_ylabel() — название оси ординат;
    axes.set_xticks() — установка отметок на оси абсцисс;
    axes.set_yticks() — установка отметок на оси ординат;
    axes.xaxis.set_tick_params() — управление параметрами отметок на оси абсцисс (например, параметр rotation отвечает за поворот отметок в градусах);
    axes.yaxis.set_tick_params() — управление параметрами отметок на оси ординат;
    axes.legend() — отображение легенды;
    axes.grid() — установка сетки.

vacc_country = covid_df.groupby('country')['people_fully_vaccinated'].last().nlargest(5)
vacc_country_per_hundred = covid_df.groupby('country')['people_fully_vaccinated_per_hundred'].last().nlargest(5)

#визуализация главного графика
fig = plt.figure(figsize=(13, 4))
main_axes = fig.add_axes([0, 0, 1, 1])
main_axes.bar(x = vacc_country.index, height = vacc_country);
main_axes.set_ylabel('Число вакцинированных (2 компонент)')
main_axes.set_title('Топ 5 стран по числу полностью привитых людей')

#визуализация вспомогательного графика
insert_axes = fig.add_axes([0.6, 0.6, 0.38, 0.38])
insert_axes.bar(x = vacc_country_per_hundred.index, height = vacc_country_per_hundred, width=0.5);
insert_axes.set_ylabel('На 100 человек')
insert_axes.xaxis.set_tick_params(rotation=45)
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






13.6
//////////////////////////////////////////
///НАДСТРОЙКА ДЛЯ Matplotlib - Seaborn///
////////////////////////////////////////
pip install seaborn

import seaborn as sns
print(sns.__version__)

//Основные параметры метода histplot()
    data — DataFrame, по которому строится график;
    x — признак, который будет отложен по оси абсцисс;
    y — признак, который будет отложен по оси ординат;
    hue — группировочный категориальный признак, который позволяет строить отдельный график для каждой категории (не стоит использовать его для гистограмм, но он широко используется для других видов графиков в Seaborn);
    ax — система координат Matplotlib, в которой строится график;
    color — цвет графика;
    bins — число столбцов в гистограмме (по умолчанию вычисляется автоматически с помощью специальных формул);
    kde — параметр, указывающий, стоит ли сглаживать гистограмму кривой (по умолчанию False).

//Коробчатая диаграмма sns.boxplot()
    orient отвечает за ориентацию диаграммы,
    width — за ширину коробок:   
fig = plt.figure(figsize=(10, 7))
boxplot = sns.boxplot(
    data=croped_covid_df,
    y='country',
    x='death_rate',
    orient='h',
    width=0.9
)
boxplot.set_title('Распределение летальности по странам');
boxplot.set_xlabel('Летальность');
boxplot.set_ylabel('Страна');
boxplot.grid()

//Многоуровневая столбчатая диаграмма sns.barplot()
    По умолчанию метод отображает среднее по столбцу, который указан в параметре 
    x (вместо среднего можно вычислить и любую другую статистическую характеристику, наименование которой задаётся в параметре estimator). 
    Для добавления многоуровневости используется параметр 
    hue, который позволяет группировать данные по признаку
fig = plt.figure(figsize=(10, 7))
croped_covid_df['quarter'] = croped_covid_df['date'].dt.quarter
barplot = sns.barplot(
    data=croped_covid_df,
    x='country',
    y='daily_confirmed_per_hundred',
    hue='quarter',
)
barplot.set_title('Средний процент болеющего населения по кварталам');

//Совмещены диаграмма рассеяния и гистограмма sns.jointplot()
jointplot = sns.jointplot(
    data=croped_covid_df, 
    x='people_fully_vaccinated_per_hundred', 
    y='daily_confirmed_per_hundred',
    hue='country',                              #Группирует данные по цветам
    xlim = (0, 40),
    ylim = (0, 0.1),
    height=8,
)

//Тепловая карта sns.heatmap()
https://www.codecamp.ru/blog/seaborn-heatmap/
https://datastart.ru/blog/read/seaborn-heatmaps-13-sposobov-nastroit-vizualizaciyu-matricy-korrelyacii
sns.heatmap(data=pivot, cmap='YlGnBu')

pivot = croped_covid_df.pivot_table(
    values='confirmed_per_hundred',
    columns='date',
    index='country',
)
pivot.columns = pivot.columns.astype('string')


heatmap = sns.heatmap(data=pivot, cmap='YlGnBu')
heatmap.set_title('Тепловая карта вакцинации', fontsize=16);
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






13.7
////////////////////////
///БИБЛИОТЕКА//////////   plotly.com
//////////////////////
Библиотека Plotly является сравнительно новым коммерческим продуктом с бесплатной версией, который создавался 
специально для Data Science, в отличие от относительно старой библиотеки Matplotlib, которая изначально разрабатывалась для научных вычислений.

→ Библиотека Plotly позволяет строить интерактивные графики, которые можно приближать, отдалять, а также 
просматривать значения на графике в реальном времени. К тому же в библиотеке собрано огромнейшее количество красочных 
методов визуализации. У Plotly приятный дизайн, а способов работы с ней несколько.

→ С помощью Plotly можно делать сложные визуализации с элементами управления, например строить интерактивную 3D-визуализацию, 
карту мира и многое другое.

pip install plotly

import plotly
import plotly.express as px
print(plotly.__version__)

////////////////С помощью экспресс-режима (px) можно строить уже знакомые нам графики:
line() — линейные графики;
histogram() — гистограммы;
scatter() — диаграммы рассеяния;
box() — коробчатые диаграммы;
bar() — столбчатые диаграммы;
pie() — круговые диаграммы.

//express режим
/line()
line_data = covid_df.groupby('date', as_index=False).sum()
fig = px.line(
    data_frame=line_data, #DataFrame
    x='date', #ось абсцисс
    y=['confirmed', 'recovered', 'deaths', 'active'], #ось ординат
    height=500, #высота
    width=1000, #ширина
    title='Confirmed, Recovered, Deaths, Active cases over Time' #заголовок
)
fig.show()

/histogram()
fig = px.histogram(
    hotels_df, 
    x='additional_number_of_scoring',
    marginal='box',
    nbins=150,
    title='Число людей с оценкой но без отзыва'            
)
fig.show();

/bar()
fig = px.bar(
    data_frame=bar_data, #DataFrame
    x="country", #ось x
    y="recover_rate", #ось y
    color='country', #расцветка в зависимости от страны
    text = 'recover_rate', #текст на столбцах
    orientation='v', #ориентация графика
    height=500, #высота
    width=1000, #ширина
    title='Top 10 Countries for Recovery Rate' #заголовок
)

#отображаем график
fig.show()

/treemap() - график из плиточек
fig = px.treemap(
    data_frame=treemap_data, #DataFrame
    path=['country'], #категориальный признак, для которого строится график
    values='daily_recovered', #параметр, который сравнивается
    height=500, #высота
    width=1000, #ширина
    title='Daily Recovered Cases by Country' #заголовок
)

#отображаем график
fig.show()

/choropleth() - тепловая карта на карте мира
#преобразуем даты в строковый формат
choropleth_data = covid_df.sort_values(by='date')
choropleth_data['date'] = choropleth_data['date'].astype('string')

#строим график
fig = px.choropleth(
    data_frame=choropleth_data, #DataFrame
    locations="country", #столбец с локациями
    locationmode = "country names", #режим сопоставления локаций с базой Plotly
    color="total_vaccinations", #от чего зависит цвет
    hover_name="country", #группирующая переменная
    animation_frame="date", #анимационный бегунок
    range_color=[0, 600e6], #диапазон цвета
    title='Global total_vaccinations of COVID-19', #заголовок
    width=800, #ширина
    height=500, #высота
    color_continuous_scale='Reds' #палитра цветов
)

#отображаем график
fig.show(renderer='notebook')

/метод scatter_3d() - 3D визуализация диаграммы рассеяния
#фильтруем таблицу по странам
countries=['United States', 'Russia', 'United Kingdom', 'Brazil', 'France']
scatter_data = covid_df[covid_df['country'].isin(countries)]

#строим график
fig = px.scatter_3d(
    data_frame=scatter_data, #DataFrame
    x = 'daily_confirmed', #ось абсцисс
    y = 'daily_deaths', #ось ординат
    z = 'daily_vaccinations', #ось аппликат
    color='country', #расцветка в зависимости от страны
    log_x=True, 
    log_y=True,
    width=1000,
    height=700
)

#отображаем график
fig.show()
fig.write_html("plotly/scatter_3d.html")

/сохранение фигуры
fig.write_html("plotly/scatter_3d.html")


//Вывод нескольких графиков на одном
import plotly.express as px
import plotly.graph_objects as go

fig1 = px.line(df, x='A', y='D')
fig2 = px.line(df2, x='X', y='Y')

fig = go.Figure(data = fig1.data + fig2.data)
fig.show()
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






5.2
/////////////////
///Очистка данных///
///////////////

//Нахождение строк с незаполненными значениями NaN
null_data = data.isnull().sum()
display(null_data[null_data > 0])

//Поиск числа пропусков
cols_null_persent = sber_data.isnull().mean() * 100
cols_with_null = cols_null_persent[cols_null_persent>0].sort_values(ascending=False)
display(cols_with_null)

//УДАЛЕНИЕ ПУСТЫХ ПРИЗНАКОВ
dropna(self, axis=0, how="any", thresh=None, subset=[None], inplace=False)
    axis : Возможные значения {0 или «индекс», 1 или «столбцы»}, по умолчанию 0. Если 0, капля строки с нулевыми значениями. 
    Если 1, падение колонн с отсутствующими значениями.
    how : Возможные значения {‘any’, ‘all’}, по умолчанию “любой”. Если «любой», отбросьте строку/столбец, если какое-либо из 
        значений нуль. Если «все», отбросьте строку/столбец, если все значения отсутствуют.
    Thresh : Значение INT для указания порога для операции падения.
    subset : Указывает строки/столбцы, чтобы искать нулевые значения.
    inplace : логическое значение. Если true, источник dataframe изменяется, и никто не возвращается.

    axis — ось, по которой производится удаление (по умолчанию 0 — строки).
    how — как производится удаление строк 
        (any — если хотя бы в одном из столбцов есть пропуск, стоит по умолчанию; 
        all — если во всех столбцах есть пропуски). 
    thresh — порог удаления. Определяет минимальное число непустых значений в строке/столбце, 
        при котором она/он сохраняется. Например, если мы установим thresh в значение 2, 
        то мы удалим строки, где число пропусков n-2  и более, где  — число n признаков (если axis=0).

/Пример
#создаем копию исходной таблицы
drop_data = sber_data.copy()
#задаем минимальный порог: вычисляем 70% от числа строк
thresh = drop_data.shape[0]*0.7
#удаляем столбцы, в которых более 30% (100-70) пропусков
drop_data = drop_data.dropna(how='any', thresh=thresh, axis=1)
#удаляем записи, в которых есть хотя бы 1 пропуск
drop_data = drop_data.dropna(how='any', axis=0)
#отображаем результирующую долю пропусков
drop_data.isnull().mean()


//ЗАПОЛНЕНИЕ НЕДОСТАЮЩИХ ЗНАЧЕНИЙ КОНСТАНТАМИ
df = df.fillna(словарь)
В словаре записать так:
Признак таблицы : на что заменить в нем NaN

/Пример
#создаем копию исходной таблицы
fill_data = sber_data.copy()
#создаем словарь имя столбца: число(признак) на который надо заменить пропуски
values = {
    'life_sq': fill_data['full_sq'],
    'metro_min_walk': fill_data['metro_min_walk'].median(),
    'metro_km_walk': fill_data['metro_km_walk'].median(),
    'railroad_station_walk_km': fill_data['railroad_station_walk_km'].median(),
    'railroad_station_walk_min': fill_data['railroad_station_walk_min'].median(),
    'hospital_beds_raion': fill_data['hospital_beds_raion'].mode()[0],
    'preschool_quota': fill_data['preschool_quota'].mode()[0],
    'school_quota': fill_data['school_quota'].mode()[0],
    'floor': fill_data['floor'].mode()[0]
}
#заполняем пропуски в соответствии с заявленным словарем
fill_data = fill_data.fillna(values)
#выводим результирующую долю пропусков
fill_data.isnull().mean()

//ДОБАВЛЕНИЕ ПРИЗНАКОВ-ИНДИКАТОРОВ
#в цикле пробегаемся по названиям столбцов с пропусками
for col in cols_with_null.index:
    #создаем новый признак-индикатор как col_was_null
    indicator_data[col + '_was_null'] = df[col].isnull()


//ОЧИСТКА ОТ ЫВБРОСОВ
Отфильтруем те, где жилая площадь больше общей
outliers = sber_data[sber_data['life_sq'] > sber_data['full_sq']]
print(outliers.shape[0])

//МЕТОД МЕЖКВАРТИЛЬНОГО РАЗМАХА (МЕТОД ТЬЮКИ)
1. Алализируем на графике box возможные выбросы
2. Вычисляем 25-ую и 75-ую квантили (первый и третий квартили) — и  для признака, который мы исследуем
3. Вычисляем межквартильное расстояние: IQR = Q75 - Q25
4. Вычисляем верхнюю и нижнюю границы Тьюки:     
    bound_upper = Q75 + 1.5*IQR
    bound_lower = Q25 - 1.5*IQR
5. Находим наблюдения, которые выходят за пределы границ.

def outliers_iqr(data, feature, log_scale=False, left=1.5, right=1.5):    
    if log_scale:
        x = np.log(data[feature]+1)
    else:
        x = data[feature]
    quartile_1, quartile_3 = x.quantile(0.25), x.quantile(0.75),
    iqr = quartile_3 - quartile_1
    upper_bound = quartile_3 + (iqr * right)
    lower_bound = quartile_1 - (iqr * left) 
    
    outliers = data[(x<lower_bound) | (x > upper_bound)]
    cleaned = data[(x>lower_bound) & (x < upper_bound)]
    return outliers, cleaned

outliers, cleaned = outliers_iqr(sber_data, 'full_sq', left=1, right=6)

print('Vibrosi: ',outliers.shape[0])
print('Itogo zapisei: ',cleaned.shape[0])    

//МЕТОД Z-ОТКЛОНЕНИЙ (МЕТОД 3-х СИГМ)
def outliers_z_score(data, feature, log_scale=False, left=3, right=3):    
    if log_scale:
        x = np.log(data[feature]+1)
    else:
        x = data[feature]
    mu = x.mean()                   #Вычислим математическое ожидание (среднее)
    sigma = x.std()                 #Вычислим стандартное отклонение для признака x
    lower_bound = mu - left * sigma    #Вычислим нижнюю границу интервала
    upper_bound = mu + right * sigma    #Вычислим верхнюю границу интервала
    outliers = data[(x < lower_bound) | (x > upper_bound)]
    cleaned = data[(x > lower_bound) & (x < upper_bound)]
    return outliers, cleaned

outliers, cleaned = outliers_z_score(sber_data, 'mkad_km', log_scale=True, left=3, right=3.5)

print('Vibrosi: ',outliers.shape[0])
print('Itogo zapisei: ',cleaned.shape[0])

//ДУБЛИКАТЫ метод .duplicated()
Возвращает маску для фильтрации, если есть дубликаты

dupl_columns = list(sber_data.columns)
dupl_columns.remove('id')

mask = sber_data.duplicated(subset=dupl_columns)
sber_duplicates = sber_data[mask]
print(f'Число найденных дубликатов: {sber_duplicates.shape[0]}')

//УДАЛЕНИЕ ДУБЛИКАТОВ метод .drop_duplicates()
sber_dedupped = sber_data.drop_duplicates(subset=dupl_columns)
print(f'Результирующее число записей: {sber_dedupped.shape[0]}')

//ОБНАРУЖЕНИЕ И ЛИКВИДАЦИЯ НЕИНФОРМАТИВНЫХ ПРИЗНАКОВ
Признак считается неинформативным, если в нем 95% (99%) одинаковых либо уникальных значений
#создаем список неинформативных признаков
low_information_cols = [] 

#цикл по всем столбцам
for col in sber_data.columns:
    #наибольшая относительная частота в признаке
    top_freq = sber_data[col].value_counts(normalize=True).max()
    #доля уникальных значений от размера признака
    nunique_ratio = sber_data[col].nunique() / sber_data[col].count()
    # сравниваем наибольшую частоту с порогом
    if top_freq > 0.95:
        low_information_cols.append(col)
        print(f'{col}: {round(top_freq*100, 2)}% одинаковых значений')
    # сравниваем долю уникальных значений с порогом
    if nunique_ratio > 0.95:
        low_information_cols.append(col)
        print(f'{col}: {round(nunique_ratio*100, 2)}% уникальных значений')

#Удалим неинформативные признаки
information_sber_data = sber_data.drop(low_information_cols, axis=1)
print(f'Результирующее число признаков: {information_sber_data.shape[1]}')

//ВАЖНОСТЬ ПРИЗНАКА
На самом деле информативность признаков определяется не только числом уникальных значений, 
но и их влиянием на целевой признак (тот, который мы хотим предсказать). Это называется важностью признака.

Признаки, которые обладают низкой важностью, называют нерелевантными признаками. 



/////////////////////////////////////////////////////////////////////////////////////////////////////////////////


/////////////////////////////////////////////////////
//////Дополнительные библиотеки для анализа и EDA///
///////////////////////////////////////////////////

//PANDAS-PROFILING
Pandas-profiling — это библиотека с открытым исходным кодом, которая создаёт подробный отчёт по данным. 
Pandas-profiling можно легко использовать для больших наборов данных: отчёты создаются всего за несколько секунд.

pip install pandas-profiling



/////////////////////////////////////////////////////////////////////////////////////////////////////////////////




5.2
/////////////////
///ООП. Классы///
///////////////

Классы, как и библиотечные функции, можно импортировать в другие программы. 
Для этого нужно положить класс в отдельный файл в корне проекта и использовать ключевое слово import. 

Например, если мы положим Dumper в файл dumper.py в корне проекта, то его можно импортировать командой:

from dumper import Dumper  

Пишем from <имя файла без .py> import <имя класса>.
Имя файла должно начинаться с буквы и не совпадать с именами библиотечных модулей. 
Если файлов с классами много, их можно складывать в папки, предварительно положив туда пустой файл __init__.py — это требование Python.

/Пример
Пусть у вас есть папка duck, в которой лежит файл egg.py, а в нём — класс Needle. Какой командой мы можем импортировать этот класс?
from duck.egg import Needle


атрибут объекта — это просто его переменная;
метод объекта — это его функция;
метод объекта автоматически получает первым аргументом сам объект под именем self;
класс описывает объект через его атрибуты и методы;
мы можем создавать множество экземпляров одного класса, и значения их атрибутов независимы друг от друга;
если определить метод __init__, то он будет выполняться при создании объекта;
всё это позволяет компактно увязывать данные и логику внутри объекта.


# Используем ключевое слово class, за которым идёт название класса, в примере это SalesReport  
class SalesReport():  
    pass  
  
# Сравните это с определением пустой функции  
# Команда pass не делает ничего; на её месте могли быть другие инструкции  
# Мы используем её только потому, что синтаксически python требует, чтобы там было хоть что-то  
def build_report():  
    pass  
  
  
# И давайте определим ещё один класс  
# Для имён классов традиционно используются имена в формате CamelCase, где начала слов отмечаются большими буквами  
# Это позволяет легко отличать их от функций, которые пишутся в формате snake_case  
class SkillfactoryStudent():  
    pass


class DepartmentReport():
    # Позволим добавлять много разных сделок   
    def add_revenue(self, amount):   
        # На первой сделке создадим список для хранения всех сделок   
        if not hasattr(self, 'revenues'):  
            self.revenues = []  
        # Добавим текущую сделку  
        self.revenues.append(amount)  
          
    # Посчитаем среднее всех сделок      
    def average_revenue(self):  
        return sum(self.revenues)/len(self.revenues)         
 
  
report = DepartmentReport()
report.add_revenue(1_000_000)
report.add_revenue(400_000)
print(report.revenues)
# => [1000000, 400000]
print(report.average_revenue())
# => 700000.0

//РАБОТА С ФАЙЛАМИ
import os

# получить текущий путь
start_path = os.getcwd()
print(start_path) # /home/nbuser/library

os.chdir("..") # подняться на один уровень выше
os.getcwd() # '/home/nbuser'

os.chdir(start_path)
os.getcwd() # '/home/nbuser/library'

# список файлов и директорий в папке
print(os.listdir()) # ['SnapchatLoader', 'FBLoader', 'tmp.py', '.gitignore', 'venv', '.git']

if 'tmp.py' not in os.listdir():
    print("Файл отсутствует в данной директории")

# соединяет пути с учётом особенностей операционной системы
print(start_path)
print(os.path.join(start_path, 'test'))

# /home/nbuser/library
# /home/nbuser/library/test

Python «из коробки» располагает достаточно широким набором инструментов для работы с файлами. 
Для того чтобы начать работать с файлом, надо его открыть с помощью команды специальной функции open.
f = open('path/to/file', 'filemode', encoding='utf8')
    path/to/file — путь к файлу может быть относительным или абсолютным. Можно указывать в Unix-стиле (path/to/file) или в Windows-стиле (path\to\file).
    filemode — режим, в котором файл нужно открывать.
        Записывается в виде строки, состоит из следующих букв:
        r — открыть на чтение (по умолчанию);
        w — перезаписать и открыть на запись (если файла нет, то он создастся);
        x — создать и открыть на запись (если уже есть — исключение);
        a — открыть на дозапись (указатель будет поставлен в конец);
        t — открыть в текстовом виде (по умолчанию);
        b — открыть в бинарном виде.
    encoding — указание, в какой кодировке файл записан (utf8, cp1251 и т. д.) По умолчанию стоит utf-8.    


















/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






5.2
/////////////////
///Воспроизводимость кода///
///////////////
Необходимо зафиксировать версии библиотеки, которые использовались в проекте.
Можно зафиксировать версии через pip командой 
pip freeze > requirements.txt.

Как перенести эти версии библиотек на другой компьютер, чтобы наш проект работал на нём?

Для этого необходимо использовать команду pip install -r requirements.txt.

/conda
Чтобы сохранить более полную информацию об окружении, необходимо использовать Anaconda, которую мы уже установили ранее. 
Выполним команду 

conda env export > environment.yaml

В результате выполнения команды в папке проекта появляется файл environment.yaml — в нём сохранены версии окружения, Python и необходимых библиотек. Более полная информация позволяет с большей вероятностью получить воспроизводимый код.

Чтобы восстановить окружение из Conda, достаточно выполнить команду conda env create -f environment.yaml.

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






16
//////////////////////////////////
///РАБОТА С ТЕКСТОВЫМИ ФАЙЛАМИ///
////////////////////////////////
Units by 2/Python16

import pandas as pd # Импорт библиотеки pandas — при выполнении последовательно всех примеров ниже, импорт библиотеки pandas выполняется один раз
countries_data = pd.read_csv('C:/Python/github/sf_data_science/Data_Science_memory/data/countries.csv', sep=';') # Загружаем данные из файла в переменную, создавая объект DataFrame
countries_data.to_csv('C:/Python/github/sf_data_science/Data_Science_memory/data//countries.txt', index=False, sep=' ') # Выгружаем данные из DataFrame в CSV-файл и сохраняем файл в папке data
display(countries_data)
txt_df = pd.read_table('C:/Python/github/sf_data_science/Data_Science_memory/data//countries.txt', sep=' ', index_col=['country'])# Загружаем данные из файла в переменную, создавая объект DataFrame
display(txt_df) # Выводим содержимое DataFrame на экран

//ПРИМЕНЕНИЕ ПАРАМЕТРА HEADER
Используя параметр header, при создании DataFrame мы учитываем наличие/отсутствие строки заголовков в исходном файле данных.
melb_data = pd.read_csv('data/melb_data_ps.csv', header=None) # Загружаем данные из файла в переменную, создавая объект DataFrame
display(melb_data) # Выводим содержимое DataFrame на экран    

//РЕШАЕМ ПРОБЛЕМУ С КОДИРОВКОЙ ИСХОДНЫХ ДАННЫХ
pip install chardet

Считываем файл и создаем DataFrame без использования параметра encoding:
data=pd.read_csv('data/ErrorEnCoding.csv', header=None ) # Считываем данные из файла с неизвестной кодировкой в переменную, создавая объект DataFrame
display(data) # Выводим содержимое DataFrame на экран    

Приведённый ниже код поможет нам определить используемую кодировку в файле, степень достоверности, используемый язык.
from chardet.universaldetector import UniversalDetector # Импортируем субмодуль chardet.universaldetector
detector = UniversalDetector()
with open('data/ErrorEnCoding.csv', 'rb') as fh:
    for line in fh:
        detector.feed(line)
        if detector.done:
            break
detector.close()

//ЧТЕНИЕ ФАЙЛА ПО ССЫЛКЕ, ИСПОЛЬЗУЯ ФУНКЦИЮ READ_TABLE()
data = pd.read_table('https://raw.githubusercontent.com/esabunor/MLWorkspace/master/melb_data.csv', sep=',')
display(data)

//ЧТЕНИЕ/ЗАПИСЬ АРХИВИРОВАННЫХ CSV-ФАЙЛОВ
Можно читать данные прямо из архива, главное, чтобы он там был один

data = pd.read_csv('data/students_performance.zip')
display(data)

Можно упаковать в архив на лету
compression_opts = dict(method='zip', archive_name='out.csv') # Определяем параметры архивирования — метод сжатия, имя файл в архиве
data.to_csv('data/out.zip', index=False, compression=compression_opts)

//СЧИТЫВАНИЕ ДАННЫХ ИЗ ФАЙЛА EXCEL
Формулы не считываются!!! Только значения!!!
pip install openpyxl

Продвинутая работа с файлами Excel в Python предполагает использование дополнительных библиотек, таких как:
    openpyxl — рекомендуемый пакет для чтения и записи файлов Excel 2010+ (например, xlsx);
    xlsxwriter — альтернативный пакет для записи данных, информации о форматировании и, в частности, диаграмм в формате Excel 2010+ (например, xlsx);
    pyxlsb — пакет позволяет читать файлы Excel в xlsb-формате;
    pylightxl — пакет позволяет читать xlsx- и xlsm-файлы и записывать xlsx-файлы;
    xlrd — пакет предназначен для чтения данных и информации о форматировании из старых файлов Excel (например, xls);
    xlwt — пакет предназначен для записи данных и информации о форматировании в старые файлы Excel (например, xls).

grades = pd.read_excel('data/grades.xlsx', sheet_name='ML')
display(grades.head())
Основные параметры метода read_excel()
    io — первый параметр, в который мы передаём адрес файла, который хотим прочитать. 
        Кроме адреса на диске, можно передавать адрес в интернете.
    sheet_name —  ссылка на лист в Excel-файле (возможные значения данного параметра: 0 — значение по умолчанию, 
        загружается первый лист; 'Sheet1' — можно передать название листа; обычно листы называются 'SheetX', 
        где X — номер листа, но могут использоваться и другие названия; 
        [0, 1, 'Sheet3'] — список, содержащий номера или названия листов; в таком случае Pandas вернёт словарь, 
        в котором ключами будут номера или названия листов, а значениями — их содержимое в виде DataFrame; 
        None — если передать такое значение, то pandas прочитает все листы и вернёт их в виде словаря, как в предыдущем пункте).
    na_values — список значений, которые будут считаться пропусками 
        ( ‘’, ‘#N/A’, ‘ N/A’, ‘#NA’, ‘-1.#IND’, ‘-1.#QNAN’, ‘-NaN’, ‘-nan’, ‘1.#IND’, ‘1.#QNAN’, ‘NA’, ‘NULL’, ‘NaN’, ‘n/a’, ‘nan’, ‘null’).

//ВЫГРУЗКА ДАННЫХ ИЗ DATAFRAME В EXCEL-ФАЙЛ
grades.to_excel('data/grades_new.xlsx') # Сохраняем данные из DataFrame grades в файл grades_new.xlsx в папке data

В этом случае будет создан один лист с именем по умолчанию "Sheet1". Также мы сохраним и индекс — в данных будет находиться лишний столбец. Чтобы создать лист с определённым именем (например, Example) и не сохранять индекс, в метод  to_excel() необходимо передать параметры sheet_name='Example' и index=False:

grades.to_excel('data/grades_new.xlsx', sheet_name='Example', index=False) # Сохраняем данные из DataFrame grades в файл grades_new.xlsx 
                                                                            #(на листе 'Example') в папке data

//JSON. Что это?
import json # Импортируем модуль json
from pprint import pprint # Импортируем функцию pprint()

Информация в формате JSON представляет собой (в закодированном виде) одну из двух структур:
    * набор пар "ключ-значение", где ключ — это всегда строковая величина (в Python такая структура преобразуется в словарь);
    * упорядоченный набор значений (при чтении JSON-файла в Python эта структура будет преобразована в список).
Формат JSON допускает неограниченное количество вложений этих структур друг в друга.

[{"id": 10259, "cuisine": "greek", "ingredients": ["romaine lettuce", "black olives", "grape tomatoes", "garlic", "pepper", "purple onion", "seasoning", "garbanzo beans", "feta cheese crumbles"]}...

→ Чтобы перевести данные из формата JSON в формат, который можно обрабатывать инструментами Python, необходимо выполнить процедуру, 
которая называется десериализация (декодирование данных). Обратный процесс, связанный с переводом структур данных Python в формат JSON, 
называется сериализацией.

Для выполнения десериализации мы воспользуемся методом load() (от англ. загрузить) модуля json, который принимает на вход ссылку на открытый JSON-файл:

 with open('recipes.json') as f: # Открываем файл и связываем его с объектом "f"
    recipes = json.load(f) # Загружаем содержимое открытого файла в переменную recipes
Отлично! Теперь содержимое нашего файла загружено в переменную recipes. Давайте выведем его на экран с помощью функции pprint() из одноимённого модуля:

 pprint(recipes) # Выводим на экран содержимое переменной recipes, используя функция pprint()

/ИЗ JSON В PANDAS

with open('recipes.json') as f: # Открываем файл и связываем его с объектом "f"
    recipes = json.load(f) # Загружаем содержимое открытого файла в переменную recipes
df = pd.DataFrame(recipes) # Создаём объект DataFrame из списка recipes
display(df.head()) # Выводим на экран первые строки полученного DataFrame

Или сразу
df = pd.read_json('recipes.json') # Создаём объект DataFrame, загружая содержимое файла recipes.json
display(df.head()) # Выводим на экран первые строки полученного DataFrame

/ИЗ PANDAS В JSON
df = pd.read_csv('recipes.csv') # Читаем содержимое файла и создаем объект df
ingredients = list(df.columns)[3:] # Создаем список уникальных значений ингредиентов

def make_list(row): # Определяем имя функции и передаваемые аргументы
    ingredient_list=[] # Создаем пустой список ингредиентов текущего блюда
    for ingredient in ingredients: # Последовательно перебираем ингредиенты из реестра
        if row[ingredient].item()==1: # Если текущий ингредиент входит в состав текущего блюда
            ingredient_list.append(ingredient) # Добавляем ингредиент в список ингредиентов текущего блюда
    return ingredient_list # Возвращаем сформированный список ингредиентов


//ИЗВЛЕКАЕМ КОНТЕНТ ИЗ XML-ФАЙЛА
 import xml.etree.ElementTree as ET # Импортируем модуль ElementTree

<menu>
    <dish name="Кура">
        <price>40</price>
        <weight>300</weight>
        <class>Мясо</class>
    </dish>
    <dish name="Греча">
        <price>20</price>
        <weight>200</weight>
        <class>Крупа</class>
    </dish>
</menu>

Для работы со структурой файла menu.xml считаем его содержимое в переменную tree, выполнив код:
    import xml.etree.ElementTree as ET # Импортируем модуль ElementTree
    tree = ET.parse('menu.xml')

/Корень
root = tree.getroot()
display(root)
#<Element 'menu' at 0x000001E4C4B4EE00>

/Потомки
display(list(root))
#[<Element 'dish' at 0x000001E4C3031040>,
# <Element 'dish' at 0x000001E4C4B46450>]

/Потомки потомков
display(list(root[1]))
#[<Element 'price' at 0x000001E4C4B46220>,
# <Element 'weight' at 0x000001E4C4B46A40>,
# <Element 'class' at 0x000001E4C4B46E00>]

/Атрибуты и теги
Выведем атрибуты 1 блюда
display(root[0][0].attrib)
#{'name':'Кура'}

В XML-узлах часто хранятся количественные показатели. Эти показатели хранятся в виде текста, и прочитать их можно, обратившись к атрибуту text у соответствующего объекта типа ElementTree.Element.

Например, возьмём узел price первого блюда из меню:
display(root[0][0])
#<Element 'price' at 0x0000025C04328B80>

Теперь прочитаем значение этого узла с помощью text:
display(root[0][0].text)
#'40'

Если вы хотите прочитать наименование тега конкретного узла, необходимо использовать tag. Например, получим наименование тега корневого узла:
display(root.tag)
#'menu'

/Использование циклов
Используя цикл for, автоматизируем обход дерева. Для этого напишем следующий код:

for dish in root:
    for param in dish:
        print(dish.attrib['name'], param.tag, param.text)
    print()

    1. В первом (внешнем) цикле перебираем потомков корня дерева (root). Потомки перебираются последовательно при помощи переменной dish. Это отдельные блюда из меню.
    2. Во втором (вложенном) цикле аналогичным образом перебираем потомков каждого блюда. Этими потомками являются параметры блюда — его цена (price), вес (weight) и класс (class).
    3. После этого выводим на экран название блюда (значение атрибута name), название очередного параметра (tag) и его значение (text).
    4. Дополнительная функция print() в цикле верхнего уровня предназначена для организации более удобного восприятия информации — между отдельными блюдами будет выведена пустая строка.

#Кура price 40
#Кура weight 300
#Кура class Мясо

#Греча price 20
#Греча weight 200
#Греча class Крупа

/ЗАГРУЖАЕМ ДАННЫЕ ИЗ XML-ФАЙЛА В DATAFRAME
Cтандартных средств для превращения XML-файла в DataFrame нет, но если XML-файл содержит чёткую структуру, сделать это средствами Python достаточно просто.

Реализуем следующий алгоритм:
    Загрузить XML-структуру файла menu.xml в переменную root .
    Создать пустой DataFrame (в него будем постепенно загружать информацию из XML-файла).
    В создаваемом DataFrame четыре столбца — название блюда (name), его цена (price), вес (weight) и класс (class).
    В цикле организовать обход xml-дерева из корня по всем потомкам.
    На каждой итерации цикла сформировать строку, содержащую информацию: наименование блюда (атрибут name узла dish) и значения потомков этого узла — узлов price, weight, class.
    Добавить сформированную строку в DataFrame, используя метод append().
    Вывести содержимое полученного DataFrame на экран.

import xml.etree.ElementTree as ET
tree = ET.parse('menu.xml')    
root = tree.getroot()

import pandas as pd
column_names = ['name', 'price', 'weight', 'class']
df = pd.DataFrame(columns=column_names)

for dish in root:
    row = [dish.attrib['name'], dish[0].text, dish[1].text, dish[2].text]
    df = df.append(pd.Series(row, index=column_names), ignore_index=True)
display(df)

/СОЗДАЁМ XML-ФАЙЛ
Воссоздадим структуру нашего исходного XML-файла с нуля,  руководствуясь общими рекомендациями.

Чтобы создать корень дерева, используем метод Element() из класса ElementTree:
import xml.etree.ElementTree as ET

new_root = ET.Element('menu')
display(new_root)

Теперь мы можем добавлять новые узлы в наше дерево, используя метод SubElement() из того же класса.
Добавим в наше меню двух потомков корневого узла, которые будут представлять два блюда, то есть будут узлами dish:
dish1 = ET.SubElement(new_root, 'dish', name='Кура')
dish2 = ET.SubElement(new_root, 'dish', name='Греча')
display(list(new_root))
В метод SubElement() мы передали первым аргументом узел, к которому добавляем потомка, вторым аргументом — наименование нового тега (dish),  третьим аргументом — наименование атрибута нового узла( name ) и его значение.
Аналогичным образом можно добавлять новые узлы к любым существующим узлам, не только к корню.

Добавим в создаваемую структуру по три потомка (атрибута) к двум новым узлам, которые будут содержать информацию 
о блюде — о его цене (price), 
весе (weight) 
и классе (class), а также значение этих атрибутов:

price1 = ET.SubElement(dish1, "price").text = "40"
weight1 = ET.SubElement(dish1, "weight").text = "300"
class1 = ET.SubElement(dish1, "class").text = "Мясо"
display(list(dish1))

price2 = ET.SubElement(dish2, "price").text = "20"
weight2 = ET.SubElement(dish2, "weight").text = "200"
class2 = ET.SubElement(dish2, "class").text = "Крупа"
display(list(dish2))

#[<Element 'price' at 0x0000025C04F08EA0>,
# <Element 'weight' at 0x0000025C04F08900>,
# <Element 'class' at 0x0000025C0D1ACEA0>]
# [<Element 'price' at 0x0000025C02BBEE00>,
# <Element 'weight' at 0x0000025C0D1ACEF0>,
# <Element 'class' at 0x0000025C0D1ACF40>]

/СОХРАНЕНИЕ XML-ФАЙЛА
В финале работы с файлом XML-формата запишем созданную нами структуру как XML-файл на диск.
Преобразуем созданный нами объект типа ElementTree.Element в строку c помощью метода tostring(), передав наше новое дерево как аргумент. Сохраним эту строку на диске, используя стандартные средства Python::
new_root_string = ET.tostring(new_root)
with open("new_menu.xml", "wb") as f:
    f.write(new_root_string)

Возможно, вы увидите проблему, связанную с кодировкой. Что делать в этом случае? 
Как вариант — записать файл, используя сам класс ElementTree() :
ET.ElementTree(new_root).write('new_menu_good.xml', encoding="utf-8")
Для этого мы передаём в класс ElementTree() наше дерево (не его строковое представление) и вызываем метод write(). 
В метод мы передаём путь к новому файлу и нужную нам кодировку.
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






17
///////////////////////////////////
///Получение данных из интернет///
/////////////////////////////////
//Библиотека requests
pip install requests 

Получим курсы валют от ЦБ
import requests # Импортируем библиотеку requests
url = 'https://www.cbr-xml-daily.ru/daily_json.js' # Определяем значение URL страницы для запроса
response = requests.get(url) # Делаем GET-запрос к ресурсу и результат ответа сохраняем в переменной response

print(response) # Выводим значение response на экран как объект
<Response [200]>
    200 — запрос был корректным и сервер отдал нам нужную информацию
    404 — страница по указанному адресу не найдена, а значение 
    403 — синтаксис GET-запроса неверный.

/Работаем с ответом
Текст ответа хранится в атрибуте text. Выведем значение атрибута на экран и посмотрим на его содержимое:

print(response.text) # Выводим содержимое атрибута text переменной response на экран
{
    "Date": "2021-12-08T11:30:00+03:00",
    "PreviousDate": "2021-12-07T11:30:00+03:00",
    "PreviousURL": "\/\/www.cbr-xml-daily.ru\/archive\/2021\/12\/07\/daily_json.js",
    "Timestamp": "2021-12-07T17:00:00+03:00",
    "Valute": {
        "AUD": {
            "ID": "R01010",
            "NumCode": "036",
            "CharCode": "AUD",
            "Nominal": 1,
            "Name": "Австралийский доллар",
            "Value": 52.6319,
            "Previous": 51.7233
        },
        "AZN": {
            "ID": "R01020A",
            "NumCode": "944",

Для того чтобы удобно было работать с полученной информацией, нам необходимо преобразовать строку в словарь. В объект ответа Response  из библиотеки requests уже встроен метод json() .

Импортируем функцию pprint(), применим к полученному ответу метод json() и выведем полученный результат на экран:
from pprint import pprint # Импортируем функцию pprint()
currencies = response.json() # Применяем метод json()
pprint(currencies) # Выводим результат на экран)
{'Date': '2021-12-08T11:30:00+03:00',
 'PreviousDate': '2021-12-07T11:30:00+03:00',
 'PreviousURL': '//www.cbr-xml-daily.ru/archive/2021/12/07/daily_json.js',
 'Timestamp': '2021-12-07T17:00:00+03:00',
 'Valute': {'AMD': {'CharCode': 'AMD',
                    'ID': 'R01060',
                    'Name': 'Армянских драмов',
                    'Nominal': 100,
                    'NumCode': '051',
                    'Previous': 14.9963,
                    'Value': 15.0921},
            'AUD': {'CharCode': 'AUD',
            ......

//Библиотека BeautifulSoup

pip install beautifulsoup4 

from bs4 import BeautifulSoup # Импортируем библиотеку BeautifulSoup
Теперь мы можем извлекать данные из любой веб-страницы.

import requests # Импортируем библиотеку requests
from bs4 import BeautifulSoup # Импортируем библиотеку BeautifulSoup
url = 'https://nplus1.ru/news/2021/10/11/econobel2021' # Определяем адрес страницы
response = requests.get(url) # Выполняем GET-запрос, содержимое ответа присваивается переменной response
page = BeautifulSoup(response.text, 'html.parser') # Создаём объект BeautifulSoup, указывая html-парсер
print(page.title) # Получаем тег title, отображающийся на вкладке браузера
print(page.title.text) # Выводим текст из полученного тега, который содержится в атрибуте text

/ИЗВЛЕКАЕМ ЗАГОЛОВОК И ВРЕМЯ НАПИСАНИЯ СТАТЬИ
print(page.find('h1').text) # Применяем метод find() к объекту и выводим результат на экран

Но как же узнать, в каких именно тегах заключена необходимая информация?

Проще всего это сделать с помощью так называемого инструмента разработчика, который есть во всех современных браузерах. 
Покажем, как открыть данный инструмент на примере использования браузера Google Chrome.

/НЕУНИКАЛЬНЫЕ ТЕГИ: ИЗВЛЕКАЕМ ТЕКСТ СТАТЬИ
При нескольких повторах тега в разных частях, нужно применять классы
print(page.find('div', class_='body').text) # Выводим содержимое атрибута text тега div класса body js-mediator-article

/СБОР НЕСКОЛЬКИХ ЭЛЕМЕНТОВ: СОБИРАЕМ ВСЕ ССЫЛКИ НА СТРАНИЦЕ
url = 'https://en.wikipedia.org/wiki/List_of_programming_languages' # Задаём адрес ресурса
response = requests.get(url) # Делаем GET-запрос к ресурсу
page = BeautifulSoup(response.text, 'html.parser') # Создаём объект BeautifulSoup
print(page.find('a')) # Ищем ссылку по тегу <a> и выводим её на экран


links = page.find_all('a') # Ищем все ссылки на странице и сохраняем в переменной links в виде списка
print(len(links)) # Выводим количество найденных ссылок

print([link.text for link in links[500:510]]) # Выводим ссылки с 500 по 509 включительно

print([link.text for link in links[0:10]]) # Выводим ссылки с 1 по 9 включительно

//API

/КЛЮЧ АВТОРИЗАЦИИ
сервисный ключ авторизации — токен
vk.com SF_Vezdexod
c09ca0c7c09ca0c7c09ca0c776c0e6d236cc09cc09ca0c7a129001f2c1071015ac70010

/ПЕРВЫЕ ЗАПРОСЫ К API
https://api.vk.com/method/users.get?user_id=1&v=5.95&access_token=c09ca0c7c09ca0c7c09ca0c776c0e6d236cc09cc09ca0c7a129001f2c1071015ac70010
{"response":[{"first_name":"Павел","id":1,"last_name":"Дуров","can_access_closed":true,"is_closed":false}]}


Итак, мы сделали GET-запрос к API ВКонтакте, который состоит из следующих элементов:

https://api.vk.com/method — домен и URL запроса API; обычно не меняется;
users.get — название метода, который отдаёт определённый отчёт, в нашем случае это метод для получения информации о пользователе;
user_id и v — параметры запроса: идентификатор пользователя, о котором хотим получить информацию (в нашем примере мы запрашиваем информацию о первом пользователе), и номер версии API;
token — токен, который выдаётся только пользователям, имеющим право просматривать определённые данные, например показания счётчиков Яндекс.Метрики вашего проекта; на все остальные запросы без корректного токена система отвечает отказом.

/ЗАПРОС К API ИЗ КОДА
import requests # Импортируем модуль requests
token = ' ... ' # Указываем свой сервисный токен
url = 'https://api.vk.com/method/users.get' # Указываем адрес страницы к которой делаем запрос
params = {'user_id': 1, 'v': 5.95, 'fields': 'sex,bdate', 'access_token': token, 'lang': 'ru'} # Перечисляем параметры нашего запроса в словаре params
response = requests.get(url, params=params) # Отправляем запрос
print(response.text) # Выводим текст ответа на экран

/СБОР ИНФОРМАЦИИ ИЗ ГРУПП
Согласно документации, обязательным параметром данного метода является group_id — идентификатор, или короткое имя, группы. В нашем случае это vk: https://vk.com/vk. Протестируем, как работает метод в самом простом случае, — получим id участников группы:

import requests # Импортируем модуль requests
token = ' ... ' # Указываем свой сервисный токен
url = 'https://api.vk.com/method/groups.getMembers' # Указываем адрес обращения
params = {'group_id': 'vk', 'v': 5.95, 'access_token': token} # Формируем строку параметров
response = requests.get(url, params = params) # Посылаем запрос
data = response.json() # Ответ сохраняем в переменной data в формате словаря
print(data) # Выводим содержимое переменной data на экран (отображён фрагмент)

По ключу count мы можем получить общее число участников группы, а список по ключу items хранит их id. Посмотрим на него поближе:

print(len(data['response']['items'])) # Выводим на экран количество элементов словаря
#1000

Мы видим, что всего пользователей в группе больше 11 миллионов, а получили мы только первую тысячу пользователей группы. По информации, указанной в документации о параметре count, это максимум, который может отдать API за один раз.

Для получения следующей тысячи пользователей можно воспользоваться параметром offset (с англ. смещение), который передвинет начало отсчёта. Для выгрузки всех пользователей группы будем в цикле выгружать по 1000 пользователей (count будет всегда равен 1000), увеличивая смещение offset на величину count.

Для тренировки напишем цикл выгрузки первых 20 пользователей со значением count=5. Иными словами, мы будем выгружать по пять пользователей за запрос до тех пор, пока не получим информацию о 20 пользователях.

Давайте выведем на экран первые 20 пользователей из нашей первой попытки получить информацию о 1000 пользователей, чтобы мы могли сверить результат выгрузки из 20 пользователей:

users_for_checking = data['response']['items'][:20] # Загружаем в переменную информацию об id первых 20 пользователей в виде списка
print(users_for_checking) # Выводим перечень id первых 20 пользователей

Теперь используем count и offset, чтобы получить те же id по пять за раз:

import requests # Импортируем модуль requests
token = ' ... ' # Указываем свой сервисный токен
url = 'https://api.vk.com/method/groups.getMembers' # Указываем адрес обращения
count = 5 
offset = 0 
user_ids = [] 
max_count = 20 
while offset < max_count: 
    # Будем выгружать по count=5 пользователей, 
    # начиная с того места, где закончили на предыдущей итерации (offset) 
    print('Выгружаю {} пользователей с offset = {}'.format(count, offset))   
    params = {'group_id': 'vk', 'v': 5.95, 'count': count, 'offset': offset, 'access_token': token} 
    response = requests.get(url, params = params) 
    data = response.json() 
    user_ids += data['response']['items'] 
    # Увеличиваем смещение на количество строк, которое мы уже выгрузили 
    offset += count 
print(user_ids) 
#Выгружаю 5 пользователей с offset = 0
#Выгружаю 5 пользователей с offset = 5
#Выгружаю 5 пользователей с offset = 10
#Выгружаю 5 пользователей с offset = 15
#[5, 6, 19, 34, 47, 54, 79, 177, 193, 198, 212, 219, 239, 243, 254, 345, 404, 406, 407, 467]

/ОГРАНИЧЕНИЕ ПО ЧАСТОТЕ ЗАПРОСОВ

→ В API часто добавляют ограничение по частоте запросов, чтобы отдельно взятые пользователи слишком сильно не перегружали сервер. 
Подобное ограничение есть и у ВКонтакте — в документации указано, что можно делать не более трёх запросов в секунду.

Воспользуемся библиотекой time и методом sleep, с помощью которого мы можем добавить паузу, например в 0.5 секунд, после каждого запроса:

import requests # Импортируем модуль requests
import time # Импортируем модуль time
token = ' ... ' # Указываем свой сервисный токен
url = 'https://api.vk.com/method/groups.getMembers' # Указываем адрес страницы, к которой делаем запрос
count = 1000 
offset = 0  
user_ids = []  
while offset < 5000: 
    params = {'group_id': 'vk', 'v': 5.95, 'count': count, 'offset': offset, 'access_token': token} 
    response = requests.get(url, params = params) 
    data = response.json() 
    user_ids += data['response']['items'] 
    offset += count 
    print('Ожидаю 0.5 секунды...') 
    time.sleep(0.5) 
print('Цикл завершен, offset =',offset) 

/ЛАЙКИ, РЕПОСТЫ И КОММЕНТАРИИ

Для получения информации о сообщениях на стене в API ВКонтакте предусмотрен метод wall.get. Применим его:

import requests # Импортируем модуль requests
from pprint import pprint # Импортируем функцию pprint()
token = ' ... ' # Указываем свой сервисный токен
url = 'https://api.vk.com/method/wall.get' # Указываем адрес страницы, к которой делаем запрос
params = {'domain': 'vk', 'filter': 'owner', 'count': 1000, 'offset': 0, 'access_token': token, 'v': 5.95} 
response = requests.get(url, params = params) 
pprint(response.json()) 

Посмотрим на информацию об отдельном сообщении:
response.json()['response']['items'][0] 

Давайте соберём итоговую статистику для последних десяти непустых сообщений в словарь stats. В качестве ключа будем использовать начало сообщения (если начало сообщения пустое, то информацию о таком сообщении проигнорируем), в качестве значения — список с тремя интересующими нас метриками и временем публикации (комментарии, лайки, репосты, дата публикации):

stats = {} 
count_post = 0 # Счётчик «непустых» сообщений
for record in response.json()['response']['items'][:]:
    title = record['text'][:30] 
    if title: 
        stats[title] = [record['comments']['count'], record['likes']['count'], record['reposts']['count'], record['date']] 
        count_post += 1 
    if count_post < 10: 
        continue 
    else: 
        break 
pprint(stats)


//Как настроить регулярную выгрузку данных
/СКРИПТЫ
Как уже говорилось, скриптом принято называть небольшую компьютерную программу, которая автоматизирует выполнение некоторой задачи. 
Программы, которые мы создаём на языке Python, также являются скриптами.

В этом случае вам нужен автоматический запуск скриптов, или, как часто его называют программисты, запуск по крону — от английского 
акронима Cron (англ. Command Run ON) — названия системы для автоматического запуска программ и скриптов на сервере в определённое время.

/КАК НАСТРОИТЬ АВТОМАТИЧЕСКИЙ ЗАПУСК
Исполняемый по расписанию код часто называют задачей (англ. task). 
Для планирования задач в Python есть несколько библиотек, среди которых — популярный и простой в использовании модуль schedule (c англ. расписание). 
Он позволяет запускать код как с определённым интервалом, так и в заданное время.

pip install schedule 

import schedule # Импортируем модуль schedule

def task(): 
    print('Hello! I am a task!') 
    return 

schedule.every(15).minutes.do(task)

Если бы мы хотели запускать задачу, например, каждый час, то могли бы написать:
schedule.every(1).hour.do(task) 

Для создания паузы мы будем использовать метод sleep из модуля time, поэтому наш код начнётся с импорта данного модуля:

import time 
while True: 
    schedule.run_pending() 
    time.sleep(1) 



















/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






5.2
///////////////
///METABASE///
/////////////
SQL
Чтобы затегать используем:
/* Такак конструкция
для множества символов*/
либо
--такая для строки

ctrl+enter - Запуск
ЕСли выделить и запустить, то выполнится только выделенная часть

//ШАБЛОН ЗАПРОСА
SELECT
    столбец1 AS новое_название,
    столбец2,
    столбец3
FROM таблица
WHERE (условие1 OR условие2)
    AND условие3
ORDER BY сортировка1, сортировка2
OFFSET 1 LIMIT 2

SELECT [ALL | DISTINCT] список_столбцов|*
FROM список_имён_таблиц
[WHERE условие_поиска]
[GROUP BY список_имён_столбцов]
[HAVING условие_поиска]
[ORDER BY имя_столбца [ASC | DESC],…]

SELECT
    столбец1 AS новое_название,
    столбец2,
    АГРЕГАТ(столбец3)
FROM таблица
WHERE (условие1 OR условие2)
    AND условие3
GROUP BY столбец1, столбец2
HAVING АГРЕГАТ(столбец3) > 5
ORDER BY сортировка1, сортировка2
OFFSET 1 LIMIT 2

Соединение таблиц
SELECT 
         N columns
FROM 
         table_1

UNION / UNION ALL / EXCEPT / INTERSECT 

SELECT 
         N columns
FROM 
         table_2

//Запросы
Выводит первые 2500 строк
SELECT /*выбрать столбцы*/ Если * то все столбцы
    director, /*столбец director*/
    movie_title, /*столбец movie_title*/
    10 - rating AS difference /*столбец, значения в котором равны разнице 10 и каждого соответствующего значения столбца rating; присвоить столбцу алиас difference*/
FROM sql.kinopoisk /*из таблицы sql.kinopoisk*/

Новое имя является просто псевдонимом, или алиасом, — оно временное и не меняет реального имени столбца в базе данных. 
Алиас влияет только на то, как столбец отображается в выводе конкретного запроса.
Алиасом может быть как одно слово, так и несколько, а его написание — как латиницей, так и кириллицей.
Обратите внимание! Если в алиасе используется кириллица или пробелы, необходимо заключать его 
в двойные кавычки: 10 - rating AS "разница" или movie_title AS "Movie Title".

SELECT * /*выбор всех столбцов*/
FROM sql.kinopoisk /*из таблицы sql.kinopoisk*/
WHERE position = 1 /*с позицией 1*/

SELECT *
FROM sql.kinopoisk 
WHERE year <> 2000   != и <> это одно и то же
AND rating >= 8

SELECT * /*выбор всех полей*/
FROM sql.kinopoisk /*из таблиц sql.kinopoisk*/
WHERE year BETWEEN 1975 AND 1985 /*при условии, что год создания лежит в промежутке между 1975 и 1985*/
                                    1975 <= x <= 1985

SELECT * /*выбор всех полей*/
FROM sql.kinopoisk /*из таблицы sql.kinopoisk*/
WHERE year NOT BETWEEN 1965 AND 1980 /*при условии, что год создания не лежит в промежутке между 1965 и 1980*/

SELECT /*выбор*/
    year, /*столбец year*/
    movie_title, /*столбец movie_title*/
    director /*столбец director*/
FROM sql.kinopoisk /*из таблицы sql.kinopoisk*/
WHERE (rating > 8.5 AND year < 2000) /*при условии, что рейтинг больше 8.5 и год создания до 2000*/
    OR year >= 2000 /*или год создания — 2000 и позднее*/
    
SELECT movie_title
FROM sql.kinopoisk
WHERE year IN (2000, 1985, 1939)

SELECT * /*выбор всех полей*/
FROM sql.kinopoisk /*из таблицы sql.kinopoisk*/
WHERE director = 'Леонид Гайдай' /*где режиссёр Леонид Гайдай*/

SELECT * /*выбор всех полей*/
FROM sql.kinopoisk /*из таблицы sql.kinopoisk*/
WHERE movie_title LIKE 'А%' /*если название фильма начинается на А*/
                                % - множество символов
                                _ - ровно один символ

SELECT * /*выбор всех полей*/
FROM sql.kinopoisk /*из таблицы sql.kinopoisk*/
WHERE overview IS NULL /*если у фильма отсутствует описание*/
Важно! NULL — это специальное значение. Если вы фильтруете столбец, в котором есть пустые значения, 
по любому условию, кроме IS NULL / IS NOT NULL, такие значения будут исключены из вывода.                                

SELECT /*выбор*/
    director, /*столбец director*/
    movie_title /*столбец movie_title*/
FROM sql.kinopoisk /*из таблицы sql.kinopoisk*/
ORDER BY year, rating DESC /*сортировка по столбцам year и rating в порядке убывания*/

SELECT /*выбор*/
    director, /*столбец director*/
    movie_title, /*столбец movie_title*/
    year /*столбец year*/
FROM sql.kinopoisk /*из таблицы sql.kinopoisk*/
ORDER BY 1, 3 DESC /*сортировка по первому и третьему столбцам*/

3.3
SELECT
    movie_title AS "Название фильма"
FROM sql.kinopoisk
WHERE rating > 8.3 
AND country = 'Франция'
ORDER BY rating DESC, year DESC

SELECT /*выбор*/
    movie_title, /*столбец movie_title*/
    rating /*столбец rating*/
FROM sql.kinopoisk /*из таблицы sql.kinopoisk*/
ORDER BY rating DESC /*сортировка по столбцу rating в порядке убывания*/
LIMIT 5 /*ограничить пятью значениями*/
OFFSET 5 /*обрезать пять значений*/

SELECT 
    movie_title
FROM sql.kinopoisk
WHERE year > 1990
AND country != 'Россия'
ORDER BY rating DESC
OFFSET 19
LIMIT 28 (LIMIT 47, но так как мы обрезали 19, обрезаем 28)

//ПРОСТЫЕ ОПЕРАЦИИ С ДАННЫМИ В METABASE
Со столбцами, которые содержат числовые данные, можно проводить арифметические операции:
    сложение с помощью + ;
    вычитание с помощью - (этот тип операции вы уже проводили, когда определяли «возраст» фильма);
    умножение с помощью * ;
    деление с помощью / ;
    получение остатка от деления с помощью % .

//Конструкции с in
Конструкции с IN имеют следующий вид:
column IN (value1, value2, value3)
Эта запись аналогична следующей: 
column = value1 OR column = value2 OR column = value3 — но выглядит проще и компактнее.

//СОРТИРОВКА ПО ВОЗРАСТАНИЮ
SELECT /*выбор*/
    movie_title, /*столбец movie_title*/
    director, /*столбец director*/
    screenwriter, /*столбец screenwriter*/
    year /*столбец year*/
FROM sql.kinopoisk /*из таблицы sql.kinopoisk*/
WHERE country = 'СССР' /*при условии, что страна производства — СССР*/
ORDER BY rating DESC /*сортировка по рейтингу в порядке убывания*/
                ASC  /*сортировка по рейтингу в порядке возрастания*/
                

Также в ORDER BY можно указывать, где должны идти пустые значения — в начале или в конце.
Такая настройка порядка вывода задаётся с помощью ключевых слов NULLS FIRST / NULLS LAST.

2.1.5.3
SELECT 
    movie_title AS "Название фильма",
    director AS "Режиссёр",
    screenwriter AS "Сценарист",
    actors AS "Актёры"
FROM sql.kinopoisk
WHERE ((rating BETWEEN 8 AND 8.5) OR year < 1990) (ещё есть конструкция rating in (8, 8.3, 8.5) которая выведет рейтинги 8, 8.3, 8.5)
    AND overview IS NOT NULL
    AND NOT ((movie_title LIKE 'Т%'))
    AND (movie_title LIKE '____________')
ORDER BY rating DESC
LIMIT 7

//АГРЕГАТНЫЕ ОБЪЕДИНЯЮЩИе ФУНКЦИИ
SELECT DISTINCT /*выбрать уникальные значения*/
    type1, /*столбец type1*/
    type2 /*столбец type2*/
FROM sql.pokemon /*из таблицы sql.pokemon*/

SELECT
    COUNT(type2) /*Посчитать число не нулевых строк*/
FROM sql.pokemon

SELECT /*выбор*/
    COUNT(DISTINCT type1) /*функция подсчёта строк; уникальные значения столбца type1*/
FROM sql.pokemon /*из таблицы sql.pokemon*/

/Основные агрегатные функции
    COUNT — вычисляет число непустых строк;
    SUM — вычисляет сумму;
    AVG — вычисляет среднее;
    MAX — вычисляет максимум;
    MIN — вычисляет минимум.

SELECT /*выбор*/
    COUNT(*) AS "всего травяных покемонов", /*подсчёт всех строк; назначить алиас "всего травяных покемонов"*/
    COUNT(type2) AS "покемонов с дополнительным типом", /*подсчёт непустых строк в столбце type2; назначить алиас "покемонов с дополнительным типом"*/
    AVG(attack) AS "средняя атака", /*среднее значение столбца attack; назначить алиас "средняя атака"*/
    AVG(defense) AS "средняя защита" /*среднее значение столбца defense; назначить алиас "средняя защита"*/
FROM sql.pokemon /*из таблицы sql.pokemon*/
WHERE type1 = 'Grass'/*при условии, что значение столбца type1 содержит grass*/

2.2.3.5
SELECT 
    COUNT(*) AS "pokemon_count", 
    AVG(speed) AS "avg_speed",
    MAX(hp) AS "max_hp",
    MIN(hp) AS "min_hp"
FROM sql.pokemon 
WHERE type1 = 'Electric'
AND (attack > 50 OR defense > 50)
AND type2 IS NOT NULL

/Сортировка GROUP BY
SELECT /*выбор*/
    type1 AS pokemon_type, /*столбец type1; присвоить алиас pokemon_type*/
    COUNT(*) AS pokemon_count /*подсчёт всех строк; присвоить алиас pokemon_count*/
FROM sql.pokemon /*из таблицы sql.pokemon*/
GROUP BY type1 /*группировка по столбцу type1*/
ORDER BY type1 /*сортировка по столбцу type1*/

SELECT /*выбор*/
    type1 AS primary_type, /*столбец type1; присвоить алиас primary_type*/
    type2 AS additional_type, /*столбец type2; присвоить алиас additional_type*/
    COUNT(*) AS pokemon_count /*подсчёт всех строк присвоить алиас pokemon_count*/
FROM sql.pokemon /*из таблицы sql.pokemon*/
GROUP BY 1, 2 /*группировка по столбцам 1 и 2*/
ORDER BY 1, 2 NULLS FIRST /*сортировка по столбцам 1 и 2; сначала нули*/

2.2.4.1
SELECT 
    type1 AS "primary_type",
    COUNT(DISTINCT type2) AS "additional_types_count", 
    AVG(hp) AS "avg_hp",
    SUM(attack) AS "attack_sum"
FROM sql.pokemon 
/*WHGROUP BY primary_typeERE 1*/
GROUP BY primary_type
ORDER BY additional_types_count DESC, primary_type

//WHERE and HAVING
WHERE - Пишется перед GROUP BY
HAVING - Пишется сразу за GROUP BY

SELECT /*выбор*/
    type1 AS primary_type, /*таблица type1; присвоить алиас primary_type*/
    AVG(attack) AS avg_attack /*расчёт среднего по столбцу attack; присвоить алиас avg_attack*/
FROM sql.pokemon /*из таблицы sql.pokemon*/
GROUP BY primary_type /*группировать по столбцу primary_type*/
HAVING AVG(attack) > 90 /*фильтровать по среднему значению attack, првышающему 90*/

2.2.5.1
SELECT 
    type1 AS "primary_type",
    type2 AS "additional_type"
FROM sql.pokemon
GROUP BY primary_type, additional_type
HAVING AVG(attack) > 100
    AND MAX(hp) < 80

2.3.1.2
select 
    season,
    SUM(home_team_goals) AS total_home_goals,
    SUM(away_team_goals) AS total_away_goals
from sql.matches
GROUP BY season
ORDER BY season

//ОБЪЕДИНЕНИЕ ТАБЛИЦ
/Декартово произведение таблиц
Каждая строка одной таблицы соединяется со строкой 2 таблицы
SELECT * /*выбор всех полей*/
FROM
    sql.teams, /*таблица с командами*/
    sql.matches /*таблица с матчами*/

Таким образом
1 1
2 1
3 1
1 2
2 2 
3 2

/Объединение по столбцу
SELECT * /*выбор всех полей в таблице*/
FROM
    sql.teams, /*таблица с командами*/
    sql.matches /*таблица с матчами*/
WHERE home_team_api_id = api_id /*условие: home_team_api_id таблицы matches равен api_id таблицы teams*/

Аналогично можем получить данные о гостевых командах: необходимо изменить условие на
where away_team_api_id = api_id
SELECT * /*выбор всех полей в таблицы*/
FROM
    sql.teams, /*таблица с командами*/
    sql.matches /*таблица с матчами*/
WHERE away_team_api_id = api_id /*условие: away_team_api_id таблицы matches равен api_id таблицы teams*/

Ключи бывают двух основных типов:

Primary — первичный ключ — служит для идентификации текущей таблицы и, как правило, идёт первым в списке столбцов. 
    Всегда уникален: повторяющихся значений в основной таблице быть не может.
Foreign — внешний ключ — представляет собой ссылку на другую таблицу.

С использованием опкратора JOIN

SELECT 
    long_name, /*столбец long_name таблицы teams*/
    home_team_goals, /*столбец home_team_goals таблицы matches*/
    away_team_goals /*столбец away_team_goals таблицы matches*/
FROM    
    sql.teams /*таблица с командами*/
JOIN sql.matches on home_team_api_id = api_id /*оператор соединения таблиц; таблица matches; условие: home_team_api_id таблицы matches равен api_id таблицы teams*/

/СИНТАКСИС JOIN
SELECT
    столбец1 AS новое название,
	столбец2 AS новое название,
	...
FROM
	таблица1
JOIN таблица2 AS новое название ON условие
JOIN таблица3 AS новое название ON условие

/СОЕДИНЕНИЕ ТАБЛИЦ С ПОМОЩЬЮ UNION
В запросе мы использовали оператор UNION ALL — он присоединяет любой результат запроса к другому «снизу» при условии, что у них одинаковая структура, а именно:
    одинаковый тип данных;
    одинаковое количество столбцов;
    одинаковый порядок столбцов согласно типу данных.

SELECT 
    book_name object_name, 'книга' object_descritption /*выбираем столбец с названием book_name, задаём алиас для столбца object_name, задаём во второй колонке объект ‘книга’ с алиасом дня столбца object_descritption*/
FROM public.books /*из схемы public и таблицы books*/

UNION ALL /*оператор присоединения*/

SELECT 
    movie_title, 'фильм' /*выбираем столбец movie_title, сами задаём во второй колонке объект ‘фильм’*/
FROM sql.kinopoisk /*из схемы sql и таблицы kinopoisk*/

Оператор присоединения существует в двух вариантах:
    UNION выводит только уникальные записи;
    UNION ALL присоединяет все строки последующих таблиц к предыдущим, без ограничений по уникальности.
Важно! UNION оставляет только уникальные значения, а потому требует дополнительных вычислительных мощностей 
и памяти (в данном случае можно провести аналогию с DISTINCT). 
Поэтому если вы уверены в отсутствии дубликатов в данных или они вам не важны, предпочтительнее использовать UNION ALL.

Для отделения запросов используются скобки
(SELECT book_name object_name, 'книга' object_descritption 
FROM public.books
ORDER BY 1
LIMIT 1)
UNION ALL
(SELECT movie_title, 'фильм' 
FROM sql.kinopoisk
ORDER BY 1
LIMIT 1)

/Изменение типа данных
Чтобы перевести city_id в текст, нам потребуется написать city_id::text.











/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






5.2
////////////////////////////////////////////////////////////////////////
///EDA (Exploratory Data Analysis) — разведывательный анализ данных.///
//////////////////////////////////////////////////////////////////////
Этот этап дата-сайентисты проводят перед построением самой модели. 
Цель этого этапа — понять, что нам могут дать данные, и как признаки могут быть взаимосвязаны между собой. 
Понимание изначальных признаков позволит создать новые, более сильные признаки и повысить качество модели. 

//МЕТОД FEATURE ENGINEERING (ПРОЕКТИРОВАНИЕ ПРИЗНАКОВ)
Цель этого метода — создать новые, более сильные признаки для обучения модели.

//МЕТОД FEATURE SELECTION (ОТБОР ПРИЗНАКОВ)
Это процесс выбора признаков из общего набора данных признаков, больше всего влияющих на качество модели.

//МЕТОД КОДИРОВАНИЯ ПРИЗНАКОВ
Это процесс создания категорий в признаках.

///Мера центральной тенденции — это число, которое описывает так называемое «среднее» признака. 
Мера центральной тенденции может рассчитываться по-разному в зависимости от типа признака или от его распределения.

Далее мы рассмотрим наиболее популярные меры центральной тенденции, используемые в машинном обучении: 
среднее арифметическое, 
медиана, 
мода. 
Для расчёта этих описательных статистик в Python мы будем пользоваться библиотекой statistics. 
Она предоставляет готовые функции для вычисления математической статистики для числовых данных.

pip install statistics

import statistics

Также в библиотеке statistics есть функции, связанные с медианой, 
— функция statistics.median_low() и функция statistics.median_high().

→ В случае, когда количество элементов в числовом ряду (серии) нечётное, функции возвращают то же, что и median().

В случае, когда количество элементов чётное, у нас получается два средних значения:

median_low() возвращает меньшее из них;
median_high() возвращает большее из них.
Примечание. Если в вашем наборе данных есть пропущенные значения, функции библиотеки statistics в отличие от 
других методов (например np.median() из библиотеки numpy) будут автоматически игнорировать пропущенные значения, 
не выдавая ошибку.


statistics.mean(wine_df['price']) - среднее

statistics.median(wine_df['price']) - медиана

statistics.mode(wine_df['price']) - мода (самое встречающееся)


Мы рассмотрели самые основные и часто используемые в машинном обучении меры центральной тенденции. Также к мерам центральной тенденции относятся:

среднее геометрическое;
среднее гармоническое;
средневзвешенное и другие.
Их также можно вычислить с помощью библиотеки statistics, но они реже используются для описания распределения в машинном обучении.

Моду также можно вычислить при помощи statistics.multimode(). В случае наличия нескольких модовых (популярных значений) функция statistics.mode() 
вернёт вам ошибку StatisticsError, а statistics.multimode() — список с всеми вычисленными модовыми значениями.

///Kорреляционный анализ
Корреляция — статистическая связь двух и более переменных. 
При изменении значения одной из переменных происходит закономерное изменение другой или других величин. 

Kоэффициент корреляции. Он может принимать значение от -1 до +1.
-1 это отрицательная корреляция (обратная зависимость)
+1 это положительная корреляция (прямая зависимость)
0 это значит, что переменные независимы

Понимание корреляции приводит нас к понятию мультиколлинеарности — такой сильной 
зависимости переменных друг от друга, что она затрудняет анализ и оценку будущей модели машинного обучения. 

Отсутствие связи или очень слабая связь	    0…+/- 0.3
Слабая связь	                            +/- 0.3…+/- 0.5
Средняя связь	                            +/- 0.5…+/- 0.7
Сильная связь	                            +/- 0.7…+/- 0.9
Очень сильная или абсолютная связь	        +/- 0.9…+/-1

Для расчёта коэффициента корреляции применим функцию df.corr() библиотеки pandas.

data.corr()

Результатом функции df.corr() является матрица корреляции. 
Матрица корреляции — таблица, заголовками и строками которой являются названия признаков в датасете. 
На пересечении строк и столбцов находится значение коэффициента корреляции этих двух признаков.
Данная матрица имеет значение 1 по главной диагонали, так как единица означает корреляцию признака с самим собой. 
Матрица является симметричной.

→ Аргумент method указывает на название используемого метода расчёта корреляции: 
    method = 'pearson' — корреляция Пирсона, (стандартная, если не указано другое значение method)
    method = 'kendall' — корреляция Кендалла, 
    method = 'spearman' — корреляция Спирмена. 

Каждый метод может быть применён для разных типов данных. 

/КОРРЕЛЯЦИЯ ПИРСОНА
Определить существование линейной связи в паре признаков эмпирическим путём можно, если вы можете сформулировать 
фразу следующего содержания: «С уменьшением/увеличением признака1, уменьшается/увеличивается признак2». 

Для большинства непрерывных признаков это подходящий метод вычисления коэффициента корреляции. 
Однако при его использовании вы предполагаете, что признаки приблизительно нормально распределены и не имеют выбросов.

/КОРРЕЛЯЦИЯ СПИРМЕНА
Коэффициент корреляции Спирмена используется для вычисления взаимосвязей между категориальными переменными.

/КОРРЕЛЯЦИЯ КЕНДАЛЛА

Так же, как и корреляция Спирмена, корреляция Кендала предусмотрена для нахождения взаимосвязей между категориальными переменными. 

Корреляции Спирмена и Кендалла очень похожи. Чтобы понять их различия, необходимо глубокое погружение в их математическую природу. 
Однако в среднем корреляция Кендала выдаёт меньшие значения коэффициента корреляции, чем корреляция Спирмена. 

Корреляция Кендалла более устойчива к ошибкам и выбросам в данных. 
Это значит, что её можно применить до очистки данных, чтобы выявить взаимосвязи заранее. 
Применение в этом случае корреляции Спирмена, как и корреляции Пирсона, не вызовет ошибки, но, скорее всего, 
некорректность расчёта приведёт к неверным выводам.

/КОРРЕЛЯЦИЯ МЭТЬЮСА
Бинарные признаки являются подгруппой категориальных. 
Мы по-прежнему можем использовать методы ранговых корреляций для расчёта связи между переменными. 

Кроме этого, существует корреляция Мэтьюса — мера силы связи между бинарными переменными.

В df.corr() нет расчёта для корреляции Мэтьюса, но мы можем воспользоваться библиотекой scikit-learn и её 
функцией matthews_corrcoef() для расчёта коэффициента корреляции Мэтьюса.

scikit-learn — это библиотека с реализацией готовых алгоритмов для машинного обучения. 

pip install scikit-learn

from sklearn.metrics import matthews_corrcoef

//МАТРИЦА КОРРЕЛЯЦИЙ

import seaborn as sns

//ПОСТРОЕНИЕ ТЕПЛОВОГО ГРАФИКА
sns.heatmap(data.corr(), annot = True)

//ГРАФИК ОТНОШЕНИЯ 2Х ПРИЗНАКОВ
Точечная диаграмма рассеивания — это такая диаграмма, 
в которой каждое значение, которое принимает признак в датасете, отражено точкой.

Возьмём для примера две пары признаков:

по оси x="Waist/Hip" — соотношение обхвата талии/бедер, по оси y="Waist" — обхват талии;
по оси x="Weight" — индекс массы тела, а по оси y="Year" — вес модели.
Построим для них точечную диаграмму:

sns.scatterplot(data=data, x="Waist/Hip", y="Waist")

/ГРАФИК ПОПАРНЫХ ОТНОШЕНИЙ PAIRPLOT

sns.pairplot(data)
Строит сразу много графиков всех переменных на одной фигуре
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






EDA 3 
///////////////////////////////
///ПРОЕКТИРОВАНИЕ ПРИЗНАКОВ///
/////////////////////////////
/Округления
# для удобства сразу преобразуем признак в int
data['price_round'] = data['price'].round().astype(int)

/Разбор текста
Регулярные выражения (regexp, или regex) — это механизм для поиска и замены текста. Это шаблоны, которые используются для поиска соответствующей части текста.

Например, с помощью такого регулярного выражения 
[^@ \t\r\n]+@[^@ \t\r\n]+\.[^@ \t\r\n]+
можно найти любой email в тексте.

regex = '\d+' # регулярное выражение для нахождения чисел
data['year'] = data['title'].str.findall(regex).str.get(0)
Однако при поиске числа методом data['title'].str.findall(regex) результатом выполнения является список найденных цифр. 
Поэтому необходимо извлечь первый элемент из списка найденных методом str.get(0), где 0 — первый элемент в списке найденных чисел.


Разберём регулярное выражение 
\d+
\d — класс символов, обозначает соответствие цифрам в диапазоне цифр [0-9];
символ + в шаблоне означает искать одно или более вхождение символа, указанного ранее. В нашем случае это числа.
Таким образом, \d+ означает поиск одной или более цифр в заданной строке.

Проверить, насколько точно работает ваше регулярное выражение, а также найти 
реализацию популярных регулярных выражений (например, поиска номера телефона), вы сможете на сайте https://ihateregex.io.

/Разбор категорий
Однако при поиске числа методом data['title'].str.findall(regex) результатом выполнения является список найденных цифр. 
Поэтому необходимо извлечь первый элемент из списка найденных методом str.get(0), где 0 — первый элемент в списке найденных чисел.

/Кодирование категориальных признаков
Ниже мы рассмотрим методы кодирования, обозначенные в блок-схеме. 
Для кодирования категориальных признаков мы будем использовать библиотеку category_encoders. 
Это удобная библиотека для кодирования категориальных переменных различными методами.


pip install category_encoders

import category_encoders as ce

Рассмотрим следующие популярные способы кодирования: 
    порядковое кодирование (Ordinal Encoding); 
    однократное кодирование (OneHot Encoding); 
    бинарное кодирование (Binary Encoding).
    Метод fit_transform устанавливает соответствия для кодирования и преобразовывает данные в соответствие с ними. Затем используем метод concat() для добавления закодированного признака в датафрейм data.

    import category_encoders as ce # импортируем библиотеку для работы с кодировщиками

    ord_encoder = ce.OrdinalEncoder()
    data_bin = ord_encoder.fit_transform(clothing[['size', 'type']])
    clothing = pd.concat([clothing, data_bin], axis=1)

    clothing


Закодируем признак type в Python. Используем класс OneHotEncoding библиотеки category_encoders. 
Укажем в cols наименование признака type для кодировки, иначе будут закодированы все строковые столбцы.

    import category_encoders as ce # импорт для работы с кодировщиком

    encoder = ce.OneHotEncoder(cols=['type']) # указываем столбец для кодирования
    type_bin = encoder.fit_transform(clothing['type'])
    clothing = pd.concat([clothing, type_bin], axis=1)

    clothing

/dummy
Напомним, что у библиотеки pandas есть дефолтный метод get_dummies() для получения 
однократного кодирования признаков. 
Однако OneHotEncoder способен принимать на вход как таблицы, так и numpy-массивы.

dummy_data = pd.get_dummies(shoppers_data)
dummy_data.head()

Закодируем признак type в Python. Используем класс BinaryEncoding библиотеки category_encoders. 
Укажем в cols наименование признака type для кодировки, иначе будут закодированы все строковые столбцы.

    import category_encoders as ce # импорт для работы с кодировщиком
    bin_encoder = ce.BinaryEncoder(cols=['type']) # указываем столбец для кодирования
    type_bin = bin_encoder.fit_transform(clothing['type'])
    clothing = pd.concat([clothing, type_bin], axis=1)

    clothing


pip install -U scikit-learn

# для нормализации, стандартизации
from sklearn import preprocessing

# Для графиков
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns

%matplotlib inline
matplotlib.style.use('ggplot')

//Нормализация
Нормализация — один из методов преобразования входных признаков, 
при котором значения признаков приводятся к заданному диапазону, например [0,...,1]. 
/MINMAXSCALER
# Копируем названия столбцов, которые теряются при использовании fit_transform()
col_names = list(df.columns)

# инициализируем нормализатор MinMaxScaler
mm_scaler = preprocessing.MinMaxScaler()

# копируем исходный датасет
df_mm = mm_scaler.fit_transform(df)

# Преобразуем промежуточный датасет в полноценный датафрейм для визуализации
df_mm = pd.DataFrame(df_mm, columns=col_names)

fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))
ax1.set_title('После нормализации MinMaxScaler')

sns.kdeplot(df_mm['beta'], ax=ax1)
sns.kdeplot(df_mm['exponential'], ax=ax1)
sns.kdeplot(df_mm['normal_p'], ax=ax1)
sns.kdeplot(df_mm['normal_l'], ax=ax1)

/ROBUSTSCALER
# Копируем названия столбцов, которые теряются при использовании fit_transform()
col_names = list(df.columns)

# инициализируем нормализатор RobustScaler
r_scaler = preprocessing.RobustScaler()

# копируем исходный датасет
df_r = r_scaler.fit_transform(df)

# Преобразуем промежуточный датасет в полноценный датафрейм для визуализации
df_r = pd.DataFrame(df_r, columns=col_names)

fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))
ax1.set_title('Распределения после RobustScaler')

sns.kdeplot(df_r['beta'], ax=ax1)
sns.kdeplot(df_r['exponential'], ax=ax1)
sns.kdeplot(df_r['normal_p'], ax=ax1)
sns.kdeplot(df_r['normal_l'], ax=ax1)

r_scaler = preprocessing.RobustScaler()
data_array = np.array(wine_df['price']).reshape(-1,1)
data_price_r = r_scaler.fit_transform(data_array)
data_price_r.sum().round()

//Стандартизация
Стандартизация — ещё один метод преобразования входных признаков, 
при котором изменяется распределение таким образом, чтобы среднее значений равнялось 0, а стандартное отклонение — 1. 

# Копируем названия столбцов, которые теряются при использовании fit_transform()
col_names = list(df.columns)

# инициализируем стандартизатор StandardScaler
s_scaler = preprocessing.StandardScaler()

# копируем исходный датасет
df_s = s_scaler.fit_transform(df)

# Преобразуем промежуточный датасет в полноценный датафрейм для визуализации
df_s = pd.DataFrame(df_s, columns=col_names)

fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))
ax1.set_title('Распределения после StandardScaler')

sns.kdeplot(df_s['beta'], ax=ax1)
sns.kdeplot(df_s['exponential'], ax=ax1)
sns.kdeplot(df_s['normal_p'], ax=ax1)
sns.kdeplot(df_s['normal_l'], ax=ax1)


/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






EDA1
/////////////////////////////
///EDA одной строкой кода///
///////////////////////////
К таким инструментам можно отнести следующие библиотеки Python, которые могут выполнять EDA всего одной строкой кода:

    d-tale; 
    pandas-profiling;
    sweetviz.

//PANDAS-PROFILING
https://github.com/ydataai/pandas-profiling

pip install pandas-profiling

import pandas as pd
from pandas_profiling import ProfileReport

df = pd.read_csv('wine.csv')
profile = ProfileReport(df, title="Wine Pandas Profiling Report")
profile


//SWEETVIZ
https://github.com/fbdesignpro/sweetviz

pip install sweetviz

import pandas as pd
import sweetviz as sv

df = pd.read_csv('wine.csv')
report = sv.analyze(my_dataframe)
report.show_html()


//D-TALE
https://github.com/man-group/dtale

pip install dtale

import pandas as pd
import dtale

df = pd.read_csv('wine.csv')
d = dtale.show(df)
d


/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






5.2
/////////////////////////////
///Доверительный интервал///
///////////////////////////
from scipy.stats import norm

n = 36 # размер выборки
x_mean = 16100 # выборочное среднее
sigma = 12000 # истинное стандартное отклонение
gamma = 0.95 # уровень надёжности
alpha = 1 - gamma # уровень значимости

z_crit = -norm.ppf(alpha/2) # z критическое
print(f"Z критическое равно: {round(z_crit,2)}")

eps = z_crit * sigma/(n ** 0.5) #погрешность
lower_bound = x_mean - eps # левая (нижняя) граница
upper_bound = x_mean + eps # правая (верхняя) граница
confidence_interval = (round(lower_bound,2), round(upper_bound,2)) # создаём кортеж из округлённых границ интервала
print('Доверительный интервал: {}'.format(confidence_interval)) # выводим результат


//Доверительный интервал по Стьюденту (по выборке)
from scipy.stats import t

n = 25 # размер выборки
k = n - 1 # число степеней свободы
x_mean = 3540 # выборочное среднее
x_std = 1150 # выборочное стандартное отклонение
gamma = 0.9 # уровень надёжности
alpha = 1 - gamma # уровень значимости

t_crit = -t.ppf(alpha/2, k) # t-критическое
print(f"T критическое равно: {round(t_crit,2)}")

eps = t_crit * x_std/(n ** 0.5) # погрешность
lower_bound = x_mean - eps # левая (нижняя) граница
upper_bound = x_mean + eps # правая (верхняя) граница
confidence_interval = (round(lower_bound), round(upper_bound)) # создаём кортеж из округлённых границ интервала
print('Доверительный интервал: {}'.format(confidence_interval)) # выводим результат


//ДОВЕРИТЕЛЬНЫЙ ИНТЕРВАЛ ДЛЯ ПРОПОРЦИИ
def proportions_conf_interval(n, x_p, gamma=0.95):   
    alpha = 1 - gamma # уровень значимости
    z_crit = -norm.ppf(alpha/2) # z критическое
    eps = z_crit * (x_p * (1 - x_p) / n) ** 0.5 #погрешность
    lower_bound = x_p - eps # левая (нижняя) граница
    upper_bound = x_p + eps # правая (верхняя) граница
    # возвращаем кортеж из округлённых границ интервала
    return round(lower_bound * 100, 2), round(upper_bound * 100, 2)

conf_interval_a = proportions_conf_interval(
n=a_data['user_id'].count(), # размер выборки
x_p=a_data['converted'].mean() # выборочная пропорция
)
conf_interval_b = proportions_conf_interval(
n=b_data['user_id'].count(), # размер выборки
x_p=b_data['converted'].mean() # выборочная пропорция
)
print('Доверительный интервал для конверсии группы А: {}'.format(conf_interval_a))
print('Доверительный интервал для конверсии группы B: {}'.format(conf_interval_b))
# Доверительный интервал для конверсии группы А: (11.86, 12.19)
# Доверительный интервал для конверсии группы B: (11.7, 12.03)

//ДОВЕРИТЕЛЬНЫЙ ИНТЕРВАЛ РАЗНИЦЫ ПРОПОРЦИЙ
def diff_proportions_conf_interval(n, xp, gamma=0.95):
    alpha = 1 - gamma # уровень значимости
    diff = xp[1] - xp[0] # выборочная разница конверсий групп B и A
    z_crit = -norm.ppf(alpha/2) # z критическое
    eps = z_crit * (xp[0] * (1 - xp[0])/n[0] + xp[1] * (1 - xp[1])/n[1]) ** 0.5 # погрешность
    lower_bound = diff - eps # левая (нижняя) граница
    upper_bound = diff + eps # правая (верхняя) граница
    # возвращаем кортеж из округлённых границ интервала
    return round(lower_bound *100, 2), round(upper_bound * 100, 2)

# размеры выборок групп А и B
n = [a_data['user_id'].count(), b_data['user_id'].count()]
# выборочная пропорция групп A и B
xp = [a_data['converted'].mean(), b_data['converted'].mean()]
# строим доверительный интервал для разности конверсий
diff_inverval = diff_proportions_conf_interval(n, xp)
print('Доверительный интервал для разности конверсий: {}'.format(diff_inverval))
 
# Доверительный интервал для разности конверсий: (-0.39, 0.08)

/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






EDA6
///////////////////
///ЛОГГИРОВАНИЕ///
/////////////////
Для логирования в Python используется модуль logging. 
Он используется большинством сторонних библиотек Python, поэтому вы можете интегрировать свои логи 
с сообщениями из этих библиотек для создания единого журнала логов приложения. Данный модуль импортируется 
как другие библиотеки:

import logging

Прежде чем приступить к логированию, необходимо установить базовые настройки:
    уровень;
    обработчик (хендлер);
    формат логирования. 

//Уровни
import logging
logging.debug('Это сообщение отладки')
logging.info('Это информационное сообщение')
logging.warning('Это сообщение-предупреждение')
logging.error('Это сообщение об ошибке')
logging.critical('Это критическое сообщение')

В приведённом ниже примере кода показано, как можно настроить уровень ведения журнала на DEBUG.

logging.basicConfig(level=logging.DEBUG)
logging.debug('Сообщение будет залогировано!')

Мы настроили уровень ведения журнала DEBUG, что означает, что будут отслеживаться только сообщения этого уровня (DEBUG) и выше.

//Обработчик (хендлер)
Обработчики являются классами модуля logging. Нам понадобится обработчик FileHandler, 
который возьмёт запись/сообщение журнала и добавит его в файл журнала log_file.log:

logging.FileHandler('log_file.log')

//Формат
Здесь формат записей журнала включает дату, время, уровень ведения журнала и само сообщение.

logging.basicConfig(format="%(levelname)s: %(asctime)s: %(message)s", level=logging.DEBUG)
logging.info('Проверка')

//Итого:

# Функция для создания лог-файла и записи в него информации
def get_logger(path, file):
  """[Создает лог-файл для логирования в него]
  Аргументы:
      path {string} -- путь к директории
      file {string} -- имя файла
   Возвращает:
      [obj] -- [логер]
  """
  # проверяем, существует ли файл
  log_file = os.path.join(path, file)
 
  #если  файла нет, создаем его
  if not os.path.isfile(log_file):
      open(log_file, "w+").close()
  
  # поменяем формат логирования
  file_logging_format = "%(levelname)s: %(asctime)s: %(message)s"
  
  # конфигурируем лог-файл
  logging.basicConfig(level=logging.INFO, 
  format = file_logging_format)
  logger = logging.getLogger()
  
  # создадим хэнлдер для записи лога в файл
  handler = logging.FileHandler(log_file)
  
  # установим уровень логирования
  handler.setLevel(logging.INFO)
  
  # создадим формат логирования, используя file_logging_format
  formatter = logging.Formatter(file_logging_format)
  handler.setFormatter(formatter)
  
  # добавим хэндлер лог-файлу
  logger.addHandler(handler)
  return logger

Для удобства лог-файлы хранят в отдельной директории. Новую папку можно создать с помощью команды mkdir:

!mkdir logs



/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






EDA6
///////////////
///Comet.ml///
/////////////
установка

pip install comet_ml

→ Comet.ml — это онлайн-платформа, позволяющая отслеживать эксперименты. 
Основное преимущество Comet состоит в том, что с её помощью можно легко построить панель отчётности и систему мониторинга.

Comet предоставляет следующие возможности:

    сравнивать эксперименты с точки зрения метрик, параметров и так далее;
    следить за моделью от создания до вывода в продакшен;
    делиться своим проектом с другими людьми, которые в режиме реального времени будут следить за результатами;
    строить отчёты исходя из результатов эксперимента;
    оставить проект приватным или сделать его общедоступным.

from comet_ml import Experiment

# Создайте эксперимент с помощью вашего API ключа
experiment = Experiment(
    api_key="УКАЖИТЕ ЗДЕСЬ СВОЙ КЛЮЧ API",
    project_name="medical-appointment",
    workspace="УКАЖИТЕ ЗДЕСЬ ИМЯ СВОЕЙ УЧЕТНОЙ ЗАПИСИ",
)

Класс Experiment — это интерфейс локального кода для Comet. 
Он определяет множество методов, описанных в официальной документации Comet. 
Платформа позволяет хранить информацию о коде, логировать графики, гиперпараметры 
модели (о них вы узнаете дальше в курсе), метрики. 

Давайте рассмотрим некоторые популярные методы:

    log_metric() и log_metrics() — логируют в эксперименте одну или несколько оценочных метрик, таких как accuracy;
    log_figure() — логирует рисунок;
    display() — создаёт интерактивную среду в Jupyter, показывающую приборную панель Comet как вывод ячейки;
    end() — если эксперимент выполняется в Jupyter, этот метод указывает, что эксперимент завершён.


/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






ML
/////////////////////////////////////
///МЕТОДЫ МАШИННОГО ОБУЧЕНИЯ (ML)///
///////////////////////////////////
см. ML_others.ipynb

//РАЗДЕЛЕНИЕ выборки
from sklearn.model_selection import train_test_split
#Разделяем выборку на тренировочную и тестовую в соотношении 70/30
#Устанавливаем random_state для воспроизводимости результатов 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)
#Выводим результирующие размеры таблиц
print('Train:', X_train.shape, y_train.shape)
print('Test:', X_test.shape, y_test.shape)



//АНАЛИТИЧЕСКОЕ РЕШЕНИЕ "РЕГРЕССИИ" С ПОМОЩЬЮ NUMPY
см ML2.ipynb
def linear_regression(X, y):
    #Создаём вектор из единиц
    ones = np.ones(X.shape[0])
    #Добавляем вектор к таблице первым столбцом
    X = np.column_stack([ones, X])
    #Вычисляем обратную матрицу Q
    Q = np.linalg.inv(X.T @ X)
    #Вычисляем вектор коэффициентов
    w = Q @ X.T @ y
    return w
#Вычисляем параметры линейной регрессии
w = linear_regression(X, y)
#Выводим вычисленные значения параметров в виде вектора
print('Vector w: {}'.format(w))
#Выводим параметры с точностью до двух знаков после запятой
print('w0 = {:.2f}'.format(w[0]))
print('w1 = {:.2f}'.format(w[1]))



//АНАЛИТИЧЕСКОЕ РЕШЕНИЕ "РЕГРЕССИИ" С ПОМОЩЬЮ SKLEARN
см ML2.ipynb
#Создаём объект класса LinearRegression
lr_lstat = linear_model.LinearRegression()
#Обучаем модель — ищем параметры по МНК
lr_lstat.fit(X, y) 
print('w0 = {}'.format(lr_lstat.intercept_)) #свободный член w0
print('w1 = {}'.format(lr_lstat.coef_)) #остальные параметры модели w1, w2, ..., wm

#Предсказываем медианную цену для всех участков из набора данных
y_predict = lr_lstat.predict(X)



//ЧИСЛЕННОЕ РЕШЕНИЕ "РЕГРЕССИИ" С ПОМОЩЬЮ SKLEARN
см ML2.ipynb
#Создаём объект класса линейной регрессии с SGD
sgd_lr_full = linear_model.SGDRegressor(random_state=42)
#Обучаем модель — ищем параметры по методу SGD
sgd_lr_full.fit(X, y)
print('w0: {}'.format(sgd_lr_full.intercept_)) #свободный член w0
print('w1: {}'.format(sgd_lr_full.coef_)) #остальные параметры модели w1, w2, ..., wm

#Предсказываем медианную цену для всех участков из набора данных
y_predict = sgd_lr_full.predict(X)
#Рассчитываем коэффициент детерминации
print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict)))



//МЕТРИКИ РЕШЕНИЯ "РЕГРЕССИИ"
см ML2.ipynb
from sklearn import metrics

#Делаем предсказание по всем признакам
y_predict_full = lr_full.predict(boston_data[features])
#Рассчитываем MAE
print('MAE score: {:.3f} thou. $'.format(metrics.mean_absolute_error(y, y_predict_full)))
#Рассчитываем RMSE
print('RMSE score: {:.3f} thou. $'.format(np.sqrt(metrics.mean_squared_error(y, y_predict_full))))
#Рассчитываем MAPE
print('MAPE score: {:.3f} %'.format(metrics.mean_absolute_percentage_error(y, y_predict_full) * 100))
#Рассчитываем коэффициент детерминации
print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict_full)))



//СМЕЩЕНИЕ (НЕДООБУЧЕНИЕ) И РАЗБРОС (ПЕРЕОБУЧЕНИЕ)
см ML2.ipynb
Стандартизацию (нормализацию) полезнее проводить перед 
генерацией полиномиальных признаков, иначе можно потерять масштаб полиномов.
#Инициализируем стандартизатор StandardScaler
scaler = preprocessing.StandardScaler()
#Подгоняем параметры стандартизатора (вычисляем среднее и СКО)
scaler.fit(X_train)
#Производим стандартизацию тренировочной выборки
X_train_scaled = scaler.transform(X_train)
#Производим стандартизацию тестовой выборки
X_test_scaled = scaler.transform(X_test)
 
#Создаём генератор полиномиальных признаков
poly = preprocessing.PolynomialFeatures(degree=2, include_bias=False)
poly.fit(X_train_scaled)
#Генерируем полиномиальные признаки для тренировочной выборки
X_train_scaled_poly = poly.transform(X_train_scaled)
#Генерируем полиномиальные признаки для тестовой выборки
X_test_scaled_poly = poly.transform(X_test_scaled)
#Выводим результирующие размерности таблиц 
print(X_train_scaled_poly.shape)
print(X_test_scaled_poly.shape)


/L1-регуляризация
#Создаём объект класса линейной регрессии с L1-регуляризацией
lasso_lr_poly = linear_model.Lasso(alpha=0.1)
#Обучаем модель
lasso_lr_poly.fit(X_train_scaled_poly, y_train)
#Делаем предсказание для тренировочной выборки
y_train_predict_poly = lasso_lr_poly.predict(X_train_scaled_poly)
#Делаем предсказание для тестовой выборки
y_test_predict_poly = lasso_lr_poly.predict(X_test_scaled_poly)
#Рассчитываем коэффициент детерминации для двух выборок
print("Train R^2: {:.3f}".format(metrics.r2_score(y_train, y_train_predict_poly)))
print("Test R^2: {:.3f}".format(metrics.r2_score(y_test, y_test_predict_poly)))

/L2-регуляризация
#Создаём объект класса линейной регрессии с L2-регуляризацией
ridge_lr_poly = linear_model.Ridge(alpha=10)
#Обучаем модель
ridge_lr_poly.fit(X_train_scaled_poly, y_train)
#Делаем предсказание для тренировочной выборки
y_train_predict_poly = ridge_lr_poly.predict(X_train_scaled_poly)
#Делаем предсказание для тестовой выборки
y_test_predict_poly = ridge_lr_poly.predict(X_test_scaled_poly)
#Рассчитываем коэффициент детерминации для двух выборок
print("Train R^2: {:.3f}".format(metrics.r2_score(y_train, y_train_predict_poly)))
print("Test R^2: {:.3f}".format(metrics.r2_score(y_test, y_test_predict_poly)))
 
ЛУЧШЕ ТА, У КОТОРОЙ ВЫШЕ ПОКАЗАТЕЛИ НА ТЕСТОВОЙ ВЫБОРКЕ

#Создаём список из 20 возможных значений от 0.001 до 1
alpha_list = np.linspace(0.001, 1, 20)
#Создаём пустые списки, в которые будем добавлять результаты 
train_scores = []
test_scores = []
for alpha in alpha_list:
    #Создаём объект класса линейной регрессии с L1-регуляризацией
    lasso_lr_poly = linear_model.Lasso(alpha=alpha, max_iter=10000)
    #Обучаем модель
    lasso_lr_poly.fit(X_train_scaled_poly, y_train)
    #Делаем предсказание для тренировочной выборки
    y_train_predict_poly = lasso_lr_poly.predict(X_train_scaled_poly)
    #Делаем предсказание для тестовой выборки
    y_test_predict_poly = lasso_lr_poly.predict(X_test_scaled_poly)
    #Рассчитываем коэффициенты детерминации для двух выборок и добавляем их в списки
    train_scores.append(metrics.r2_score(y_train, y_train_predict_poly))
    test_scores.append(metrics.r2_score(y_test, y_test_predict_poly))

#Визуализируем изменение R^2 в зависимости от alpha
fig, ax = plt.subplots(figsize=(12, 4)) #фигура + координатная плоскость
ax.plot(alpha_list, train_scores, label='Train') #линейный график для тренировочной выборки
ax.plot(alpha_list, test_scores, label='Test') #линейный график для тестовой выборки
ax.set_xlabel('Alpha') #название оси абсцисс
ax.set_ylabel('R^2') #название оси ординат
ax.set_xticks(alpha_list) #метки по оси абсцисс
ax.xaxis.set_tick_params(rotation=45) #поворот меток на оси абсцисс
ax.legend(); #отображение легенды   

//ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ В КЛАССИФИКАЦИИ С ПОМОЩЬЮ SKLEARN
#Создаем объект класса логистическая регрессия
log_reg = linear_model.LogisticRegression(random_state=42, max_iter=1000)
#Обучаем модель, минизируя logloss
log_reg.fit(X, y)
#Выводим результирующие коэффициенты
print('w0: {}'.format(log_reg.intercept_)) #свободный член w0
print('w1, w2: {}'.format(log_reg.coef_)) #остальные параметры модели w1, w2, ..., wm

#Значения концентации глюкозы и индекса массы тела для пациента
x_new = [[180, 51]]
#Делаем ПРЕДСКАЗАНИЕ ВЕРОЯТНОСТИ:
y_new_proba_predict = log_reg.predict_proba(x_new)
print('Predicted probabilities: {}'.format(np.round(y_new_proba_predict, 2)))

#Значения концентации глюкозы и индекса массы тела для пациента
x_new = [[180, 51]]
#Делаем ПРЕДСКАЗАНИЕ КЛАССА:
y_new_predict = log_reg.predict(x_new)
print('Predicted class: {}'.format(y_new_predict))

//МЕТРИКИ КЛАССИФИКАЦИИ
#Модель log_reg_full:
#Рассчитываем accuracy
print('Accuracy: {:.2f}'.format(metrics.accuracy_score(y, y_pred2)))
#Рассчитываем precision
print('Precision: {:.2f}'.format(metrics.precision_score(y, y_pred2)))
#Рассчитываем recall
print('Recall: {:.2f}'.format(metrics.recall_score(y, y_pred2)))
#Рассчитываем F1-меру
print('F1 score: {:.2f}'.format(metrics.f1_score(y, y_pred2)))

Алгоритмов сэмплирования, в том числе SMOTE, нет в стандартном пакете 
sklearn — они содержатся в библиотеке imblearn (imbalanced-learn). 
Команды для установки приведены дале

pip install imbalanced-learn
для Conda
conda install -c conda-forge imbalanced-learn

from imblearn.over_sampling import SMOTE

Примечание. Если вы используете среду Anaconda, у вас может возникнуть следующая ошибка при импорте библиотеки imblearn:

ImportError: cannot import name '_euclidean_distances' from 'sklearn.metrics.pairwise'
В этом случае обновите пакеты Anaconda:

conda update conda
После этого произведите установку пакета ещё раз:

!conda install -c conda-forge imbalanced-learn




















































/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






5.2
/////////////////
///ДЕКОРАТОРЫ///
///////////////
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






5.2
/////////////////
///ДЕКОРАТОРЫ///
///////////////
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






5.2
/////////////////
///ДЕКОРАТОРЫ///
///////////////
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






5.2
/////////////////
///ДЕКОРАТОРЫ///
///////////////
/////////////////////////////////////////////////////////////////////////////////////////////////////////////////






5.2
/////////////////
///ДЕКОРАТОРЫ///
///////////////


















































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































