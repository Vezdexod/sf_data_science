{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    " \n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import model_selection #методы разделения и валидации\n",
    "from sklearn import linear_model #линейные модели\n",
    "from sklearn import tree #деревья решений\n",
    "plt.style.use('seaborn') #стиль отрисовки seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_data = pd.read_csv('water_potability.csv')\n",
    "water_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Невооруженным глазом видно, что большинство столбцов таблицы являются числовыми. Целевой признак — Potability (пригодность для питья): 1 — вода пригодна, 0 — вода не пригодна.\n",
    "\n",
    "В данных есть пропуски. Выведем информацию о них в процентном соотношении:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 14.987790\n",
       "Hardness            0.000000\n",
       "Solids              0.000000\n",
       "Chloramines         0.000000\n",
       "Sulfate            23.840049\n",
       "Conductivity        0.000000\n",
       "Organic_carbon      0.000000\n",
       "Trihalomethanes     4.945055\n",
       "Turbidity           0.000000\n",
       "Potability          0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(water_data.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, у нас отсутствует около 15 % информации о кислотности воды (ph), около 24 % — о содержании сульфатов (Sulfate) и около 5 % — о тригалометанах (Trihalomethanes). Мы знаем, что пропуски — непосильная ноша для большинства моделей машинного обучения. Их необходимо обработать.\n",
    "\n",
    "Заполним пропуски медианным значением в признаке зависимости класса воды (Potability). Для этого сгруппируем данные по признаку Potability, посчитаем медиану в каждой группе, а затем отправим результат в метод fillna():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполняем пропуски\n",
    "water_data['ph'] = water_data['ph'].fillna(water_data.groupby('Potability')['ph'].transform('median'))\n",
    "water_data['Sulfate'] = water_data['Sulfate'].fillna(water_data.groupby('Potability')['Sulfate'].transform('median'))\n",
    "water_data['Trihalomethanes'] = water_data['Trihalomethanes'].fillna(water_data.groupby('Potability')['Trihalomethanes'].transform('median'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся в отсутствии пропусков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 0.0\n",
       "Hardness           0.0\n",
       "Solids             0.0\n",
       "Chloramines        0.0\n",
       "Sulfate            0.0\n",
       "Conductivity       0.0\n",
       "Organic_carbon     0.0\n",
       "Trihalomethanes    0.0\n",
       "Turbidity          0.0\n",
       "Potability         0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(water_data.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проблема пропусков устранена. Давайте по традиции разделим набор данных на матрицу наблюдений X и вектор правильных ответов y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = water_data.drop('Potability', axis=1)\n",
    "y = water_data['Potability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все методы разбиения выборки и валидации, которые мы будем изучать, находятся в модуле model_selection, мы импортировали его заранее.\n",
    "\n",
    "Метод hold-out реализован в уже знакомой вам функции train_test_split(). Она предназначена для разбиения исходного набора данных случайным образом на две части в заданных соотношениях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Valid shape: (656, 9)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))\n",
    "  \n",
    "## Train shape: (2620, 9)\n",
    "## Valid shape: (656, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train hold-out accuracy: 0.82\n",
      "Valid hold-out accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик\n",
    "print('Train hold-out accuracy: {:.2f}'.format(metrics.accuracy_score(y_train, y_train_pred)))\n",
    "print('Valid hold-out accuracy: {:.2f}'.format(metrics.accuracy_score(y_valid, y_valid_pred))) \n",
    " \n",
    "# Train hold-out accuracy: 0.82\n",
    "# Valid hold-out accuracy: 0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOLD-OUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если же мы используем трёхкомпонентный подход (разбиваем выборку на тренировочную, валидационную и отдельную тестовую), тут нам понадобится чуть больше кода. К сожалению, в sklearn нет специализированного функционала для такого разбиения.\n",
    "\n",
    "Применим функцию train_test_split() дважды: сначала разобьём исходный набор на тренировочный и валидационный в соотношении 80/20, затем разобьём валидационный набор на валидационный и тестовый в соотношении 50/50. В итоге наша выборка будет разбита в соотношении 80/10/10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разбиваем исходную выборку на тренировочную и валидационную в соотношении 80/20\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#разбиваем валидационную выборку на валидационную и тестовую в соотношении 50/50\n",
    "X_valid, X_test, y_valid, y_test = model_selection.train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Valid shape: (328, 9)\n",
      "Test shape: (328, 9)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))\n",
    "print('Test shape: {}'.format(X_test.shape))\n",
    "\n",
    "## Train shape: (2620, 9)\n",
    "## Valid shape: (328, 9)\n",
    "## Test shape: (328, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-FOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод k-fold более известен как кросс-валидация (cross validation), или перекрёстный контроль."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные параметры инициализатора KFold:\n",
    "\n",
    "n_split —  число фолдов (число  из метода k-fold). По умолчанию — 5.\n",
    "shuffle — параметр, указывающий, стоит ли перемешивать исходный набор данных перед разбиением. По умолчанию — False.\n",
    "random_state — число, на основе которого производится генерация случайных чисел, если набор данных будет перемешиваться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора KFold\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    "#Создаём список для хранения тренировочных и валидационных метрик\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "#Организуем цикл для кросс-валидации (используем весь набор данных)\n",
    "#train_index — индексы тренировочной выборки\n",
    "#valid_index — индексы валидационной выборки\n",
    "for train_index, valid_index in kf.split(X, y): \n",
    "    #Создаём тренировочную и валидационную выборку, обращаясь по текущим индексам\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_valid, y_valid = X.iloc[valid_index], y.iloc[valid_index]\n",
    "    #Обучаем случайный лес на тренировочной выборке\n",
    "    model.fit(X_train, y_train)\n",
    "    #Делаем предсказание для каждой из выборок\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    #Рассчитываем метрику и заносим её в список\n",
    "    train_metrics.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    val_metrics.append(metrics.accuracy_score(y_valid, y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8034351145038168, 0.8168637924456315, 0.8027470431133156, 0.8267836703548264, 0.8157191911484166]\n",
      "[0.7957317073170732, 0.7053435114503817, 0.7358778625954199, 0.7282442748091603, 0.732824427480916]\n"
     ]
    }
   ],
   "source": [
    "print(train_metrics)\n",
    "print(val_metrics)\n",
    " \n",
    "## [0.8034351145038168, 0.8168637924456315, 0.8027470431133156, 0.8267836703548264, 0.8157191911484166]\n",
    "## [0.7957317073170732, 0.7053435114503817, 0.7358778625954199, 0.7282442748091603, 0.732824427480916]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(train_metrics)))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(val_metrics)))\n",
    " \n",
    "## Train k-fold mean accuracy: 0.81\n",
    "## Valid k-fold mean accuracy: 0.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно же, нет. На самом весь приведённый выше код можно значительно сократить, если использовать специальную функцию для кросс-валидации — cross_validate() из модуля model_selection. Она организует процедуру кросс-валидации и расчёт метрик.\n",
    "\n",
    "Основные параметры функции cross_validate():\n",
    "\n",
    "estimator — модель, качество которой будет проверяться на кросс-валидации.\n",
    "X — матрица наблюдений.\n",
    "y — вектор-столбец правильных ответов.\n",
    "cv — кросс-валидатор из библиотеки sklearn (например, KFold) или количество фолдов, на которые необходимо разбить выборку. По умолчанию используется кросс-валидация на пяти фолдах.\n",
    "scoring — название метрики в виде строки либо функция для её вычисления ('accuracy', 'precision', 'recall', 'f1' и другие; полный список — в документации к функции).\n",
    "return_train_score — параметр, указывающий стоит ли возвращать значения метрики, полученных на тренировочных фолдах. По умолчанию — False, то есть метрики считаются только на валидационных фолдах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция возвращает словарь со следующими ключами:\n",
    "\n",
    "fit_time — время обучения модели на каждой итерации кросс-валидации;\n",
    "score_time — время вычисления метрик на каждой итерации кросс-валидации;\n",
    "test_score — значения метрик на валидационных фолдах;\n",
    "train_score — значения метрик на тренировочных фолдах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02599144, 0.02799058, 0.02499294, 0.02599311, 0.02799082]),\n",
       " 'score_time': array([0.00199986, 0.00199962, 0.00199866, 0.00199842, 0.00399947]),\n",
       " 'test_score': array([0.79573171, 0.70534351, 0.73587786, 0.72824427, 0.73282443]),\n",
       " 'train_score': array([0.80343511, 0.81686379, 0.80274704, 0.82678367, 0.81571919])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора KFold\n",
    "kf = model_selection.KFold(n_splits=5) # Число форлдов\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=kf, #кросс-валидатор\n",
    "    scoring='accuracy', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    "display(cv_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В массивах, хранящихся по ключам train_score и test_score, содержится по пять значений метрики accuracy, полученных на тренировочных и валидационных фолдах соответственно на каждой итерации кросс-валидации. Давайте рассчитаем среднее и сравним его с результатом, полученным ранее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))\n",
    " \n",
    "## Train k-fold mean accuracy: 0.81\n",
    "## Valid k-fold mean accuracy: 0.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEAVE-ONE-OUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке sklearn метод leave-one-out реализован в классе LeaveOneOut. Параметров инициализации у данного класса нет.\n",
    "\n",
    "Работа с кросс-валидатором полностью идентична работе с KFold, который мы рассматривали ранее (цикл для организации кросс-валидации вручную будет выглядеть аналогично).\n",
    "\n",
    "Объект класса LeaveOneOut также можно передать в функцию cross_validate() для получения метрик на каждом из примеров. В случае с метрикой accuracy список будет состоять из 0 и 1 (0 — модель не угадала класс на отложенном примере, 1 — модель угадала класс на отложенном примере).\n",
    "\n",
    "Так как датасет у нас довольно большой (более трёх тысяч образцов воды), алгоритм кросс-валидации leave-one-out будет выполняться очень долго. Для экономии времени выполнения кода будем использовать первые 500 наблюдений из исходной таблицы.\n",
    "\n",
    "Примечание. Значение метрики будет рассчитано не для всего набора данных, а только для его части. Если вы захотите рассчитать метрику на всём наборе данных, вместо среза передавайте в функцию таблицу X и столбец y целиком. Но имейте в виду, что код в таком случае может выполняться до нескольких минут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.95\n",
      "Valid k-fold mean accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём кросс-валидатор LeaveOneOut\n",
    "loo = model_selection.LeaveOneOut()\n",
    " \n",
    "#Считаем метрики на кросс-валидации leave-one-out\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X.iloc[:500], #матрица наблюдений X\n",
    "    y=y.iloc[:500], #вектор ответов y\n",
    "    cv=loo, #кросс-валидатор\n",
    "    scoring='accuracy', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    " \n",
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))\n",
    " \n",
    "## Train k-fold mean accuracy: 0.95\n",
    "## Valid k-fold mean accuracy: 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('sf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "563b3fbad9c1e703622b628cf34b11b58769da99b1ed9a9df4fdabd54b844cdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
